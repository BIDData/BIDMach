import BIDMach.networks._
import scala.io.Source
import BIDMach.datasources._
import scala.util.Random
import BIDMach._
import BIDMach.updaters._
import BIDMach.mixins._
import BIDMat.TMat

//val a=IMat(rand(1,10000)*10)
      class LearnOptions extends Learner.Options with NextWord.Opts with MatSource.Opts with ADAGrad.Opts with L2Regularizer.Opts
      def getLearner(mat0:Mat) = {
        val opts = new LearnOptions;
        opts.batchSize = math.min(100000, mat0.ncols/30 + 1);
      	val nn = new Learner(
      	    new MatSource(Array(mat0), opts), 
      	    new NextWord(opts), 
      	    Array(new L2Regularizer(opts)),
      	    new ADAGrad(opts), 
      	    null,
      	    opts)
        (nn, opts)
      }
    
    def getSample(p:FMat) : Int = {
        val v = Random.nextFloat
        var cur = 0f
        //println(sum(p).dv)
        for(i<-0 until p.size) {
            cur+=p.data(i) 
            if (cur>=v)
                return i
        }
        0
    }
    
    def sample(model:NextWord, N: Int,s:Array[Int]) = {
        val width = model.opts.width
        val batchSize = model.datasource.opts.batchSize
        val tmp = irow(s)
        model.gmats(0)<--tmp//IMat(1,batchSize)
        model.ogmats=new Array[Mat](width)
        val res = new Array[Int](N)
        for(i<-0 until N){
            model.evalbatch(model.gmats,0,0)
            val p:FMat = FMat(model.ogmats(width-1)(?,0))
            val (v,id)=maxi2(p)
            res(i) = getSample(p)
            for(j<-0 until width-1)
                tmp(j)=tmp(j+1)
            tmp(width-1) = res(i)
            model.gmats(0)<--tmp
        }
        val dict = loadCSMat("/data/word2vec/dict.csmat.lz4")
        //println(res.map(_.toChar).mkString)
        res.map(dict(_)).mkString(" ")
        /*println(model.evalbatch(model.mats,0,0).data.toList)
        println(model.ogmats(0).nrows,model.ogmats(0).ncols)
        val (v,i) = maxi2(model.ogmats(0))
        println(v)
        println(i)*/
    }
    
    def sample2(model:NextWord, N: Int,s:Array[Int]) = {
        val width = model.opts.width
        val batchSize = model.datasource.opts.batchSize
        model.gmats(0)<--irow(s)//IMat(1,batchSize)
        model.ogmats=new Array[Mat](width)
        val res = new Array[Int](N)
        val scores=model.evalbatch(model.gmats,0,0)
        for(i<-0 until N){
            val p:FMat = FMat(model.ogmats(i%width)(?,i/width))
            val (v,id)=maxi2(p)
            res(i) = getSample(p)
        }
        println(sum(irow(s.tail.take(N))==irow(res)))
        val dict = loadCSMat("/data/word2vec/dict.csmat.lz4")
        println(s.map(dict(_)).mkString(" "))
        res.map(dict(_)).mkString(" ")

    }
    
    def sample3(model:NextWord, N: Int,s:Array[Int]) = {
        val width = model.opts.width
        val batchSize = model.datasource.opts.batchSize
        model.gmats(0)<--irow(s)//IMat(1,batchSize)
        model.ogmats=new Array[Mat](width)
        val res = new Array[Int](N)
        val scores=model.evalbatch(model.gmats,0,0)
        for(i<-0 until N){
            val p:FMat = FMat(model.ogmats(i%width)(?,i/width))
            val (v,id)=maxi2(p)
            res(i) = id(0)//getSample(p)
        }
        println(sum(irow(s.tail.take(N))==irow(res)))
        val dict = loadCSMat("/data/word2vec/dict.csmat.lz4")
        println(s.map(dict(_)).mkString(" "))
        res.map(dict(_)).mkString(" ")

    }
    
    def generate() = {
        val n = 20000
        val data = new Array[Int](n)
        val width = 10 
        val w=150
        for (i<-0 until (n/width))
            if (i<w){
                val l = width/2+Random.nextInt(width/2)
                for(j<-0 until l)
                    data(i*width+j) = Random.nextInt(26)+1
            }
            else
            {
                val k = Random.nextInt(w)
                for(j<-0 until width)
                    data(i*width+j) = data(k*width+j)
            }
        data
    }

    def getWords(len:Int, n:Int) = {
        val data = Array.fill(n)(32)
        val words = Source.fromFile("/home/byeah/data/char-rnn/wordsEn.txt").getLines.filter(_.length<=len)
                    .toArray
        val m = words.size//100
        for(i<-0 until n/len) {
            val s = words(i%m)
            for(j<-0 until s.size)
                data(i*len+j) = s(j).toInt
        }
        data
    }
    
val prefix="/data/word2vec/";
val filename=prefix+"data000.imat.lz4"
val vob = 100100
val data = min(loadIMat(filename)(0,?),vob-1)
//val split = 4000000
val (l,o)=NextWord.learner(data)//(0 until 2000000))
//val (l,o)=getLearner(irow(data.take(4000000)));
o.nvocab=vob;
o.npasses=2;
o.lrate=0.1;
o.height=1;
o.width = 10
o.batchSize=4000;
o.autoReset=false;
o.dim=256
o.kind=1
o.scoreType=2
//o.debug=1
//o.reg2weight=0f//.0001f
Net.interval = 10
Net.modelId = 1
//o.logFuncs=Array(Net.logChange)
l.train
//l.model.layers(0).ge
//sample(l.model.asInstanceOf[NextWord], 100,97,null)//data.take(10000))
//sample2(l.model.asInstanceOf[NextWord], 1000,data.slice(split,split+o.batchSize+1))
//sample(l.model.asInstanceOf[NextWord], 1000,data.slice(split,split+o.batchSize+1))
//sample(l.model.asInstanceOf[NextWord], 100,data.data.take(o.batchSize))
 //sample2(l.model.asInstanceOf[NextWord], 1000,data.data.take(o.batchSize))
 
//println(data.take(100).tail.map(_.toChar).mkString)



