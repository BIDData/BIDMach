{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDMach: parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll explore automated parameter exploration by grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 CUDA device found, CUDA version 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.15258427,1843126272,12079398912)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BIDMat.{CMat,CSMat,DMat,Dict,IDict,FMat,FND,GDMat,GMat,GIMat,GSDMat,GSMat,HMat,Image,IMat,Mat,SMat,SBMat,SDMat}\n",
    "import BIDMat.MatFunctions._\n",
    "import BIDMat.SciFunctions._\n",
    "import BIDMat.Solvers._\n",
    "import BIDMat.Plotting._\n",
    "import BIDMach.Learner\n",
    "import BIDMach.models.{FM,GLM,KMeans,KMeansw,ICA,LDA,LDAgibbs,NMF,RandomForest,SFA}\n",
    "import BIDMach.datasources.{MatSource,FileSource,SFileSource}\n",
    "import BIDMach.mixins.{CosineSim,Perplexity,Top,L1Regularizer,L2Regularizer}\n",
    "import BIDMach.updaters.{ADAGrad,Batch,BatchNorm,IncMult,IncNorm,Telescoping}\n",
    "import BIDMach.causal.{IPTW}\n",
    "\n",
    "Mat.checkMKL\n",
    "Mat.checkCUDA\n",
    "Mat.plotInline = true\n",
    "if (Mat.hasCUDA > 0) GPUmem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Reuters RCV1 V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is the widely used Reuters news article dataset RCV1 V2. This dataset and several others are loaded by running the script <code>getdata.sh</code> from the BIDMach/scripts directory. The data include both train and test subsets, and train and test labels (cats). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "1.337"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var dir = \"../data/rcv1/\"             // adjust to point to the BIDMach/data/rcv1 directory\n",
    "tic\n",
    "val train = loadSMat(dir+\"docs.smat.lz4\")\n",
    "val cats = loadFMat(dir+\"cats.fmat.lz4\")\n",
    "val test = loadSMat(dir+\"testdocs.smat.lz4\")\n",
    "val tcats = loadFMat(dir+\"testcats.fmat.lz4\")\n",
    "toc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets enumerate some parameter combinations for learning rate and time exponent of the optimizer (texp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "  0.30000\n",
       "  0.40000\n",
       "  0.50000\n",
       "  0.60000\n",
       "  0.70000\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lrates = col(0.03f, 0.1f, 0.3f, 1f)        // 4 values\n",
    "val texps = col(0.3f, 0.4f, 0.5f, 0.6f, 0.7f)  // 5 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to enumerate all pairs of parameters. We can do this using the kron operator for now, this will eventually be a custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "  0.030000   0.30000\n",
       "   0.10000   0.30000\n",
       "   0.30000   0.30000\n",
       "         1   0.30000\n",
       "  0.030000   0.40000\n",
       "   0.10000   0.40000\n",
       "   0.30000   0.40000\n",
       "         1   0.40000\n",
       "        ..        ..\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lrateparams = ones(texps.nrows, 1) ⊗ lrates\n",
    "val texpparams = texps ⊗ ones(lrates.nrows,1)\n",
    "lrateparams \\ texpparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the learner again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "BIDMach.models.GLM$LearnOptions@2220a5ce"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (mm, opts) = GLM.learner(train, cats, GLM.logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple, we'll focus on just one category and train many models for it. The \"targmap\" option specifies a mapping from the actual base categories to the model categories. We'll map from category six to all our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
       "  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nparams = lrateparams.length\n",
    "val targmap = zeros(nparams, 103)\n",
    "targmap(?,6) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "  0.30000\n",
       "  0.30000\n",
       "  0.30000\n",
       "  0.30000\n",
       "  0.40000\n",
       "  0.40000\n",
       "  0.40000\n",
       "  0.40000\n",
       "       ..\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts.targmap = targmap\n",
    "opts.lrate = lrateparams\n",
    "opts.texp = texpparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus perplexity=5582.125391\n",
      "pass= 0\n",
      " 2.00%, ll=-0.69315, gf=14.628, secs=0.0, GB=0.02, MB/s=1108.15, GPUmem=0.139997\n",
      "16.00%, ll=-0.40496, gf=15.181, secs=0.1, GB=0.13, MB/s=1020.17, GPUmem=0.139997\n",
      "30.00%, ll=-0.37984, gf=15.109, secs=0.2, GB=0.25, MB/s=1004.31, GPUmem=0.139997\n",
      "44.00%, ll=-0.31457, gf=15.080, secs=0.4, GB=0.36, MB/s=999.76, GPUmem=0.139997\n",
      "58.00%, ll=-0.34047, gf=15.112, secs=0.5, GB=0.48, MB/s=1001.03, GPUmem=0.139997\n",
      "72.00%, ll=-0.23351, gf=15.118, secs=0.6, GB=0.59, MB/s=999.33, GPUmem=0.139997\n",
      "87.00%, ll=-0.28147, gf=15.059, secs=0.7, GB=0.70, MB/s=995.33, GPUmem=0.139997\n",
      "100.00%, ll=-0.23005, gf=14.928, secs=0.8, GB=0.81, MB/s=983.12, GPUmem=0.139736\n",
      "pass= 1\n",
      " 2.00%, ll=-0.28089, gf=14.921, secs=0.8, GB=0.83, MB/s=985.95, GPUmem=0.139736\n",
      "16.00%, ll=-0.22614, gf=10.039, secs=1.4, GB=0.94, MB/s=663.01, GPUmem=0.139736\n",
      "30.00%, ll=-0.28112, gf=10.423, secs=1.5, GB=1.05, MB/s=687.93, GPUmem=0.139736\n",
      "44.00%, ll=-0.27817, gf=10.757, secs=1.6, GB=1.17, MB/s=709.90, GPUmem=0.139736\n",
      "58.00%, ll=-0.23577, gf=11.052, secs=1.8, GB=1.28, MB/s=729.45, GPUmem=0.139736\n",
      "72.00%, ll=-0.19567, gf=11.299, secs=1.9, GB=1.39, MB/s=745.33, GPUmem=0.139736\n",
      "87.00%, ll=-0.27456, gf=11.527, secs=2.0, GB=1.51, MB/s=760.40, GPUmem=0.139736\n",
      "100.00%, ll=-0.21937, gf=11.714, secs=2.1, GB=1.61, MB/s=771.44, GPUmem=0.139736\n",
      "Time=2.0910 secs, gflops=11.71\n"
     ]
    }
   ],
   "source": [
    "mm.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "BIDMach.models.GLM$PredOptions@43fc3b6f"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (pp, popts) = GLM.predictor(mm.model, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And invoke the predict method on the predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus perplexity=65579.335560\r\n",
      "Predicting\r\n"
     ]
    },
    {
     "ename": "java.lang.RuntimeException",
     "evalue": "dimensions mismatch (20 103), (256 772)",
     "output_type": "error",
     "traceback": [
      "java.lang.RuntimeException: dimensions mismatch (20 103), (256 772)",
      "    BIDMat.GMat.GMult(GMat.scala:538)",
      "    BIDMat.GPair.$times(GMat.scala:1392)",
      "    BIDMat.Mop_Times$.op(Operators.scala:399)",
      "    BIDMat.Mop$class.op(Operators.scala:193)",
      "    BIDMat.Mop_Times$.op(Operators.scala:386)",
      "    BIDMat.GMat.$times(GMat.scala:1325)",
      "    BIDMach.models.GLM.meval3(GLM.scala:189)",
      "    BIDMach.models.GLM.meval2(GLM.scala:185)",
      "    BIDMach.models.RegressionModel.evalbatch(Regression.scala:77)",
      "    BIDMach.models.Model.evalbatchg(Model.scala:171)",
      "    BIDMach.Learner.repredict(Learner.scala:179)",
      "    BIDMach.Learner.predict(Learner.scala:157)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pp.predict\n",
    "val preds = FMat(pp.preds(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although ll values are printed above, they are not meaningful (there is no target to compare the prediction with). \n",
    "\n",
    "We can now compare the accuracy of predictions (preds matrix) with ground truth (the tcats matrix). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "java.lang.NoClassDefFoundError",
     "evalue": "Could not initialize class ",
     "output_type": "error",
     "traceback": [
      "java.lang.NoClassDefFoundError: Could not initialize class "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "val vcats = targmap * tcats                                          // create some virtual cats\n",
    "val lls = mean(ln(1e-7f + vcats ∘ preds + (1-vcats) ∘ (1-preds)),2)  // actual logistic likelihood\n",
    "mean(lls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more thorough measure is ROC area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "        0        0        0        0        0        0        0        0...\n",
       "  0.84498  0.83089  0.70786  0.68339  0.83812  0.83970  0.76794  0.72687...\n",
       "  0.88921  0.88448  0.82171  0.80113  0.88726  0.88800  0.85490  0.82922...\n",
       "  0.91925  0.91368  0.87920  0.86826  0.91730  0.91980  0.89681  0.88874...\n",
       "  0.93529  0.93241  0.90859  0.90460  0.93325  0.93492  0.92101  0.91841...\n",
       "  0.94632  0.94252  0.93065  0.92722  0.94484  0.94548  0.93427  0.93325...\n",
       "  0.95299  0.95031  0.94252  0.93677  0.95216  0.95281  0.94669  0.94261...\n",
       "  0.95800  0.95698  0.95160  0.94474  0.95744  0.95782  0.95337  0.94854...\n",
       "       ..       ..       ..       ..       ..       ..       ..       ..\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rocs = roc2(preds, vcats, 1-vcats, 100)   // Compute ROC curves for all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "ptolemy.plot.Plot[,0,0,484x239,layout=java.awt.FlowLayout,alignmentX=0.0,alignmentY=0.0,border=,flags=16777225,maximumSize=,minimumSize=,preferredSize=]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "0.97690,0.97633,0.97336,0.97058,0.97659,0.97681,0.97469,0.97249,0.97606,0.97700,0.97553,0.97189,0.97517,0.97694,0.97613,0.97292,0.97389,0.97664,0.97639,0.97353"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val aucs = mean(rocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maxi2 function will find the max value and its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (bestv, besti) = maxi2(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using the best index we can find the optimal parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "0.50000,0.10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texpparams(besti) \\ lrateparams(besti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Write the optimal values in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> although our parameters lay in a square grid, we could have enumerated any sequence of pairs, and we could have searched over more parameters. The learner infrastructure supports more intelligent model optimization (e.g. Bayesian methods). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
