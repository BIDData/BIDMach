{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning at Scale, Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans clustering at scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training models with data that fits in memory is very limiting. But minibatch learners can easily work with data directly from disk. \n",
    "\n",
    "We'll use the MNIST data set, which has 8 million images (about 17 GB). The dataset has been partition into groups of 100k images (using the unix split command) and saved in compressed lz4 files. This dataset is very large and doesnt get loaded by default by <code>getdata.sh</code>. You have to load it explicitly by calling <code>getmnist.sh</code> from the scripts directory. The script automatically splits the data into files that are small enough to be loaded into memory. \n",
    "\n",
    "Let's load BIDMat/BIDMach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 CUDA device found, CUDA version 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14971523,1808470016,12079398912)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BIDMat.{CMat,CSMat,DMat,Dict,IDict,Image,FMat,FND,GDMat,GMat,GIMat,GSDMat,GSMat,HMat,IMat,Mat,SMat,SBMat,SDMat}\n",
    "import BIDMat.MatFunctions._\n",
    "import BIDMat.SciFunctions._\n",
    "import BIDMat.Solvers._\n",
    "import BIDMat.Plotting._\n",
    "import BIDMach.Learner\n",
    "import BIDMach.models.{FM,GLM,KMeans,KMeansw,ICA,LDA,LDAgibbs,Model,NMF,RandomForest,SFA}\n",
    "import BIDMach.datasources.{DataSource,MatSource,FileSource,SFileSource}\n",
    "import BIDMach.mixins.{CosineSim,Perplexity,Top,L1Regularizer,L2Regularizer}\n",
    "import BIDMach.updaters.{ADAGrad,Batch,BatchNorm,IncMult,IncNorm,Telescoping}\n",
    "import BIDMach.causal.{IPTW}\n",
    "\n",
    "Mat.checkMKL\n",
    "Mat.checkCUDA\n",
    "Mat.plotInline = true\n",
    "if (Mat.hasCUDA > 0) GPUmem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define the root directory for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "../data/MNIST8M/parts/"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mdir = \"../data/MNIST8M/parts/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files we need are named \"alls00.fmat.lz4\", \"alls01.fmat.lz4\" etc. We can create a learner using a pattern for accessing these files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "BIDMach.models.KMeans$fsopts@6593bce2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (mm, opts) = KMeans.learner(mdir+\"alls%02d.fmat.lz4\",1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string \"%02d\" is a C/Scala format string that expands into a two-digit ASCII number to help with the enumeration.\n",
    "\n",
    "There are several new options that can tailor a files datasource, but we'll mostly use the defaults. One thing we will do is define the last file to use for training (number 70). This leaves us with some held-out files to use for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts.nend = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the training data include image data and labels (0-9). K-Means is an unsupervised algorithm and if we used image data only KMeans will often build clusters containing different digit images. To produce cleaner clusters, and to facilitate classification later on, the <code>alls</code> data includes both labels in the first 10 rows, and image data in the remaining rows. The label features are scaled by a large constant factor. That means that images of different digits will be far apart in feature space. It effectively prevents different digits occuring in the same cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following options are the important ones for tuning. For KMeans, batchSize has no effect on accracy since the algorithm uses all the data instances to perform an update. So you're free to tune it for best speed. Generally larger is better, as long as you dont use too much GPU ram. \n",
    "\n",
    "npasses is the number of passes over the dataset. Larger is typically better, but the model may overfit at some point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts.batchSize = 20000\n",
    "opts.npasses = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You invoke the learner the same way as before. You can change the options above after each run to optimize performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass= 0\n",
      "First pass random centroid initialization\n",
      " 2.00%, ll=0.00000, gf=62.245, secs=0.5, GB=0.13, MB/s=242.44, GPUmem=0.109619\n",
      "12.00%, ll=0.00000, gf=32.781, secs=2.0, GB=0.83, MB/s=414.95, GPUmem=0.109087\n",
      "24.00%, ll=0.00000, gf=28.554, secs=3.4, GB=1.52, MB/s=444.84, GPUmem=0.109000\n",
      "35.00%, ll=0.00000, gf=25.349, secs=5.1, GB=2.22, MB/s=431.94, GPUmem=0.108913\n",
      "45.00%, ll=0.00000, gf=22.749, secs=7.2, GB=2.92, MB/s=407.58, GPUmem=0.108826\n",
      "57.00%, ll=0.00000, gf=22.725, secs=8.6, GB=3.62, MB/s=420.42, GPUmem=0.108826\n",
      "68.00%, ll=0.00000, gf=22.493, secs=10.2, GB=4.32, MB/s=425.51, GPUmem=0.108826\n",
      "79.00%, ll=0.00000, gf=22.721, secs=11.5, GB=5.02, MB/s=436.92, GPUmem=0.108740\n",
      "89.00%, ll=0.00000, gf=21.064, secs=13.9, GB=5.72, MB/s=410.19, GPUmem=0.108740\n",
      "100.00%, ll=0.00000, gf=21.137, secs=15.4, GB=6.35, MB/s=411.61, GPUmem=0.108653\n",
      "pass= 1\n",
      " 2.00%, ll=-2463799.75000, gf=26.068, secs=16.3, GB=6.48, MB/s=398.32, GPUmem=0.101600\n",
      "12.00%, ll=-2467914.25000, gf=65.288, secs=17.0, GB=7.18, MB/s=422.62, GPUmem=0.101600\n",
      "24.00%, ll=-2484128.00000, gf=101.321, secs=17.7, GB=7.88, MB/s=444.92, GPUmem=0.101600\n",
      "35.00%, ll=-2470360.50000, gf=134.577, secs=18.4, GB=8.58, MB/s=465.61, GPUmem=0.101600\n",
      "45.00%, ll=-2464860.00000, gf=165.351, secs=19.1, GB=9.27, MB/s=484.76, GPUmem=0.101600\n",
      "57.00%, ll=-2484230.00000, gf=193.901, secs=19.8, GB=9.97, MB/s=502.50, GPUmem=0.101600\n",
      "68.00%, ll=-2466179.25000, gf=220.466, secs=20.6, GB=10.67, MB/s=519.01, GPUmem=0.101600\n",
      "79.00%, ll=-2465936.00000, gf=245.233, secs=21.3, GB=11.37, MB/s=534.38, GPUmem=0.101600\n",
      "89.00%, ll=-2488821.00000, gf=268.205, secs=22.0, GB=12.07, MB/s=548.38, GPUmem=0.101600\n",
      "100.00%, ll=-2488821.00000, gf=287.882, secs=22.7, GB=12.70, MB/s=560.73, GPUmem=0.101600\n",
      "pass= 2\n",
      " 2.00%, ll=-1633004.50000, gf=285.632, secs=23.2, GB=12.83, MB/s=553.61, GPUmem=0.101600\n",
      "12.00%, ll=-1624021.37500, gf=305.033, secs=23.9, GB=13.53, MB/s=564.96, GPUmem=0.101600\n",
      "24.00%, ll=-1606139.37500, gf=318.304, secs=25.1, GB=14.23, MB/s=566.85, GPUmem=0.101600\n",
      "35.00%, ll=-1632257.00000, gf=335.172, secs=25.9, GB=14.93, MB/s=576.76, GPUmem=0.101600\n",
      "45.00%, ll=-1624979.25000, gf=348.789, secs=26.8, GB=15.63, MB/s=582.32, GPUmem=0.101600\n",
      "57.00%, ll=-1617725.50000, gf=363.922, secs=27.6, GB=16.32, MB/s=591.47, GPUmem=0.101600\n",
      "68.00%, ll=-1622298.87500, gf=378.330, secs=28.4, GB=17.02, MB/s=600.28, GPUmem=0.101600\n",
      "79.00%, ll=-1624221.75000, gf=391.598, secs=29.1, GB=17.72, MB/s=608.02, GPUmem=0.101600\n",
      "89.00%, ll=-1622257.50000, gf=404.140, secs=29.9, GB=18.42, MB/s=615.32, GPUmem=0.101600\n",
      "100.00%, ll=-1617452.62500, gf=415.116, secs=30.6, GB=19.06, MB/s=621.97, GPUmem=0.101600\n",
      "pass= 3\n",
      " 2.00%, ll=-1567983.00000, gf=416.407, secs=30.8, GB=19.18, MB/s=623.27, GPUmem=0.101600\n",
      "12.00%, ll=-1570730.00000, gf=428.290, secs=31.5, GB=19.88, MB/s=630.71, GPUmem=0.101600\n",
      "24.00%, ll=-1581877.25000, gf=440.034, secs=32.2, GB=20.58, MB/s=638.39, GPUmem=0.101600\n",
      "35.00%, ll=-1570931.37500, gf=451.255, secs=33.0, GB=21.28, MB/s=645.72, GPUmem=0.101600\n",
      "45.00%, ll=-1571025.87500, gf=461.971, secs=33.7, GB=21.98, MB/s=652.71, GPUmem=0.101600\n",
      "57.00%, ll=-1584378.12500, gf=471.979, secs=34.4, GB=22.68, MB/s=659.03, GPUmem=0.101600\n",
      "68.00%, ll=-1568567.00000, gf=481.786, secs=35.1, GB=23.38, MB/s=665.40, GPUmem=0.101600\n",
      "79.00%, ll=-1571677.50000, gf=491.295, secs=35.8, GB=24.07, MB/s=671.63, GPUmem=0.101600\n",
      "89.00%, ll=-1584836.12500, gf=500.405, secs=36.6, GB=24.77, MB/s=677.59, GPUmem=0.101600\n",
      "100.00%, ll=-1584836.12500, gf=508.342, secs=37.2, GB=25.41, MB/s=682.86, GPUmem=0.101600\n",
      "Time=37.2090 secs, gflops=508.33\n"
     ]
    }
   ],
   "source": [
    "mm.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets extract the model as a Floating-point matrix. We included the category features for clustering to make sure that each cluster is a subset of images for one digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "      0      0      0      0      0  10000      0      0      0      0...\n",
       "  10000      0      0      0      0      0      0      0      0      0...\n",
       "      0      0      0      0  10000      0      0      0      0      0...\n",
       "  10000      0      0      0      0      0      0      0      0      0...\n",
       "      0      0      0      0  10000      0      0      0      0      0...\n",
       "      0      0      0  10000      0      0      0      0      0      0...\n",
       "      0  10000      0      0      0      0      0      0      0      0...\n",
       "      0      0      0      0      0  10000      0      0      0      0...\n",
       "     ..     ..     ..     ..     ..     ..     ..     ..     ..     ..\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val modelmat = FMat(mm.modelmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we build a 30 x 10 array of images to view the first 300 cluster centers as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "javax.swing.JFrame[frame0,0,0,1696x598,layout=java.awt.BorderLayout,title=Image 0,resizable,normal,defaultCloseOperation=HIDE_ON_CLOSE,rootPane=javax.swing.JRootPane[,8,30,1680x560,layout=javax.swing.JRootPane$RootLayout,alignmentX=0.0,alignmentY=0.0,border=,flags=16777673,maximumSize=,minimumSize=,preferredSize=],rootPaneCheckingEnabled=true]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nx = 30\n",
    "val ny = 10\n",
    "val im = zeros(28,28)\n",
    "val allim = zeros(28*nx,28*ny)\n",
    "for (i<-0 until nx) {\n",
    "    for (j<-0 until ny) {\n",
    "        val slice = modelmat(i+nx*j,10->794)\n",
    "        im(?) = slice(?)\n",
    "        allim((28*i)->(28*(i+1)), (28*j)->(28*(j+1))) = im\n",
    "    }\n",
    "}\n",
    "Image.show(allim kron ones(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll predict using the closest cluster (or 1-NN if you like). First we read some data directly. We could also try to do evaluation directly from disk, but this would usually be overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val test = loadFMat(mdir+\"alls70.fmat.lz4\")   // Load a test data file\n",
    "val testdata = test.copy                      // copy it\n",
    "testdata(0->10,?) = 0                         // and remove the digit labels\n",
    "val preds = izeros(1, test.ncols)             // make a container to hold the predictions\n",
    "1                                             // avoids a monster data cell being printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a predictor from the just-computed model and the testdata, with the preds matrix to catch the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "<console>:30: error: not enough arguments for method predictor: (model: BIDMach.models.Model, mat1: BIDMat.Mat, preds: BIDMat.Mat)(BIDMach.Learner, BIDMach.models.KMeans.memopts).\r",
      "Unspecified value parameter preds.\r",
      "       val (pp, popts) = KMeans.predictor(mm.model, testdata)\r",
      "                                         ^"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "val (pp, popts) = KMeans.predictor(mm.model, testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp.predict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>preds</code> matrix now contains the numbers of the best-matching cluster centers. We still need to look up the category label for each one. We also need to look up the category for each of the test inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val (vmax, predcat) = maxi2(modelmat(preds,0->10).t)   // Lookup the cat for the matching cluster\n",
    "val (wmax, truecat) = maxi2(test(0->10,?))             // Reference cats for test items\n",
    "val inds = predcat.t \\ truecat.t                       // Concatenate them into a two-column matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the actual and predicted categories, we can compute a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val conf = accum(inds, 1f, 10, 10)  // accumulate the (estimate,exact) ids into a matrix\n",
    "conf ~ conf / sum(conf)             // normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create an image by multiplying each confusion matrix cell by a white square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image.show((conf * 250f) ⊗ ones(64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its useful to isolate the correct classification rate by digit, which is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val dacc = getdiag(conf).t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the mean of the diagonal accuracies to get an overall accuracy for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean(dacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment again with a larger number of clusters (3000, then 30000). You should reduce the batchSize option to 20000 to avoid memory problems.\n",
    "\n",
    "Include the training time output by the call to <code>nn.train</code> but not the evaluation time (the evaluation code above is not using the GPU). Rerun and fill out the table below: \n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>KMeans Clusters</th>\n",
    "<th>Training time</th>\n",
    "<th>Avg. gflops</th>\n",
    "<th>Accuracy</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>300</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>3000</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>30000</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
