{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll explore training and evaluation of Naive Bayes and Logitistic Regression Classifiers.\n",
    "\n",
    "To start, we import the standard BIDMach class definitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 CUDA devices found, CUDA version 8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$exec.$                          \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $exec.^.lib.bidmach_notebook_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load some training and test data, and some category labels. The data come from a news collection from Reuters, and is a \"classic\" test set for classification. Each article belongs to one or more of 103 categories. The articles are represented as Bag-of-Words (BoW) column vectors. For a data matrix A, element A(i,j) holds the count of word i in document j. \n",
    "\n",
    "The category matrices have 103 rows, and a category matrix C has a one in position C(i,j) if document j is tagged with category i, or zero otherwise.  \n",
    "\n",
    "To reduce the computing time and memory footprint, the training data have been sampled. The full collection has about 700k documents. Our training set has 60k. \n",
    "\n",
    "Since the document matrices contain counts of words, we use a min function to limit the count to \"1\", i.e. because we need binary features for naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdict\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../data/rcv1/\"\u001b[39m\n",
       "\u001b[36mtraindata\u001b[39m: \u001b[32mSMat\u001b[39m = (    33,     0)     1\n",
       "(    47,     0)     1\n",
       "(    94,     0)     1\n",
       "(   104,     0)     1\n",
       "(   112,     0)     1\n",
       "(   118,     0)     1\n",
       "(   141,     0)     1\n",
       "(   165,     0)     1\n",
       "(   179,     0)     1\n",
       "(   251,     0)     1\n",
       "(   270,     0)     1\n",
       "(   306,     0)     1\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mtraincats\u001b[39m: \u001b[32mFMat\u001b[39m =    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mtestdata\u001b[39m: \u001b[32mSMat\u001b[39m = (    0,    0)    1\n",
       "(    1,    0)    1\n",
       "(    4,    0)    1\n",
       "(    6,    0)    1\n",
       "(    7,    0)    1\n",
       "(   11,    0)    1\n",
       "(   12,    0)    1\n",
       "(   13,    0)    1\n",
       "(   14,    0)    1\n",
       "(   18,    0)    1\n",
       "(   19,    0)    1\n",
       "(   20,    0)    1\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mtestcats\u001b[39m: \u001b[32mFMat\u001b[39m =    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   1   0   1   0   0   0   0   0   1   0   1   0   1   0   0   0   0   0...\n",
       "   1   0   0   0   0   0   1   0   0   0   0   1   0   0   1   1   0   0...\n",
       "   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   1   0   0   0   0   1   1   0   0   0   0   1   1   0   1   1   0   0...\n",
       "   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   1   1   1   1   0   0   1   0   1   1   0   0   1   0   0   1   0...\n",
       "   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0...\n",
       "   0   0   1   0   0   0   0   0   0   1   1   0   0   1   0   0   0   1...\n",
       "   0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mres1_5\u001b[39m: \u001b[32mSMat\u001b[39m = (    33,     0)     1\n",
       "(    47,     0)     1\n",
       "(    94,     0)     1\n",
       "(   104,     0)     1\n",
       "(   112,     0)     1\n",
       "(   118,     0)     1\n",
       "(   141,     0)     1\n",
       "(   165,     0)     1\n",
       "(   179,     0)     1\n",
       "(   251,     0)     1\n",
       "(   270,     0)     1\n",
       "(   306,     0)     1\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mres1_6\u001b[39m: \u001b[32mSMat\u001b[39m = (    0,    0)    1\n",
       "(    1,    0)    1\n",
       "(    4,    0)    1\n",
       "(    6,    0)    1\n",
       "(    7,    0)    1\n",
       "(   11,    0)    1\n",
       "(   12,    0)    1\n",
       "(   13,    0)    1\n",
       "(   14,    0)    1\n",
       "(   18,    0)    1\n",
       "(   19,    0)    1\n",
       "(   20,    0)    1\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dict = \"../data/rcv1/\"\n",
    "val traindata = loadSMat(dict+\"docs.smat.lz4\")\n",
    "val traincats = loadFMat(dict+\"cats.fmat.lz4\")\n",
    "val testdata = loadSMat(dict+\"testdocs.smat.lz4\")\n",
    "val testcats = loadFMat(dict+\"testcats.fmat.lz4\")\n",
    "min(traindata, 1, traindata)                       // the first \"traindata\" argument is the input, the other is output\n",
    "min(testdata, 1, testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the word and document counts from the data. This turns out to be equivalent to a matrix multiply. For a data matrix A and category matrix C, we want all (cat, word) pairs (i,j) such that C(i,k) and A(j,k) are both 1 - this means that document k contains word j, and is also tagged with category i. Summing over all documents gives us\n",
    "\n",
    "$${\\rm wordcatCounts(i,j)} = \\sum_{k=1}^N C(i,k) A(j,k) = C * A^T$$\n",
    "\n",
    "\n",
    "Because we are doing independent binary classifiers for each class, we need to construct the counts for words not in the class (negwcounts).\n",
    "\n",
    "Finally, we add a smoothing count 0.5 to counts that could be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtruecounts\u001b[39m: \u001b[32mFMat\u001b[39m =     6601    6282       0       0    1338    2167    2931     551    3588...\n",
       "   54661   63593       0       0   35284   30807   30156    7978   40192...\n",
       "   31637   15944       0       0   18959   36288   35867   36767   18956...\n",
       "   14443   14678       0       0    7309   14194   16290    1882   11460...\n",
       "   88680   65557       0       0   54424  117815  119028   40490   68167...\n",
       "   11592   15108       0       0   14155    3868    5600    3529    2315...\n",
       "  129559  169595       0       0  164626   66692   95662  143881   53627...\n",
       "   17642   33419       0       0   39781    6437   11017   51591    7120...\n",
       "   43411   70692       0       0   69276   26538   31923   89144   15103...\n",
       "    8301    8799       0       0    5441    4137    3469    1455    2164...\n",
       "   50537  116171       0       0   53590   36965   30849   18426   31545...\n",
       "    8300    8901       0       0    5528    4220    3469    1485    2143...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mwcounts\u001b[39m: \u001b[32mFMat\u001b[39m =       6601.5      6282.5     0.50000     0.50000      1338.5      2167.5...\n",
       "       54662       63594     0.50000     0.50000       35285       30808...\n",
       "       31638       15945     0.50000     0.50000       18960       36289...\n",
       "       14444       14679     0.50000     0.50000      7309.5       14195...\n",
       "       88681       65558     0.50000     0.50000       54425  1.1782e+05...\n",
       "       11593       15109     0.50000     0.50000       14156      3868.5...\n",
       "  1.2956e+05  1.6960e+05     0.50000     0.50000  1.6463e+05       66693...\n",
       "       17643       33420     0.50000     0.50000       39782      6437.5...\n",
       "       43412       70693     0.50000     0.50000       69277       26539...\n",
       "      8301.5      8799.5     0.50000     0.50000      5441.5      4137.5...\n",
       "       50538  1.1617e+05     0.50000     0.50000       53591       36966...\n",
       "      8300.5      8901.5     0.50000     0.50000      5528.5      4220.5...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mnegwcounts\u001b[39m: \u001b[32mFMat\u001b[39m =   8.9902e+05  1.1471e+06     0.50000     0.50000  8.7687e+05  6.9242e+05...\n",
       "  8.5096e+05  1.0898e+06     0.50000     0.50000  8.4292e+05  6.6378e+05...\n",
       "  8.7398e+05  1.1375e+06     0.50000     0.50000  8.5925e+05  6.5830e+05...\n",
       "  8.9118e+05  1.1387e+06     0.50000     0.50000  8.7090e+05  6.8039e+05...\n",
       "  8.1694e+05  1.0879e+06     0.50000     0.50000  8.2378e+05  5.7677e+05...\n",
       "  8.9403e+05  1.1383e+06     0.50000     0.50000  8.6405e+05  6.9072e+05...\n",
       "  7.7606e+05  9.8381e+05     0.50000     0.50000  7.1358e+05  6.2789e+05...\n",
       "  8.8798e+05  1.1200e+06     0.50000     0.50000  8.3843e+05  6.8815e+05...\n",
       "  8.6221e+05  1.0827e+06     0.50000     0.50000  8.0893e+05  6.6805e+05...\n",
       "  8.9732e+05  1.1446e+06     0.50000     0.50000  8.7277e+05  6.9045e+05...\n",
       "  8.5508e+05  1.0372e+06     0.50000     0.50000  8.2462e+05  6.5762e+05...\n",
       "  8.9732e+05  1.1445e+06     0.50000     0.50000  8.7268e+05  6.9037e+05...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mdcounts\u001b[39m: \u001b[32mFMat\u001b[39m =     8289\n",
       "  116471\n",
       "   47402\n",
       "   25304\n",
       "  198938\n",
       "   31231\n",
       "  370541\n",
       "   79524\n",
       "  147606\n",
       "   16586\n",
       "  232297\n",
       "   16770\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val truecounts = traincats *^ traindata\n",
    "val wcounts = truecounts + 0.5\n",
    "val negwcounts = sum(truecounts) - truecounts + 0.5\n",
    "val dcounts = sum(traincats,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the probabilities \n",
    "* pwordcat = probability that a word is in a cat, given the cat.\n",
    "* pwordncat = probability of a word, given the complement of the cat.\n",
    "* pcat = probability that doc is in a given cat. \n",
    "* spcat = sum of pcat probabilities (> 1 because docs can be in multiple cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpwordcat\u001b[39m: \u001b[32mFMat\u001b[39m =    0.0068321   0.0065020  5.1747e-07  5.1747e-07   0.0013853   0.0022432...\n",
       "   0.0055248   0.0064276  5.0537e-08  5.0537e-08   0.0035663   0.0031138...\n",
       "   0.0071998   0.0036285  1.1379e-07  1.1379e-07   0.0043147   0.0082583...\n",
       "   0.0065308   0.0066370  2.2608e-07  2.2608e-07   0.0033051   0.0064182...\n",
       "   0.0061666   0.0045587  3.4768e-08  3.4768e-08   0.0037845   0.0081925...\n",
       "   0.0044292   0.0057726  1.9104e-07  1.9104e-07   0.0054085   0.0014781...\n",
       "   0.0055111   0.0072142  2.1269e-08  2.1269e-08   0.0070028   0.0028369...\n",
       "   0.0050931   0.0096476  1.4434e-07  1.4434e-07    0.011484   0.0018584...\n",
       "   0.0061113   0.0099519  7.0388e-08  7.0388e-08   0.0097525   0.0037360...\n",
       "   0.0048131   0.0051018  2.8989e-07  2.8989e-07   0.0031549   0.0023989...\n",
       "   0.0019538   0.0044912  1.9330e-08  1.9330e-08   0.0020718   0.0014291...\n",
       "   0.0047402   0.0050834  2.8554e-07  2.8554e-07   0.0031572   0.0024102...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mpwordncat\u001b[39m: \u001b[32mFMat\u001b[39m =    0.0045730   0.0058350  2.5433e-09  2.5433e-09   0.0044603   0.0035221...\n",
       "   0.0045367   0.0058101  2.6657e-09  2.6657e-09   0.0044939   0.0035388...\n",
       "   0.0045245   0.0058885  2.5884e-09  2.5884e-09   0.0044482   0.0034079...\n",
       "   0.0045619   0.0058292  2.5595e-09  2.5595e-09   0.0044581   0.0034829...\n",
       "   0.0044621   0.0059417  2.7310e-09  2.7310e-09   0.0044994   0.0031503...\n",
       "   0.0045861   0.0058391  2.5648e-09  2.5648e-09   0.0044323   0.0035432...\n",
       "   0.0044596   0.0056535  2.8732e-09  2.8732e-09   0.0041006   0.0036082...\n",
       "   0.0045749   0.0057702  2.5760e-09  2.5760e-09   0.0043196   0.0035453...\n",
       "   0.0045271   0.0056848  2.6253e-09  2.6253e-09   0.0042473   0.0035076...\n",
       "   0.0045820   0.0058448  2.5532e-09  2.5532e-09   0.0044566   0.0035257...\n",
       "   0.0049805   0.0060415  2.9123e-09  2.9123e-09   0.0048031   0.0038304...\n",
       "   0.0045826   0.0058450  2.5535e-09  2.5535e-09   0.0044568   0.0035257...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mpcat\u001b[39m: \u001b[32mFMat\u001b[39m =     0.010610\n",
       "     0.14908\n",
       "    0.060673\n",
       "    0.032388\n",
       "     0.25464\n",
       "    0.039975\n",
       "     0.47428\n",
       "     0.10179\n",
       "     0.18893\n",
       "    0.021230\n",
       "     0.29733\n",
       "    0.021465\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mspcat\u001b[39m: \u001b[32mFMat\u001b[39m = 3.2424"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pwordcat = wcounts / sum(wcounts,2)                 // Normalize the rows to sum to 1.\n",
    "val pwordncat = negwcounts / sum(negwcounts,2)          // Each row represents word probabilities conditioned on one cat. \n",
    "val pcat = dcounts / traindata.ncols\n",
    "val spcat = sum(pcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take the logs of those probabilities. Here we're using the formula presented <a href=\"https://bcourses.berkeley.edu/courses/1267848/files/51512989/download?wrap=1in\">here</a> to match Naive Bayes to Logistic Regression for independent data.\n",
    "\n",
    "For each word, we compute the log of the ratio of the complementary word probability over the in-class word probability. \n",
    "\n",
    "For each category, we compute the log of the ratio of the complementary category probability over the current category probability.\n",
    "\n",
    "lpwordcat(j,i) represents $\\log\\left(\\frac{{\\rm Pr}(X_i|\\neg c_j)}{{\\rm Pr}(X_i|c_j)}\\right)$\n",
    "\n",
    "while lpcat(j) represents $\\log\\left(\\frac{{\\rm Pr}(\\neg c)}{{\\rm Pr}(c)}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlpwordcat\u001b[39m: \u001b[32mFMat\u001b[39m =    -0.40147   -0.10823    -5.3155    -5.3155     1.1693    0.45114...\n",
       "   -0.19705   -0.10100    -2.9423    -2.9423    0.23118    0.12794...\n",
       "   -0.46455    0.48418    -3.7833    -3.7833   0.030486   -0.88511...\n",
       "   -0.35877   -0.12979    -4.4811    -4.4811    0.29928   -0.61126...\n",
       "   -0.32353    0.26497    -2.5441    -2.5441    0.17303   -0.95573...\n",
       "   0.034805   0.011458    -4.3106    -4.3106   -0.19905    0.87429...\n",
       "   -0.21170   -0.24378    -2.0018    -2.0018   -0.53518    0.24048...\n",
       "   -0.10730   -0.51401    -4.0259    -4.0259   -0.97782    0.64592...\n",
       "   -0.30007   -0.55996    -3.2888    -3.2888   -0.83124  -0.063085...\n",
       "  -0.049195    0.13595    -4.7322    -4.7322    0.34544    0.38508...\n",
       "    0.93577    0.29653    -1.8927    -1.8927    0.84083    0.98593...\n",
       "  -0.033811    0.13960    -4.7169    -4.7169    0.34474    0.38036...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mlpcat\u001b[39m: \u001b[32mFMat\u001b[39m =   5.7190\n",
       "  3.0325\n",
       "  3.9597\n",
       "  4.5962\n",
       "  2.4624\n",
       "  4.3834\n",
       "  1.7641\n",
       "  3.4293\n",
       "  2.7826\n",
       "  5.0221\n",
       "  2.2930\n",
       "  5.0110\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lpwordcat = ln(pwordncat/pwordcat)   // ln is log to the base e (natural log)\n",
    "val lpcat = ln((spcat-pcat)/pcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where we apply Naive Bayes. The formula we're using is borrowed from <a href=\"https://bcourses.berkeley.edu/courses/1267848/files/51512989/download?wrap=1in\">here</a>.\n",
    "\n",
    "$${\\rm Pr}(c|X_1,\\ldots,X_k) = \\frac{1}{1 + \\frac{{\\rm Pr}(\\neg c)}{{\\rm Pr}(c)}\\prod_{i-1}^k\\frac{{\\rm Pr}(X_i|\\neg c)}{{\\rm Pr}(X_i|c)}}$$\n",
    "\n",
    "and we can rewrite\n",
    "\n",
    "$$\\frac{{\\rm Pr}(\\neg c)}{{\\rm Pr}(c)}\\prod_{i-1}^k\\frac{{\\rm Pr}(X_i|\\neg c)}{{\\rm Pr}(X_i|c)}$$\n",
    "\n",
    "as\n",
    "\n",
    "$$\\exp\\left(\\log\\left(\\frac{{\\rm Pr}(\\neg c)}{{\\rm Pr}(c)}\\right) + \\sum_{i=1}^k\\log\\left(\\frac{{\\rm Pr}(X_i|\\neg c)}{{\\rm Pr}(X_i|c)}\\right)\\right)  = \\exp({\\rm lpcat(j)} + {\\rm lpwordcat(j,?)} * X)$$\n",
    "\n",
    "for class number j and an input column $X$. This follows because an input column $X$ is a sparse vector with ones in the positions of the input features. The product ${\\rm lpwordcat(i,?)} * X$ picks out the features occuring in the input document and adds the corresponding logs from lpwordcat. \n",
    "\n",
    "Finally, we take the exponential above and fold it into the formula $P(c_j|X_1,\\ldots,X_k) = 1/(1+\\exp(\\cdots))$. This gives us a matrix of predictions. preds(i,j) = prediction of membership in category i for test document j. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlogodds\u001b[39m: \u001b[32mFMat\u001b[39m =    -6.0932    82.044    57.881    57.881    46.718    63.467    43.108...\n",
       "    10.183    17.738    36.602    36.602    22.135    45.008    24.703...\n",
       "   -30.983    96.652    46.998    46.998    62.005    20.090   -74.427...\n",
       "   -25.657    108.47    86.850    86.850    62.880    33.790   -29.653...\n",
       "   -33.350    69.578    58.679    58.679    59.652   -65.415   -70.871...\n",
       "    78.985   -22.122    34.228    34.228    21.171    34.943    111.26...\n",
       "    36.580   -22.600   -30.684   -30.684   -2.4677    30.346    50.377...\n",
       "    92.823    85.826  -0.92882  -0.92882    35.390    113.61    124.14...\n",
       "    40.340    45.135   -29.260   -29.260    25.949    71.048    57.417...\n",
       "    48.189    14.777    32.442    32.442    32.825    70.634    87.507...\n",
       "    62.109    47.123    58.016    58.016    5.9495    89.868    117.45...\n",
       "    50.110    13.168    32.410    32.410    32.537    72.225    92.823...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mpreds\u001b[39m: \u001b[32mFMat\u001b[39m =      0.99775  2.3386e-36  7.2888e-26  7.2888e-26  5.1342e-21  2.7320e-28...\n",
       "  3.7791e-05  1.9795e-08  1.2703e-16  1.2703e-16  2.4362e-10  2.8391e-20...\n",
       "           1           0  3.8822e-21  3.8822e-21  1.1792e-27  1.8830e-09...\n",
       "           1           0  1.9122e-38  1.9122e-38  4.9172e-28  2.1134e-15...\n",
       "           1  6.0612e-31  3.2827e-26  3.2827e-26  1.2397e-26           1...\n",
       "  4.9782e-35           1  1.3651e-15  1.3651e-15  6.3936e-10  6.6751e-16...\n",
       "  1.2985e-16           1           1           1     0.92184  6.6234e-14...\n",
       "           0  5.3243e-38     0.71684     0.71684  4.2709e-16           0...\n",
       "  3.0228e-18  2.5022e-20           1           1  5.3761e-12  1.3940e-31...\n",
       "  1.1802e-21  3.8222e-07  8.1360e-15  8.1360e-15  5.5485e-15  2.1085e-31...\n",
       "  1.0628e-27  3.4240e-21  6.3677e-26  6.3677e-26   0.0026004           0...\n",
       "  1.7285e-22  1.9098e-06  8.4068e-15  8.4068e-15  7.3989e-15  4.2942e-32...\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val logodds = lpwordcat * testdata + lpcat\n",
    "val preds = 1 / (1 + exp(logodds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the accuracy of the predictions above, we can compute the probability that the classifier outputs the right label. We used this formula in class for the expected accuracy for logistic regression. The \"dot arrow\" operator takes dot product along rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36macc\u001b[39m: \u001b[32mFMat\u001b[39m =   0.96676\n",
       "  0.91988\n",
       "  0.92873\n",
       "  0.90522\n",
       "  0.92503\n",
       "  0.92083\n",
       "  0.87694\n",
       "  0.93186\n",
       "  0.91148\n",
       "  0.97116\n",
       "  0.93154\n",
       "  0.97145\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mres6_1\u001b[39m: \u001b[32mFMat\u001b[39m = 0.96676,0.91988,0.92873,0.90522,0.92503,0.92083,0.87694,0.93186,0.91148,0.97116,0.93154,0.97145,0.89068,0.97366,0.96644,0.93150,0.93144,0.99561,0.96318,0.90782,0.91158,0.88406,0.97971,0.94595,0.94944,0.91045,0.90866,0.89464,0.96982,0.96171,0.93822,0.97635,0.97523,0.90473,0.92854,0.85144,0.90741,0.96143,0.98985,0.99624,0.98202,0.97888,0.99910,0.93597,0.90695,0.98017,0.96474,0.97071,0.96489,0.92164,0.99069,0.97455,0.96476,0.90273,0.97072,0.98506,0.98083,0.99524,0.97665,0.99359,0.96843,0.98735,0.97673,0.99521,0.98967,0.99410,0.93016,0.99611,0.99480,0.99684,0.99672,0.96849,0.99729,0.97603,0.96933,0.98094,0.99288,0.99335,0.99803,0.90614,0.99000,0.99077,0.99327,0.96843,0.95881,0.99586,0.99706,0.92778,0.99615,0.99851,0.99031,0.99615,0.99574,0.99295,0.99623,0.99870,0.99871,0.99938,0.99944,0.99869,0.99881,0.99952,0.99978"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val acc = ((preds ∙→ testcats) + ((1-preds) ∙→ (1-testcats)))/preds.ncols\n",
    "acc.t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw accuracy is not a good measure in most cases. When there are few positives (instances in the class vs. its complement), accuracy simply drives down false-positive rate at the expense of false-negative rate. In the worst case, the learner may always predict \"no\" and still achieve high accuracy. \n",
    "\n",
    "ROC curves and ROC Area Under the Curve (AUC) are much better. Here we compute the ROC curves from the predictions above. We need:\n",
    "* scores - the predicted quality from the formula above.\n",
    "* good - 1 for positive instances, 0 for negative instances.\n",
    "* bad - complement of good. \n",
    "* npoints (100) - specifies the number of X-axis points for the ROC plot. \n",
    "\n",
    "itest specifies which of the categories to plot for. We chose itest=6 because that category has one of the highest positive rates, and gives the most stable accuracy plots.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mitest\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m6\u001b[39m\n",
       "\u001b[36mscores\u001b[39m: \u001b[32mFMat\u001b[39m = 1.2985e-16,1,1,1,0.92184,6.6234e-14,1.3227e-22,1.0000,6.4175e-05,0.74290,0.091579,2.8002e-11,4.0427e-22,0.29289,0.99790,0.0054418,0.99997,2.7469e-31,1.1725e-10,0.015976,0.95969,7.5308e-10,2.9457e-16,0.011309,9.1842e-10,2.0738e-05,3.0239e-30,3.6126e-07,2.0369e-06,1,1,0.99999,0.99999,9.8394e-11,0.81547,0.99826,5.4711e-12,0.99052,4.8879e-10,3.0592e-06,0.99899,1.0000,2.0468e-06,0.99994,0.99781,0.97165,0.0045558,0.021813,1.1182e-17,1.1182e-17,7.6746e-17,1.0000,7.6746e-17,7.3089e-06,7.3089e-06,0.99864,2.8267e-09,1.2181e-14,1,4.7808e-24,2.3243e-24,9.4091e-14,0.99724,7.0307e-08,0.99816,1.3932e-13,1.2951e-08,0.91334,6.3677e-06,5.1386e-10,3.3876e-17,1.0000,1.0000,0.99958,7.8813e-06,1.4805e-12,0.99981,0.99971,8.4397e-11,0.99939,0.99836,1,7.2057e-08,0.010264,1.0000,0.044583,8.8276e-08,6.1791e-13,0.017260,0.99966,0.0021901,4.3284e-17,0.99996,0.99821,0.93932,0.98340,4.8482e-24,1.3503e-11,2.3761e-06,0.99011,0.00018747,1,0.99882,0.98596,0.99655,0.0012145,1.5212e\u001b[33m...\u001b[39m\n",
       "\u001b[36mgood\u001b[39m: \u001b[32mFMat\u001b[39m = 0,1,1,1,1,0,0,1,0,1,1,0,0,1,0,0,1,0,1,1,1,0,0,0,0,1,0,1,0,1,1,1,1,0,1,1,0,1,0,0,1,1,1,1,1,1,1,1,0,0,0,1,0,0,0,0,1,1,1,0,0,1,1,0,1,0,0,1,1,1,0,1,1,1,1,0,1,1,0,1,1,1,0,1,1,1,0,0,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,0,0,1,0,1,1,0,0,0,0,1,1,1,1,0,1,1,1,0,0,1,1,0,1,0,1,1,1,1,0,0,0,1,0,0,1,1,1,0,0,0,0,1,1,1,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,0,1,1,1,1,1,1,0,1,0,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,1,0,1,1,0,1,1,1,0,0,1,1,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,0,0,1,1,0,1,1,0,0,1,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,1,1,0,1,0,1,0,1,1,0,1,1,1,1,1,0,1,0,0,1,1,1,1,0,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,0,1,0,0,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,1,1,1,0,0,0,1,0,1,1,0,1,0,1,1,1,1,1,0,1,1,\u001b[33m...\u001b[39m\n",
       "\u001b[36mbad\u001b[39m: \u001b[32mFMat\u001b[39m = 1,0,0,0,0,1,1,0,1,0,0,1,1,0,1,1,0,1,0,0,0,1,1,1,1,0,1,0,1,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,0,0,0,1,1,1,0,1,1,1,1,0,0,0,1,1,0,0,1,0,1,1,0,0,0,1,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,1,1,0,0,1,1,0,0,0,0,1,1,1,0,0,0,0,0,0,1,1,0,1,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,1,0,0,1,0,1,0,0,0,0,1,1,1,0,1,1,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,1,0,0,0,0,0,0,1,0,1,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,1,0,1,0,0,1,0,0,0,1,1,0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,0,0,1,1,0,0,1,0,0,1,1,0,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,1,0,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,0,1,1,0,0,0,0,1,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,1,0,1,1,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,1,0,0,0,0,0,1,1,1,0,1,0,0,1,0,1,0,0,0,0,0,1,0,0,\u001b[33m...\u001b[39m\n",
       "\u001b[36mrr\u001b[39m: \u001b[32mDMat\u001b[39m =         0\n",
       "  0.72112\n",
       "  0.77285\n",
       "  0.79854\n",
       "  0.81708\n",
       "  0.83275\n",
       "  0.84081\n",
       "  0.84990\n",
       "  0.85898\n",
       "  0.86510\n",
       "  0.87159\n",
       "  0.87762\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val itest = 6\n",
    "val scores = preds(itest,?)\n",
    "val good = testcats(itest,?)\n",
    "val bad = 1-testcats(itest,?)\n",
    "val rr =roc(scores,good,bad,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO 1: In the cell below, write an expression to derive the ROC Area under the curve (AUC) given the curve rr. rr gives the ROC curve y-coordinates at 100 evenly-spaced X-values from 0 to 1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "// auc = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO 2: In the cell below, write the value of AUC returned by the expression above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train a logistic classifier on the same data. BIDMach has an umbrella classifier called GLM for Generalized Linear Model. GLM includes linear regression, logistic regression (with log accuracy or direct accuracy optimization), and SVM. \n",
    "\n",
    "The learner function accepts these arguments:\n",
    "* traindata: the training data in the same format as for Naive Bayes\n",
    "* traincats: the training category labels\n",
    "* testdata: the test input data\n",
    "* predcats: a container for the predictions generated by the model\n",
    "* modeltype (GLM.logistic here): an integer that specifies the type of model (0=linear, 1=logistic log accuracy, 2=logistic accuracy, 3=SVM). \n",
    "\n",
    "We'll construct the learner and then look at its options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option Name       Type          Value\n",
      "===========       ====          =====\n",
      "addConstFeat      boolean       false\n",
      "aopts             Opts          null\n",
      "autoReset         boolean       true\n",
      "batchSize         int           10000\n",
      "checkPointFile    String        null\n",
      "checkPointInterval  float         0.0\n",
      "clipByValue       float         -1.0\n",
      "cumScore          int           0\n",
      "debug             int           0\n",
      "debugCPUmem       boolean       false\n",
      "debugMem          boolean       false\n",
      "dim               int           256\n",
      "doAllReduce       boolean       false\n",
      "doubleScore       boolean       false\n",
      "doVariance        boolean       false\n",
      "epsilon           float         1.0E-5\n",
      "evalStep          int           11\n",
      "featThreshold     Mat           null\n",
      "featType          int           1\n",
      "gsq_decay         float         -1.0\n",
      "hashBound1        int           1000000\n",
      "hashBound2        int           1000000\n",
      "hashFeatures      int           0\n",
      "initsumsq         float         1.0E-5\n",
      "iweight           FMat          null\n",
      "l2reg             FMat          null\n",
      "langevin          float         0.0\n",
      "lim               float         0.0\n",
      "links             IMat          2,2,2,2,2,2,2,2,2,2,...\n",
      "logDataSink       DataSink      null\n",
      "logfile           String        log.txt\n",
      "logFuncs          Function2[]   null\n",
      "lr_policy         Function3     null\n",
      "lrate             FMat          1\n",
      "mask              FMat          null\n",
      "matrixOfScores    boolean       false\n",
      "max_grad_norm     float         -1.0\n",
      "mixinInterval     int           1\n",
      "naturalLambda     float         0.0\n",
      "nesterov_vel_decay  FMat          null\n",
      "nNatural          int           1\n",
      "npasses           int           2\n",
      "nzPerColumn       int           0\n",
      "pauseAt           long          -1\n",
      "pexp              FMat          0\n",
      "pstep             float         0.01\n",
      "putBack           int           -1\n",
      "r1nmats           int           1\n",
      "reg1weight        FMat          1.0000e-07\n",
      "resFile           String        null\n",
      "rmask             FMat          null\n",
      "sample            float         1.0\n",
      "sizeMargin        float         3.0\n",
      "startBlock        int           8000\n",
      "targets           FMat          null\n",
      "targmap           FMat          null\n",
      "texp              FMat          0.50000\n",
      "trace             int           0\n",
      "updateAll         boolean       false\n",
      "useCache          boolean       true\n",
      "useDouble         boolean       false\n",
      "useGPU            boolean       true\n",
      "useGPUcache       boolean       true\n",
      "vel_decay         FMat          null\n",
      "vexp              FMat          0.50000\n",
      "waitsteps         int           3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mpredcats\u001b[39m: \u001b[32mFMat\u001b[39m =    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mmm\u001b[39m: \u001b[32mLearner\u001b[39m = BIDMach.Learner@54c2c0e7\n",
       "\u001b[36mmopts\u001b[39m: \u001b[32mGLM\u001b[39m.\u001b[32mLearnOptions\u001b[39m = BIDMach.models.GLM$LearnOptions@18119d55"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predcats = zeros(testcats.nrows, testcats.ncols)\n",
    "val (mm,mopts) = GLM.learner(traindata, traincats, GLM.maxp)\n",
    "mopts.what"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important options are:\n",
    "* lrate: the learning rate\n",
    "* batchSize: the minibatch size\n",
    "* npasses: the number of passes over the dataset\n",
    "\n",
    "We'll use the following parameters for this training run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus perplexity=81528.088805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:16 INFO: pass= 0\n",
      "00:19:17 INFO:  1.00%, score=-0.50000, secs=0.5, samps/s=16427.1, gf= 4.9, MB/s=17.62, GPUmem=0.886633\n",
      "00:19:17 INFO:  2.00%, score=-0.02578, secs=0.6, samps/s=27491.4, gf= 8.7, MB/s=29.06, GPUmem=0.886633\n",
      "00:19:17 INFO:  3.00%, score=-0.02423, secs=0.7, samps/s=34782.6, gf=11.2, MB/s=36.57, GPUmem=0.886633\n",
      "00:19:17 INFO:  4.00%, score=-0.02123, secs=0.8, samps/s=43156.6, gf=14.2, MB/s=45.34, GPUmem=0.886633\n",
      "00:19:17 INFO:  5.00%, score=-0.02148, secs=0.9, samps/s=49197.9, gf=16.4, MB/s=51.70, GPUmem=0.886633\n",
      "00:19:17 INFO:  7.00%, score=-0.02072, secs=1.0, samps/s=54337.5, gf=18.3, MB/s=57.13, GPUmem=0.886633\n",
      "00:19:17 INFO:  8.00%, score=-0.02275, secs=1.2, samps/s=58469.5, gf=19.7, MB/s=61.38, GPUmem=0.886633\n",
      "00:19:17 INFO: 10.00%, score=-0.02079, secs=1.3, samps/s=61912.2, gf=21.0, MB/s=65.11, GPUmem=0.886633\n",
      "00:19:17 INFO: 11.00%, score=-0.02122, secs=1.4, samps/s=64748.2, gf=22.0, MB/s=68.01, GPUmem=0.886633\n",
      "00:19:18 INFO: 12.00%, score=-0.02124, secs=1.5, samps/s=67198.9, gf=22.9, MB/s=70.20, GPUmem=0.886633\n",
      "00:19:18 INFO: 14.00%, score=-0.01956, secs=1.6, samps/s=69264.1, gf=23.6, MB/s=72.15, GPUmem=0.886633\n",
      "00:19:18 INFO: 15.00%, score=-0.01604, secs=1.7, samps/s=71098.3, gf=24.2, MB/s=73.79, GPUmem=0.886633\n",
      "00:19:18 INFO: 17.00%, score=-0.01926, secs=1.8, samps/s=72707.5, gf=24.8, MB/s=75.23, GPUmem=0.886633\n",
      "00:19:18 INFO: 18.00%, score=-0.01616, secs=2.0, samps/s=74093.0, gf=25.3, MB/s=76.62, GPUmem=0.886633\n",
      "00:19:18 INFO: 19.00%, score=-0.01942, secs=2.1, samps/s=75362.3, gf=25.8, MB/s=77.86, GPUmem=0.886633\n",
      "00:19:18 INFO: 21.00%, score=-0.01935, secs=2.2, samps/s=76500.2, gf=26.1, MB/s=78.68, GPUmem=0.886633\n",
      "00:19:18 INFO: 22.00%, score=-0.01776, secs=2.3, samps/s=77526.1, gf=26.5, MB/s=79.70, GPUmem=0.886633\n",
      "00:19:18 INFO: 24.00%, score=-0.01736, secs=2.4, samps/s=78455.8, gf=26.8, MB/s=80.55, GPUmem=0.886633\n",
      "00:19:19 INFO: 25.00%, score=-0.01787, secs=2.5, samps/s=79270.7, gf=27.1, MB/s=81.46, GPUmem=0.886633\n",
      "00:19:19 INFO: 27.00%, score=-0.02167, secs=2.6, samps/s=80045.5, gf=27.4, MB/s=82.25, GPUmem=0.886633\n",
      "00:19:19 INFO: 28.00%, score=-0.01949, secs=2.8, samps/s=80727.3, gf=27.7, MB/s=83.07, GPUmem=0.886633\n",
      "00:19:19 INFO: 29.00%, score=-0.01993, secs=2.9, samps/s=81354.8, gf=27.9, MB/s=83.78, GPUmem=0.886633\n",
      "00:19:19 INFO: 31.00%, score=-0.01999, secs=3.0, samps/s=81934.2, gf=28.1, MB/s=84.32, GPUmem=0.886633\n",
      "00:19:19 INFO: 32.00%, score=-0.01648, secs=3.1, samps/s=82470.9, gf=28.3, MB/s=84.92, GPUmem=0.886633\n",
      "00:19:19 INFO: 34.00%, score=-0.01744, secs=3.2, samps/s=82969.4, gf=28.5, MB/s=85.46, GPUmem=0.886633\n",
      "00:19:19 INFO: 35.00%, score=-0.01929, secs=3.3, samps/s=83433.7, gf=28.6, MB/s=86.04, GPUmem=0.886633\n",
      "00:19:19 INFO: 36.00%, score=-0.01944, secs=3.4, samps/s=83867.2, gf=28.8, MB/s=86.49, GPUmem=0.886633\n",
      "00:19:20 INFO: 38.00%, score=-0.01960, secs=3.5, samps/s=84296.6, gf=28.9, MB/s=86.97, GPUmem=0.886633\n",
      "00:19:20 INFO: 39.00%, score=-0.01814, secs=3.7, samps/s=84676.3, gf=29.1, MB/s=87.33, GPUmem=0.886633\n",
      "00:19:20 INFO: 41.00%, score=-0.02070, secs=3.8, samps/s=85055.6, gf=29.2, MB/s=87.67, GPUmem=0.886633\n",
      "00:19:20 INFO: 42.00%, score=-0.01609, secs=3.9, samps/s=85390.9, gf=29.3, MB/s=88.04, GPUmem=0.886633\n",
      "00:19:20 INFO: 43.00%, score=-0.01814, secs=4.0, samps/s=85728.6, gf=29.5, MB/s=88.40, GPUmem=0.886633\n",
      "00:19:20 INFO: 45.00%, score=-0.01705, secs=4.1, samps/s=86047.6, gf=29.6, MB/s=88.76, GPUmem=0.886633\n",
      "00:19:20 INFO: 46.00%, score=-0.01696, secs=4.2, samps/s=86329.2, gf=29.7, MB/s=89.00, GPUmem=0.886633\n",
      "00:19:20 INFO: 48.00%, score=-0.01646, secs=4.3, samps/s=86616.0, gf=29.8, MB/s=89.29, GPUmem=0.886633\n",
      "00:19:20 INFO: 49.00%, score=-0.01876, secs=4.5, samps/s=86888.2, gf=29.9, MB/s=89.58, GPUmem=0.886633\n",
      "00:19:21 INFO: 50.00%, score=-0.01600, secs=4.6, samps/s=87127.9, gf=30.0, MB/s=89.88, GPUmem=0.886633\n",
      "00:19:21 INFO: 52.00%, score=-0.02060, secs=4.7, samps/s=87355.8, gf=30.0, MB/s=90.15, GPUmem=0.886633\n",
      "00:19:21 INFO: 53.00%, score=-0.01864, secs=4.8, samps/s=87554.7, gf=30.1, MB/s=90.41, GPUmem=0.886633\n",
      "00:19:21 INFO: 55.00%, score=-0.01700, secs=4.9, samps/s=87780.0, gf=30.2, MB/s=90.68, GPUmem=0.886633\n",
      "00:19:21 INFO: 56.00%, score=-0.01863, secs=5.0, samps/s=87977.7, gf=30.3, MB/s=90.92, GPUmem=0.886633\n",
      "00:19:21 INFO: 57.00%, score=-0.01703, secs=5.1, samps/s=88183.8, gf=30.3, MB/s=91.15, GPUmem=0.886633\n",
      "00:19:21 INFO: 59.00%, score=-0.01828, secs=5.3, samps/s=88381.0, gf=30.4, MB/s=91.39, GPUmem=0.886633\n",
      "00:19:21 INFO: 60.00%, score=-0.01735, secs=5.4, samps/s=88569.8, gf=30.5, MB/s=91.62, GPUmem=0.886633\n",
      "00:19:21 INFO: 62.00%, score=-0.01599, secs=5.5, samps/s=88750.9, gf=30.6, MB/s=91.80, GPUmem=0.886633\n",
      "00:19:22 INFO: 63.00%, score=-0.01576, secs=5.6, samps/s=88924.7, gf=30.6, MB/s=91.94, GPUmem=0.886633\n",
      "00:19:22 INFO: 65.00%, score=-0.01434, secs=5.7, samps/s=89107.2, gf=30.7, MB/s=92.03, GPUmem=0.886633\n",
      "00:19:22 INFO: 66.00%, score=-0.01572, secs=5.8, samps/s=89267.3, gf=30.7, MB/s=92.17, GPUmem=0.886633\n",
      "00:19:22 INFO: 67.00%, score=-0.01343, secs=5.9, samps/s=89421.3, gf=30.8, MB/s=92.33, GPUmem=0.886633\n",
      "00:19:22 INFO: 69.00%, score=-0.01723, secs=6.0, samps/s=89584.4, gf=30.8, MB/s=92.47, GPUmem=0.886633\n",
      "00:19:22 INFO: 70.00%, score=-0.01664, secs=6.2, samps/s=89726.9, gf=30.9, MB/s=92.61, GPUmem=0.886633\n",
      "00:19:22 INFO: 72.00%, score=-0.01576, secs=6.3, samps/s=89864.3, gf=30.9, MB/s=92.66, GPUmem=0.886633\n",
      "00:19:22 INFO: 73.00%, score=-0.01565, secs=6.4, samps/s=89982.8, gf=31.0, MB/s=92.73, GPUmem=0.886633\n",
      "00:19:23 INFO: 74.00%, score=-0.01501, secs=6.5, samps/s=90124.8, gf=31.0, MB/s=92.77, GPUmem=0.886633\n",
      "00:19:23 INFO: 76.00%, score=-0.01778, secs=6.6, samps/s=90248.3, gf=31.1, MB/s=92.86, GPUmem=0.886633\n",
      "00:19:23 INFO: 77.00%, score=-0.01526, secs=6.7, samps/s=90367.7, gf=31.1, MB/s=93.03, GPUmem=0.886633\n",
      "00:19:23 INFO: 79.00%, score=-0.01483, secs=6.8, samps/s=90483.2, gf=31.2, MB/s=93.19, GPUmem=0.886633\n",
      "00:19:23 INFO: 80.00%, score=-0.01889, secs=6.9, samps/s=90594.8, gf=31.2, MB/s=93.30, GPUmem=0.886633\n",
      "00:19:23 INFO: 81.00%, score=-0.01395, secs=7.1, samps/s=90702.9, gf=31.2, MB/s=93.42, GPUmem=0.886633\n",
      "00:19:23 INFO: 83.00%, score=-0.01423, secs=7.2, samps/s=90807.6, gf=31.3, MB/s=93.57, GPUmem=0.886633\n",
      "00:19:23 INFO: 84.00%, score=-0.01764, secs=7.3, samps/s=90909.1, gf=31.3, MB/s=93.71, GPUmem=0.886633\n",
      "00:19:23 INFO: 86.00%, score=-0.01650, secs=7.4, samps/s=91007.4, gf=31.3, MB/s=93.87, GPUmem=0.886633\n",
      "00:19:24 INFO: 87.00%, score=-0.01498, secs=7.5, samps/s=91102.8, gf=31.4, MB/s=94.03, GPUmem=0.886633\n",
      "00:19:24 INFO: 88.00%, score=-0.01615, secs=7.6, samps/s=91195.4, gf=31.4, MB/s=94.17, GPUmem=0.886633\n",
      "00:19:24 INFO: 90.00%, score=-0.01225, secs=7.7, samps/s=91273.4, gf=31.4, MB/s=94.27, GPUmem=0.886633\n",
      "00:19:24 INFO: 91.00%, score=-0.01454, secs=7.8, samps/s=91360.9, gf=31.5, MB/s=94.35, GPUmem=0.886633\n",
      "00:19:24 INFO: 93.00%, score=-0.01362, secs=8.0, samps/s=91457.3, gf=31.5, MB/s=94.41, GPUmem=0.886633\n",
      "00:19:24 INFO: 94.00%, score=-0.01237, secs=8.1, samps/s=91539.7, gf=31.5, MB/s=94.47, GPUmem=0.886633\n",
      "00:19:24 INFO: 95.00%, score=-0.01512, secs=8.2, samps/s=91619.8, gf=31.6, MB/s=94.56, GPUmem=0.886633\n",
      "00:19:24 INFO: 97.00%, score=-0.01148, secs=8.3, samps/s=91697.8, gf=31.6, MB/s=94.63, GPUmem=0.886633\n",
      "00:19:24 INFO: 98.00%, score=-0.01330, secs=8.4, samps/s=91773.7, gf=31.6, MB/s=94.70, GPUmem=0.886633\n",
      "00:19:25 INFO: 100.00%, score=-0.01312, secs=8.5, samps/s=91762.4, gf=31.6, MB/s=94.69, GPUmem=0.886469\n",
      "00:19:25 INFO: pass= 1\n",
      "00:19:25 INFO:  1.00%, score=-0.01669, secs=8.6, samps/s=91839.1, gf=31.7, MB/s=94.80, GPUmem=0.886469\n",
      "00:19:25 INFO:  2.00%, score=-0.01562, secs=8.7, samps/s=91924.9, gf=31.7, MB/s=94.90, GPUmem=0.886469\n",
      "00:19:25 INFO:  3.00%, score=-0.01608, secs=8.8, samps/s=91998.7, gf=31.7, MB/s=94.98, GPUmem=0.886469\n",
      "00:19:25 INFO:  4.00%, score=-0.01401, secs=8.9, samps/s=92066.9, gf=31.7, MB/s=95.07, GPUmem=0.886469\n",
      "00:19:25 INFO:  5.00%, score=-0.01514, secs=9.0, samps/s=92133.3, gf=31.7, MB/s=95.17, GPUmem=0.886469\n",
      "00:19:25 INFO:  7.00%, score=-0.01510, secs=9.1, samps/s=92198.1, gf=31.8, MB/s=95.26, GPUmem=0.886469\n",
      "00:19:25 INFO:  8.00%, score=-0.01798, secs=9.2, samps/s=92261.3, gf=31.8, MB/s=95.33, GPUmem=0.886469\n",
      "00:19:25 INFO: 10.00%, score=-0.01542, secs=9.3, samps/s=92322.9, gf=31.8, MB/s=95.43, GPUmem=0.886469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:25 INFO: 11.00%, score=-0.01431, secs=9.4, samps/s=92383.1, gf=31.8, MB/s=95.50, GPUmem=0.886469\n",
      "00:19:26 INFO: 12.00%, score=-0.01575, secs=9.5, samps/s=92441.9, gf=31.9, MB/s=95.52, GPUmem=0.886469\n",
      "00:19:26 INFO: 14.00%, score=-0.01429, secs=9.7, samps/s=92499.2, gf=31.9, MB/s=95.56, GPUmem=0.886469\n",
      "00:19:26 INFO: 15.00%, score=-0.01219, secs=9.8, samps/s=92564.7, gf=31.9, MB/s=95.59, GPUmem=0.886469\n",
      "00:19:26 INFO: 17.00%, score=-0.01502, secs=9.9, samps/s=92619.4, gf=31.9, MB/s=95.61, GPUmem=0.886469\n",
      "00:19:26 INFO: 18.00%, score=-0.01174, secs=10.0, samps/s=92672.8, gf=31.9, MB/s=95.66, GPUmem=0.886469\n",
      "00:19:26 INFO: 19.00%, score=-0.01562, secs=10.1, samps/s=92725.1, gf=32.0, MB/s=95.70, GPUmem=0.886469\n",
      "00:19:26 INFO: 21.00%, score=-0.01566, secs=10.2, samps/s=92785.2, gf=32.0, MB/s=95.69, GPUmem=0.886469\n",
      "00:19:26 INFO: 22.00%, score=-0.01361, secs=10.3, samps/s=92835.1, gf=32.0, MB/s=95.73, GPUmem=0.886469\n",
      "00:19:26 INFO: 24.00%, score=-0.01250, secs=10.4, samps/s=92875.0, gf=32.0, MB/s=95.74, GPUmem=0.886469\n",
      "00:19:27 INFO: 25.00%, score=-0.01380, secs=10.6, samps/s=92922.8, gf=32.0, MB/s=95.80, GPUmem=0.886469\n",
      "00:19:27 INFO: 27.00%, score=-0.01839, secs=10.7, samps/s=92969.6, gf=32.0, MB/s=95.85, GPUmem=0.886469\n",
      "00:19:27 INFO: 28.00%, score=-0.01558, secs=10.8, samps/s=93006.9, gf=32.1, MB/s=95.91, GPUmem=0.886469\n",
      "00:19:27 INFO: 29.00%, score=-0.01669, secs=10.9, samps/s=93051.8, gf=32.1, MB/s=95.97, GPUmem=0.886469\n",
      "00:19:27 INFO: 31.00%, score=-0.01644, secs=11.0, samps/s=93095.9, gf=32.1, MB/s=96.00, GPUmem=0.886469\n",
      "00:19:27 INFO: 32.00%, score=-0.01324, secs=11.1, samps/s=93139.0, gf=32.1, MB/s=96.06, GPUmem=0.886469\n",
      "00:19:27 INFO: 34.00%, score=-0.01417, secs=11.2, samps/s=93181.3, gf=32.1, MB/s=96.11, GPUmem=0.886469\n",
      "00:19:27 INFO: 35.00%, score=-0.01613, secs=11.4, samps/s=93222.8, gf=32.1, MB/s=96.18, GPUmem=0.886469\n",
      "00:19:27 INFO: 36.00%, score=-0.01631, secs=11.5, samps/s=93263.4, gf=32.1, MB/s=96.22, GPUmem=0.886469\n",
      "00:19:28 INFO: 38.00%, score=-0.01644, secs=11.6, samps/s=93303.3, gf=32.2, MB/s=96.27, GPUmem=0.886469\n",
      "00:19:28 INFO: 39.00%, score=-0.01570, secs=11.7, samps/s=93342.3, gf=32.2, MB/s=96.30, GPUmem=0.886469\n",
      "00:19:28 INFO: 41.00%, score=-0.01768, secs=11.8, samps/s=93380.6, gf=32.2, MB/s=96.33, GPUmem=0.886469\n",
      "00:19:28 INFO: 42.00%, score=-0.01376, secs=11.9, samps/s=93418.2, gf=32.2, MB/s=96.37, GPUmem=0.886469\n",
      "00:19:28 INFO: 43.00%, score=-0.01563, secs=12.0, samps/s=93447.3, gf=32.2, MB/s=96.40, GPUmem=0.886469\n",
      "00:19:28 INFO: 45.00%, score=-0.01511, secs=12.1, samps/s=93468.2, gf=32.2, MB/s=96.43, GPUmem=0.886469\n",
      "00:19:28 INFO: 46.00%, score=-0.01438, secs=12.3, samps/s=93496.3, gf=32.2, MB/s=96.45, GPUmem=0.886469\n",
      "00:19:28 INFO: 48.00%, score=-0.01442, secs=12.4, samps/s=93523.9, gf=32.2, MB/s=96.47, GPUmem=0.886469\n",
      "00:19:29 INFO: 49.00%, score=-0.01642, secs=12.5, samps/s=93551.0, gf=32.3, MB/s=96.51, GPUmem=0.886469\n",
      "00:19:29 INFO: 50.00%, score=-0.01397, secs=12.6, samps/s=93577.6, gf=32.3, MB/s=96.55, GPUmem=0.886469\n",
      "00:19:29 INFO: 52.00%, score=-0.01878, secs=12.7, samps/s=93596.4, gf=32.3, MB/s=96.58, GPUmem=0.886469\n",
      "00:19:29 INFO: 53.00%, score=-0.01640, secs=12.8, samps/s=93614.8, gf=32.3, MB/s=96.62, GPUmem=0.886469\n",
      "00:19:29 INFO: 55.00%, score=-0.01460, secs=12.9, samps/s=93640.1, gf=32.3, MB/s=96.66, GPUmem=0.886469\n",
      "00:19:29 INFO: 56.00%, score=-0.01681, secs=13.1, samps/s=93665.0, gf=32.3, MB/s=96.70, GPUmem=0.886469\n",
      "00:19:29 INFO: 57.00%, score=-0.01534, secs=13.2, samps/s=93682.4, gf=32.3, MB/s=96.73, GPUmem=0.886469\n",
      "00:19:29 INFO: 59.00%, score=-0.01614, secs=13.3, samps/s=93706.5, gf=32.3, MB/s=96.77, GPUmem=0.886469\n",
      "00:19:29 INFO: 60.00%, score=-0.01514, secs=13.4, samps/s=93737.1, gf=32.3, MB/s=96.82, GPUmem=0.886469\n",
      "00:19:30 INFO: 62.00%, score=-0.01421, secs=13.5, samps/s=93753.4, gf=32.3, MB/s=96.83, GPUmem=0.886469\n",
      "00:19:30 INFO: 63.00%, score=-0.01382, secs=13.6, samps/s=93776.3, gf=32.3, MB/s=96.84, GPUmem=0.886469\n",
      "00:19:30 INFO: 65.00%, score=-0.01289, secs=13.7, samps/s=93798.8, gf=32.3, MB/s=96.82, GPUmem=0.886469\n",
      "00:19:30 INFO: 66.00%, score=-0.01437, secs=13.9, samps/s=93821.0, gf=32.4, MB/s=96.84, GPUmem=0.886469\n",
      "00:19:30 INFO: 67.00%, score=-0.01231, secs=14.0, samps/s=93842.8, gf=32.4, MB/s=96.86, GPUmem=0.886469\n",
      "00:19:30 INFO: 69.00%, score=-0.01569, secs=14.1, samps/s=93864.2, gf=32.4, MB/s=96.87, GPUmem=0.886469\n",
      "00:19:30 INFO: 70.00%, score=-0.01545, secs=14.2, samps/s=93885.3, gf=32.4, MB/s=96.88, GPUmem=0.886469\n",
      "00:19:30 INFO: 72.00%, score=-0.01433, secs=14.3, samps/s=93820.8, gf=32.4, MB/s=96.78, GPUmem=0.886469\n",
      "00:19:30 INFO: 73.00%, score=-0.01419, secs=14.4, samps/s=93841.9, gf=32.4, MB/s=96.78, GPUmem=0.886469\n",
      "00:19:31 INFO: 74.00%, score=-0.01405, secs=14.6, samps/s=93869.1, gf=32.4, MB/s=96.76, GPUmem=0.886469\n",
      "00:19:31 INFO: 76.00%, score=-0.01659, secs=14.7, samps/s=93889.5, gf=32.4, MB/s=96.76, GPUmem=0.886469\n",
      "00:19:31 INFO: 77.00%, score=-0.01392, secs=14.8, samps/s=93915.9, gf=32.4, MB/s=96.81, GPUmem=0.886469\n",
      "00:19:31 INFO: 79.00%, score=-0.01389, secs=14.9, samps/s=93941.9, gf=32.4, MB/s=96.85, GPUmem=0.886469\n",
      "00:19:31 INFO: 80.00%, score=-0.01755, secs=15.0, samps/s=93967.5, gf=32.4, MB/s=96.88, GPUmem=0.886469\n",
      "00:19:31 INFO: 81.00%, score=-0.01285, secs=15.1, samps/s=93992.8, gf=32.4, MB/s=96.91, GPUmem=0.886469\n",
      "00:19:31 INFO: 83.00%, score=-0.01328, secs=15.2, samps/s=94011.5, gf=32.4, MB/s=96.95, GPUmem=0.886469\n",
      "00:19:31 INFO: 84.00%, score=-0.01656, secs=15.3, samps/s=94036.0, gf=32.4, MB/s=96.98, GPUmem=0.886469\n",
      "00:19:31 INFO: 86.00%, score=-0.01534, secs=15.5, samps/s=94060.2, gf=32.4, MB/s=97.04, GPUmem=0.886469\n",
      "00:19:32 INFO: 87.00%, score=-0.01404, secs=15.6, samps/s=94084.0, gf=32.4, MB/s=97.09, GPUmem=0.886469\n",
      "00:19:32 INFO: 88.00%, score=-0.01505, secs=15.7, samps/s=94107.5, gf=32.5, MB/s=97.14, GPUmem=0.886469\n",
      "00:19:32 INFO: 90.00%, score=-0.01145, secs=15.8, samps/s=94130.7, gf=32.5, MB/s=97.17, GPUmem=0.886469\n",
      "00:19:32 INFO: 91.00%, score=-0.01384, secs=15.9, samps/s=94153.5, gf=32.5, MB/s=97.19, GPUmem=0.886469\n",
      "00:19:32 INFO: 93.00%, score=-0.01270, secs=16.0, samps/s=94176.0, gf=32.5, MB/s=97.20, GPUmem=0.886469\n",
      "00:19:32 INFO: 94.00%, score=-0.01155, secs=16.1, samps/s=94198.2, gf=32.5, MB/s=97.21, GPUmem=0.886469\n",
      "00:19:32 INFO: 95.00%, score=-0.01443, secs=16.3, samps/s=94220.1, gf=32.5, MB/s=97.23, GPUmem=0.886469\n",
      "00:19:32 INFO: 97.00%, score=-0.01092, secs=16.4, samps/s=94241.7, gf=32.5, MB/s=97.25, GPUmem=0.886469\n",
      "00:19:32 INFO: 98.00%, score=-0.01268, secs=16.5, samps/s=94263.0, gf=32.5, MB/s=97.27, GPUmem=0.886469\n",
      "00:19:33 INFO: 100.00%, score=-0.01214, secs=16.6, samps/s=94247.5, gf=32.5, MB/s=97.25, GPUmem=0.886469\n",
      "00:19:33 INFO: Time=16.5800 secs, gflops=32.52\n"
     ]
    }
   ],
   "source": [
    "mopts.lrate=1.0\n",
    "mopts.batchSize=1000\n",
    "mopts.npasses=2\n",
    "mopts.autoReset = false\n",
    "mm.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus perplexity=115510.898502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnn\u001b[39m: \u001b[32mLearner\u001b[39m = BIDMach.Learner@7673c34c\n",
       "\u001b[36mnopts\u001b[39m: \u001b[32mGLM\u001b[39m.\u001b[32mPredOptions\u001b[39m = BIDMach.models.GLM$PredOptions@65dcb612\n",
       "\u001b[36mres10_1\u001b[39m: \u001b[32mFMat\u001b[39m =      0     0     0     0     0     0     0     0     0     0     0     0...\n",
       "   772  1544  2316  3088  3860  4632  5404  6176  6948  7720  8492  9264...\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (nn, nopts) = GLM.predictor(mm.model, testdata)\n",
    "\n",
    "nn.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpredcats\u001b[39m: \u001b[32mFMat\u001b[39m =   2.0390e-31           0  1.5414e-32  1.5414e-32  8.0951e-15           0...\n",
       "   0.0069917  1.4453e-14  1.7498e-11  1.7498e-11  6.0095e-05  1.4591e-22...\n",
       "     0.99655  7.0360e-21  3.1158e-16  3.1158e-16  1.6628e-08  4.7719e-14...\n",
       "  5.6964e-30           0  5.4361e-32  5.4361e-32  1.4166e-14  2.2035e-35...\n",
       "           1  2.9218e-13  5.2180e-22  5.2180e-22  1.1321e-11           1...\n",
       "  3.5295e-31           0  2.7782e-32  2.7782e-32  4.4355e-15  6.3061e-35...\n",
       "  1.8177e-13           1           1           1     0.99800  3.0332e-12...\n",
       "  1.9986e-21  8.0684e-29  5.0547e-13  5.0547e-13  4.0137e-11  3.1115e-28...\n",
       "  2.1465e-16  1.6936e-22     0.99995     0.99995  1.0668e-10  1.1596e-21...\n",
       "  2.9865e-31           0  2.1006e-32  2.1006e-32  8.4742e-15           0...\n",
       "  3.9151e-19  4.6547e-23  8.9845e-13  8.9845e-13  1.0123e-05  1.4977e-25...\n",
       "  3.4177e-31           0  2.9459e-32  2.9459e-32  1.2208e-14           0...\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mlacc\u001b[39m: \u001b[32mFMat\u001b[39m =   0.98791\n",
       "  0.94737\n",
       "  0.98871\n",
       "  0.96870\n",
       "  0.96625\n",
       "  0.96013\n",
       "  0.93866\n",
       "  0.97810\n",
       "  0.96912\n",
       "  0.98057\n",
       "  0.96011\n",
       "  0.97962\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mres11_2\u001b[39m: \u001b[32mFMat\u001b[39m = 0.98791,0.94737,0.98871,0.96870,0.96625,0.96013,0.93866,0.97810,0.96912,0.98057,0.96011,0.97962,0.97085,0.99176,0.98625,0.98874,0.98233,0.99716,0.98351,0.98043,0.95906,0.95426,0.98515,0.97096,0.98793,0.94792,0.93681,0.92882,0.98124,0.98269,0.97228,0.98429,0.99772,0.95660,0.98502,0.96457,0.96581,0.99553,0.99811,0.99591,0.99275,0.99189,0.99962,0.98083,0.97553,0.99280,0.99150,0.98238,0.97193,0.97771,0.99442,0.98789,0.99539,0.98273,0.99306,0.98761,0.98649,0.99820,0.99124,0.99280,0.99141,0.99478,0.98766,0.99785,0.99401,0.99833,0.98296,0.99802,0.99846,0.99828,0.99824,0.98731,0.99863,0.99383,0.99254,0.99146,0.99668,0.99556,0.99850,0.98990,0.99471,0.99729,0.99785,0.99608,0.99599,0.99776,0.99897,0.99280,0.99763,0.99923,0.99837,0.99941,0.99742,0.99712,0.99811,0.99945,0.99932,0.99984,0.99988,0.99971,0.99988,0.99997,0.99997\n",
       "\u001b[36mres11_3\u001b[39m: \u001b[32mFMat\u001b[39m = 0.98607"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predcats = FMat(nn.preds(0))\n",
    "val lacc = (predcats ∙→ testcats + (1-predcats) ∙→ (1-testcats))/preds.ncols\n",
    "lacc.t\n",
    "mean(lacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have the accuracy scores for both Naive Bayes and Logistic regression, we can plot both of them on the same axes. Naive Bayes is red, Logistic regression is blue. The x-axis is the category number from 0 to 102. The y-axis is the absolute accuracy of the predictor for that category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAGQCAYAAABYs5LGAABD/ElEQVR42u2deXBVZZr/e/alZqpmampm/pr5Z5aa5Z/+1UxN1VRNTSfpVqyYtNq0EBFcsGOjCShLI2IjCAroSLs3SUSMWxtxS2K0XVpRRI1rtLWVRoSwRVkTQUCI5Pnd77k513OP59wt23tzP5+qA/fe3OR+73vOeb/P87zve863DAAAAIqeb9EEAAAAGDoAAABg6AAAAIChAwAAAIYOUNBJ861v5bRl+71S5je/+Y0tWbLE/u3f/o12AcDQATD08diGAIChA4yJGY30741HlJkvXrzYPvjgA9oFAEMHKC5DB9oTAEMHGOcZen9/v11//fX2j//4j/ZHf/RH9k//9E9200032cDAQMbfG66fffnll3bZZZfZX//1X9vv/d7vpb33448/tlmzZtm///u/25/92Z/ZH/7hH9rf//3f25QpU6yzsxNDB8DQATB0n5qamsjx5EsvvXRUDD38+T733Xef/fEf/3HsePfv/u7v2nXXXYehA2DoAMVv6EOdFPfwww+nva7x5c2bN3vbv/zLv+RszL/zO79TsKH/3d/9nW3YsMGrFPi8+eabXrbuv+d///d/bcuWLXbw4EGbNm1a2u+3trZi6AAYOkBpG/qECRNizfHRRx/N2ZjDpfJ8DH3dunXf0Hv22WenvefXv/516md79uxJ+9l3vvMdDB0AQwcobkMf6u/91V/9VdrrMkufzz77bFQMPfiZPn/7t3+bc/Dy53/+5xg6AIYOUNqGHixraztx4kTqZ8ePHy/I0POdTKf3h/n93//9nA19KEaMoQNg6ADjMkPft29fQRl6cAz9wIEDBU+Y8/mbv/mbtPf09PQ41Z4AgKEDOGXop512WtrrTz75ZOpn2cbQ/+Iv/iLtZ319fd7rv/rVr4Zs6GeeeWbae9asWYOhA2DoABh63O+FTfvb3/62ffLJJ97672zXOv+v//qvtJ+tWrXKPv30U/uf//mfIRv6yy+/7GX9/ntUSXjsscfs8OHD3vbOO+/Yz372M/uP//gPDB0AQwfA0EXcOvRLLrkk4+89+OCDkb83c+bMIRu6uOOOO3IaSx9qG3JddwAMHWBcGLrWf69cudL+4R/+wbsSm64Yp+x39+7dab+jEnuYW265xXv/H/zBH3i/f/PNNw/pCnNhtFzt4osvtn/+53+2P/3TP/UMXjPgtVRt0aJF9t5772HoABg6AGTi7rvvTjO4U045hUYBAAwdwFU05n3vvffajh07vGVrO3futDvvvNP+8i//Ms3Qn3nmGRoLADB0AGdPxCylZ92wZfXq1TQUAGDoAC6ju5ZpAty//uu/2p/8yZ9449SaVf7f//3ftnDhQtu6dSuNBAAYOgAAAIYOAAAAGDoAAABg6AAAAIChAwAAYOgAAACAoQMAAACGDgAAABg6AAAAhg4AAAAYuqt0dXWlPdclNZcsWeLkdvnllzurDX20HfpoO/btyG833ngjhh7Hiy++mPb8ggsuKBqt6Bs/+mg79i362Le5IFPH0HPcIYq4XGXbtm1OtyX6aDv00XbsWwzdGUPPt7EAAAAwdDJ0Imn00XbsW/SxbzH0kTB0xtDRhzb00Xboc1Ubhk6Gjj4iffShDX1k6KVl6IyhAwCAq2DoZOjoI9JHH9rQR4Y+dpSVlaW2XBgYGLCGhgarqqqy6upqa2pq8l7Lx9AZQ0cf2tBH26HPVW1Fn6Hnaujt7e1WW1trPT093qbHHR0dZOjoI9JHH9rQR4ZeTIZeV1dnnZ2dqed6XF9fn5ehM4YOAACuUjKGXllZaX19fannvb29XvmdDB19RProQxv6yNCLyNDLy8utv78/9VyPKyoqIt+rm7LIzFtaWtJer6mp8V73d5T+d+V5+H/0DZ++rVu32cmTI/f5v/1tt331VfzPW1tbY3//hRdesl/NftQ+/+zImLVfJn3D/Vzf9733doyYvvXrX7RPPumO/fnTT79iH3wQ//nPPbfBtmzptqNHzXvfI4+8Za+/vssOHDD79a932BNPdNr77++ww4fNPvxwu/38549k/Lxf/OJd7++NVHs+cv/rGX/e3Nw87Ptz8+Zu27vXEm39qa1evSmn82PXLrOOh7bbvctesWef/TTRZqqy7rbbbmuzl1/ebe++a3bvvQfshhu2ec+PHMmu55NPttlTT71qr722K7FvzFpXvWsPXfWsPdv4jr25bqv9cuVGe/SqX9rzN220N25/3V6eeZ89f2mzvbjoCXtjxa/s1UvX2rN199kz1663DXf82h65YoPdu+Ale/zGLntu9cd2z4wn7cE5z9pT17xoG1dssM7aBlt/yV32yoJ19s6ix6zzJw/Ycw88O6ztS4ZOhp43O7b22xNTW2zPZwPjPtKX0c6fb7ZixfB9lg6rRx81u+OO5N9OxIl2/vlmP/2p2Z23HbOP626ydx/d4plCnDbN53zllYSuGYlg4Owae+Kq18as7X7zm+2xP1MM/fzzw/M5J06Y3bDkiP3flLft8cct1T757FsZqcw1CnUPN176iV114W5bu9bsrbfMjh0zO3Qouc90I6spU5L7TAFemC+/NGubus4em/Sg3Xpup624YJNdNXWbLT9/k625cKO1TnvEtk2ab7+ZfI29fs5N1nnOzdY9aZ49NO8N73fDbNxotv/sGfbzaa9aY6N5phP1uVHo+ND758wxu+uu5PH27LNm991ntq75iLXOecm6albYwNmTrGnVIQt0jWl0du7yzLKtzexnPzObNk39oNkll2iSsNnkyWZz55qtXGnW1GT2f/+n+UrJTZ95002JY/pOs+XLza6esdfWT/q5PTr5IXtp2p3226lLbXvi+y9cmPyuOtf8dtTztXPet7cnX29dk1fY/po66580xU4ktmdnttvC+f1WW2s2depJb38sWzpgT17+rL09/Q57YkaHNU95xtad85g9NK3Dls056H2GdNfVmV02a8B+en4iuJp0n70zeaVtm/pT+7LmfDs2+Xz7/NxLbd/0+bb3wvn2+ZQZdvDcmbZrxjLbMev/bPdFi2zHJctt24IGb9t18RLbeely2335DfZZ3VL7YkqtfX5evR24eIEd+PGVdujci+3Aj+bbp3NusJ3zb7XdP7rats651bYsvtc2X/ML++3SFju4aQ8ZeiGGzhh6OupkAwWLnDl40GzpjB6vI7j2kl22b5+NWzwDuSFptLNnD8/fVId84YVJc/jVr8w+/jjZgR3att/233K/nZg23T6d9hPrPecSu2zqfps3L9ERXm12zz2WyCbMXnop2VGqE/vpFSfsy7o5dvLa5fbkjx7z/l4uHb0O44cfTpqU7hD8xhvJ1wtBp9S0ycc9ffv3p3/Ohg3Jjv/ccy2R2VpMNczsyitlupk/JxF/26Ir++3T6Qtt4NyptmZVn110kdlDD5mXrcm89H3eveIXtnv6T73Pe/11BRuWyMCS79P3lpbzzktkex1mx4+n67jk4q/s8AX1NjDlXNs950Z74Cdddu6UAe93mpftsG03PmIDtRfbhxff5AVjwTbTsbJ0aSJYuGBOMvqTs+nA0Yepn5EbPvhgctOOUjSWcK2TP7vZts1Y6Rnv7t1fHyP33psww4s/tK+m/8j6Z82xjtZ+W7DA7JxzzK64Inn8rFljdv31SbN99VVLZP7JfXn//WYzZpgt/MkJ+/Siq2z7FXfY1rm32yf1P7PPJ9faiXPOs76rbrCjz2ywgcsutyd/3u215S9/mfxs7ccnnjDv8yZNSrZbIlG3F15ISH7pK9vz5nY79NTLdqJhrZ2ceZl1bxvwPldBlt4r7dpk8Dp2tS/efjvRNs3tdvLSRFusW5d8UZ3Qeed7v6vf+9GPzH7yk2RwqwBg6w0PW//cK5Jf6tNPkw3e05OMHmbNSkZcitAUPcycmXDqy5LtLrGJKOLLRdfZl/Vz7avzpyfasdYOz7rSvqibbyfPu8BO1s20gWuvM7v7bpVKkn9nHDBuDT38elviqB/qLPdLLonv1Z97Lnl8FUOGLhNRx6CTWB3xzp1f/+yLL5LH9+23Jx8H+fzzZJT75s0bPYfbvuhOu/RSs88+G9kMXR2vOuzRbD+ZrDpoZRgKfPQ9t28f+ufI5BYvDr2o9EEdvzoi1SKFjs2EEXS/vT/Rfx32fqSs8bbbklpk7l5nJIEJVz22ZKW3P7u7M3/+L36R7AvV4WofL1uWzDpXrbLYLC0OlUEXXbjDBibX2GMNe7xARX9TfbWyNvmZjiV9JfW1+uyg4esrSrM+W99JQYpeU58dNEsZdv2Mfuu5bGXSGAfduWfXSbvmmqQBqB97aPkW+3LKdPvynAvsoZt2e8GYvPTii/u9z5ZpHz1w1HZsPuYZ4sUXJ81QGawCjwM3rk1GcEr9dUInHG3gggtt4KLaZGqnnZD4QydX3eR9N507fhVHv3bzTQPJ/ZiHOXT/9remVLPz4R1eW8jj9J2uS3jNV4uXJl1UJjXYeApQPvggGaTIgHWMKrhQs6gNlEHr++z+sC95XCla0g5RXybXf+SR9BNbjZ8ILrQvdVxOnWo2fbrZ6tWJAOHNo3ZSf1A7UztIDS2HVyegD1RUqINJB3UuqNHCnaQij8EOROe4goBU80mEygpRqGyQ+N0BdWQ66DZvzvzZilKefDIZdeR7oBdB1bToDT24Dj1qPXr4eXAdurbGxsa816GXl8+Nfa8yOJ3zhWS9w1PGzW3NozIJnY86t3UeqZ/48Y+T5TN1cOqPrroq2QGrg5aJ6H3qA5QtKrj2XtSDxC+9+OQX3jkZDAry1afsS51QHOo7pGu02k/nvvpB9Sf+IaKsJ2hIQdavT2ZHuWTHysTUF6VQ5qGGjqoDD5r6a1GBp/6IXEg7RmWTRC+sMqX617hS9MsvJw1OJeTwMaHvpgxJ/pEL+hv6W+/f87Yd0QGU+OCjew55f0f7Ktxv6/06rtT3Sq4yMPmNH7/4JeLbF++1tskP2IU1Rz1j0Vc879yvrHfhDcm0VO6pN197bWqHePtIO0069MFKL5XFRR176vBUq00c1Ap+dExrn3z5wivJL6TB13AJIvhlFG0kzM0/Hx57zOzWW5NJ+cnuHckdkO9xpwwzYazq/1UN8LL/jzYlOxR9XxmQds6WLTlGCd1JA/ZO1iyoYiBjHkT+6Ze+9XeOaScoktWOktNqDCKIjFQdQNSYQTj6UwcTHjPQPlW1IgoFEorm4kjoeVM7wFFYh+74Dvn2t6/++mAPoPNNhqgoXZnPaKAsO1M0GBerKKtQUhcuA6sP9DvXYHldfab8RpufkXi1uI8+SvbOra1eMqOxNGUW6h/U/4UNPlO0qn5HmYGXdYZQB+OPfRUa8G7alExMNDdKsYiMRZlpcF/6+vbsSfb3ylaCbagfR43Q6D3qpxQAZRvfVOVQTZeG2lDi4kiY+UkdXOr01SnqA+WO6kSVqvmoA0+YjTIceV1Yi7xAGeCOHYOllhgfUDlXvqg4I1NQqGRL+1o7r0+RzwMPJF/UDzNUWvyKgI6rb5xLikTkkvouiajgq6uvsd572+3QFdcmT67gL6gN5Paq5cpMlN6rjYSiapVgB8s6qWNPUaxe1/tkkInnas6BnbuSjZPrASaTS0ShCkS1axQQeF9b6bVKKPlmcdKvgyhhnKnsVDsxOIaiaC31QRlQFqrvou+aa8no5pujf5b4zC9UAsjGLbckqyaZ0OC9ouIwMuSoTlNtok4hqsMd4yyYDH2cGPp3vrPE6z/CqKKlKF0no/rZ4SgP6/iXEUXx5pvJknlcxqiOU1mSzrFgx67ypzrrfIeLFJSnzFwdik40/a8DVl84cdIpi3/nna/HKjXRKzimGofO14bpr9tX0y7wDDNo6mrHwWTKtOCg0GBJnqkKitpUya76XWlUFr5nT7rxq1995pfRzqzAIhxIKYGTScuoMvmyHwdpXDctO1fnm212l1xapVE1kBxEZtTQkP4edcqJ41W7RX6jt6i9ZOAKzLSbdNx4ZqeyaUyHr/2hY1m/HzWEpGNBbaeqiRfwKNX2B+H1i8q4MlS+9PdV0fgGagNFWhoY9jt0CZCR+5lqGJWrJVTm9/Ofp/9MDa3gwNfit/XWrcnn+l/tqdlm2rG5liaE0vHBHakENVXB1T6JmyyQDR2Yajv/jyqoCX9n/TzupPfNUSm+xhZyRZGegqG47D2XLF8nug66uBNe30MnsqobYXSSf2MMypIJg0o4gKGPlKFPnDjfC0bDLFpkKaPX8anOM1zWzAeZsAxZfbcyZ9+U1TepOqa/LyPROeSfI8FoUP2K+kFlzDpXdc6qI1b/leqk9QeyRL+x6W4wzdQBpOwhom9RP5stWlWC8PCcV7zBv943NqdMXd9LfbWCEL9ip2CkkMlb2j/vvRefzKji99hj+7zP88rhykoUtKij1y/L+RMdqfo2DaMGs3NVBRXIqGKu34+rEOq4UFCRpj9bdh7VdsquJSR8gGlAVeYUqAyr79exomHQlA8oOlLnqi8eFzEOeqU8Rd9XMYCqrvJaHZN6PVVhTXzpHf4Ygt6oWVA68HKdju1HCd4U/zvz37k62PV9oo5lGUUiy+1WFKYT4ZlnvhlE6PU4Q4tDsxIVHYZRAJFrWTy8bxWFK5pUmURBUtTYsSIHRfL6zioPBCN4BXQ6ThW95YPaQAdI1ImV6ET2+lWPbOiYjMv0FUnqPIpCYxfq7MKfrwAn0zgcGTqGPlRDnzr1Iq9DCw4X+cFpsD9RZqR5LIWi/lHnpvpeeYv6G/W9/sRZLyNInDyvPtjteas+29eqyTKqKp5ctNhLz2SY6idUrUtVA9XZqkauKaVRJYdM6ARX3TpYR46IpPUR0uZXDePGk9QHfnr7I8kvmsjwNGtehiG/CSdNaodglTnX/uqyqQfsxO69kT9XoiYjnjbtRHKYQB2LMkINiiuKUEQho0l0bpqFrLb0+x7FRNpPPgoMFAMEZ08H4560uUO5ZueW41icIgnt5BDSKq9PoQNE0Z4iHH3x8Cw66dH+PXLE62v1VvX3CqYUTKb5hXZWokHS9KnkoahM2XZURhaV3SnSURWi0Kn24XHd4M5N6OuRsaukEEfUDsuEjo2wQeVYIs64bxVhSquisLjJOMretX80BqY2U8egcRKd3NnK8XHooI7KrmfNsjc0iSwX9P2lOypI1EGUqQKiDkvnWkTFaVjODUf8A0N3bIfMSRz4Cp6DCan8LVz91LmopEHZm7/cQ1lcrutmdW4GS89aqqTA3J8T5KGByER2Jz0KjhUNagzc66O7DiZr3vpQS5bY5bmpeVd6o04+vywpV8plzZNf9gs2gDphdeARs0xV7pVnqa+IilYVuOjjvS+sUqWipUS0oj5By3HCqFqh4dp8UHLQ9ePVX6+diuhw1S66uISHphF7okLGMGiWflARzM6DqIITjHf8ooaaKC1pzTE7zznS1/eS84YndYVRqu5PglLZXU6tyFHRjJ+C+4uMdWAnvruOxciEWxHNypXf1OdHEYp0w1lxGB13apxCzTwb11xjJzU7O9eTL9cAQm0dPJZ03CiIGUoWJ0PWcar5CNlQhUbjUDrPM5Xhc3OBb44TKshJaOnONCktjPa5jpvgOJY/wSjTpLko89YxETZ5MnQMfTgNfUlVlZdlBSbQello1AxneYCSVy2LUd8tg1dQrWpdzJykVKCr4z/8nuA54h3o+oMJI1bGJBNXiVTZu0zP+0dZT9yyPNXdtS7G73yVWipi0B/JJZoPz57T56jMGkG49B7qa5NZq6INuZ5KxhlMTt9VbZhPIiKP2n7l6uTgvqoAape0aeYhNBbrNWLILJV9JXaO9qdkKtENZufBCqI0KmlSAUTNpSHrtEBEmWuO2XneHXOm7ya0M4KD4wpyZCI6nhQZ+im4OmLtPJm7DDGq0WU8mYISfU9FQPobcciUsk2oGgqqhORb1smFcHldMy6D4zGFoiApW1AWNvahogpUWhlnsAMLB7bZUNSnpZQK5PwhA50w2aJwnW/BKFgZSFQZHjD04TT0q//f/7NjRwe8/k3HnPoK9YO5Hncah1TSI8OWt/jjw0FkcFmvSqasRlmt3CLRaaoPOP/8k97ELE+LOlHNYgtPFPJRGS08w0yduT8hKQ6VWPWFw2g8T5lCROlTXihza25OX5alwF/9vJfkqEHUMan8OzjJLg61W+D6QFnRKqLjl8//uoIgM1O7haabp2YbD1YJvoHenwg61ATqr5Swh7Pz4D5UEUN9ovxRXpj2lfTLcftmKJG+MrVsk5gU/YXHWZWCx7W5DiiNI0SZonZGV1dmfWpTVZPiMrRwgFEsmZLK3cEymsbD4pZfuZ5hqtQfPvdVFkxkzgXpU8KhaFf7VuX0DHM1PNQRBoftFJTmaExk6Bh6wYa+8D//05vmrGVfWqqlbDtcXs0FBQM61qMqdEqcI+aYpSMzl6krIxjMbmbP7k2uuvFnj4UnrwXRbORwiUt1Z6WWmUpj6rDiJgdoMlRMdqhq3uTJA973VTKvj9KQpldAkJEH7zOvv5PBsTV84U8GzoYKCRdfNJhdB8dJVf4IzWDz9rU6sWD5JZzFDHbgWqKmrWCixq7zOA5jkTHGlUP8fazPzhcFgOEOX0Y/GIhl1afSUVyWrGNuhC/0MSJjmfqbwUlgUZWrsdKWLzpvw8vTtMQs0cEVrE/ZupIKnXvZUCIQnH+gqk/UEjdX288hbRh6Hjtkwemne0s5VErX3BUlWtmCz0zHu/w2eJ1rf7gp6xwdzRrTDC1/6U0wGvTXd6mcq5MkqnygWnDU2Jgmr2QaS1c5bfBGF99AmWGGsT/dYEL9hhJTfUdV+L2EXg0YjM41rpvhoFQ1UhWS8FXs4goZv1jRncwwozpkZRGD7eO1n8YA4oIJ7SiNnQwmwlkuMpg5e9Gku5GI9BUcqXHiSkbBoZZ8UCkqOBtQDF5gJSd9mhEeVZrX381Ujnc5Uwp8f2+SSCGBkisZpj+nJogC20RHN2R9uV5pS52p/1maQPPaa8XTfmToxWnoS1Q+mjvXO0bVbxa6jMonOGlMyCQGPSOecOchswpOSAtegUUdTvgKIYokBseDIyP1TEt4ZLxR4wR+2SxqUDnmHFdQ5KFFycGLcShKl3nsSN7RygtMVMMOLBPSkuxclvuqCvBRw4vRy2m04zRTWaUW4dfS4zogZdTDcUF3ZfnhWZTDicYY4q5Rq8lwhU6g0nhqcN/rsnOZZo4H0c6OCiT0N7QzixUdLxq+GJwcWLToXAj3CVF9x0iijs9PJnT+j+ebRGDobhj65aqzykwTEa18bzju1aLERTPVhcaas16URvX4YM1Zdf81a5LRoLLdoOmok0m7koklM/u4m9L4M9aj1tL6F5SJKx/ICDWRJWaiV2y0KoMJZ2+qMMhAVMLQbGL/WueDJTm9XVIyVa31VdTfHmtoTk7MiULGp/2ZyGx7VVLONIcgMDFuSKgKkudYa16Rvq4b6gcpUZ/92muFH6jB8aXmr9s1qz4NcagsE45+mzPsm2LIlPwLzOh4LfASpM5kmDrf/Ivu+CXwxP4aNX2K0DXbNM9hITJ0DL1gQ79AnZJqxoksSwFkvtdwiPMJBQfqD3LK+DWWG6z3qlyWSPNf0uCyDCnYsQSXKPkom1DHHodK6lETtjKNyftoHC5mglPseJKCk/BVy3QiqLNURujPrg7c2EFFBsU1qm5o2DsKxSTeSjMd4FFXlQmayurVdjSXa2UrsNAVrApFwqOWMOR5HGZEZh5X5gncCCNvNFSg3/cP0MC4eE76VDnwqy4+mcbWR/A8Hjb8C8xo3keBl4d0ZgxYE4NUMRH+hXhGU5+qjPpMBUh53KuYMXQMvfAMXeVtlQ9zub5xHijTVECsibNZkUuFx78XLbI9/q2rghNz5HrhkqbGur2LcGfJpsKD1Fpwn+3KTQomYpbuxEarWsydywQxGVWoxCt/UNFEMU54VVVKij+DPg5VFBLt1q9oKhsKmAoePB/stPJdCpRvpL8j5gYh4cmHhaBjT0sbFZiocjJYjclJnyoHwauf+RWP4V66N5qZktarKigJtEXRZuiaXOsvH1RyMDgMNmr6/AqgJsPlcrlZMnQMfaiG7jWWSq4ZSsuFoonnWVfv+Oszw1f5UEepLCF89Srf8YLI4LNNo9eYc/hOKfo9P4IfLsOKGruLQwGGJi6E1uhqN6hPVXk9mOxpV32wfm+y7JENdSIynGyoo9OOKhRFGamL4o8QalPNOPRvru2jKsVQx4jU0Uq/hiqiJhpmQuOjwcqBOrvhusn8WKHStNbwF/v38IN/P2DWEELc5NeRRBm6qoBx60EBQx/2DF1o0DvXuxkVii45Fr5iTdyypITRD2gduNaTBlEWpA4nmL7qO4RLn2FU6tZ6c2WjMnZtMtO0q9tEoEBD74vIiCOjVY1bhGfXZkLl+ZhZ+JqEruF/jSYo4Vfcc+KVN3KerJRTNF2IkaWfbQV1VnlH+lG3/VMHPdRgQseNZqUHMric9elKdMG5G9qPuQRRrmdKChijLmtYbBlm8EIy6mMGLwk9qvo0WVQBfh5DUmToGHrBhn6BX7JURhzM1DQhTJ3oUC/BGETrcxWtBgfV45b/JDigpWhRpevgZBf/0pK5XG9a48UqsWsilErNud7AQuNfEROvIseTlDXGXGEuEl3HVZWIGPT1NDKgmMLzDpUQtYyvgH0dG7BElYk1mSfbTSw0mVCl2bjrjg9VWzhQUskieFs9ZV9pF5MvEAU0uhZBoIKTkz4dx8E150O5M9lIt1++WWW+1yMeLW354F+LXvtJQfbg0N2o6tOcBJ0jxdh+jmjD0AvJ0DUbTh2mOnhls3pddV9F63HlY3Wo6vjjlhQF0cQl/S3tnGDpSyara0bnEw0GLyIjw4+4gcewoss4Rtw1K1KfOvScJg4EKg7heQIxiaQ3OqDMKcfLyuUcTevqOMF9IINSR5itU1fwEnfHqZGI9GWYwWAm6gYYhaC/qepN4DLBOesL3Ha0kDuTFX0W7Lo2Gbn6p8BlV0dVn277mme1g32LoRds6GmNpQ5JpXedBP6iapln1MVVNLbsz5BX6qiypX437r7F/qVdlWnJwGTEfgSd7x2VgqVWuZxms47sUZx7WVrZf76TzFQ1yPGmJl47FzqrO5Pm4LXeNS6s+QW67m4m8pzsM2Q0PKKgU3MOMt0iM180IVMXp8/3DmVCcwg0FOAfy7ledARGB0321fmY4/UkwD0w9EIydD/b0FhTsISqbE0GHMyE1JnKxFNXUrHkz9XwgftXp6FJabrgilCZVFm1LvqiKkC+0aDGbH2ziVrzPdz4C8BDa/oi9eliI/nevlVLaqJmcYdRuTnTVdMKjaaDl/zUUj4FdP7N2zOh4ZMCl7wVHOlrjFr7W1WkAu4EFolMWKXRQLvmrE+VDf9GPKNoGmRxeQTLCvgDy1Zdbjv27Tgy9IFEh9LQ0GBVVVVWXV1tTU1N3mvx/fvhRFK83HvvGWecYXfrMqZ5GvoFuSz70dhicFxYmXZUWVnlxrhMVuYQvFKSyvXqkDNc3zh2vEZXlvNvqBJ1oZmRQJPXQuO1kfoU6ORyz+wwmrkfcbvWNDShMMN4e87tF8ZfFqbhFs1b8FcMKIjRTWqi0Az9wIVxhhpY5ox/V7eoa7GPYOAbi7J6Zea6mMwI6hm29is1bRoCU/IQqEC53Hbs23Fk6O3t7Qmfqk30WT3epscdGcq3KxNmtnTp0kTieNDb9MWfCi/NyidDjyPY0avErd+JK0+qJKzZv2HDCF/JTdmm7liV4ftljAb9tdi6LGwhBlpIx6AoX5eO1ATCFStsQB15cLmdMj19p0JMTsGYJiPpb2vYQm0YNlNNUsvjzjk5R9MKGlW+1t8PnjwqV8bdulTj+P7lAEc70tcwkC5BqJnpLmQiyszVVqPY2ZHF5YgujqOJi4HjmAydDH1UqEuYU2dgwpMe18dd0jTB97///USf/3WnL1OfqYlCeRh6zo2lCUPKipW1Zbpoiq58Ei6BK8iIKsUroy9k3FIoU5Xxxd2sZbhRaVnL6DSxT2PMupybhguCpqJhh1xK53HtK6NSO2nYQ5+jDDhY5tfPR8rEVDZWOT8YjGmeQtzaXVVXIiYKjgpq58mTC7+L0HCjY16mMRwT9GB4UTVP8yMOHKAtipSiNfTKykrrC9x2UWat8nuuhp7t/QVn6D7K0rPdaUXGF74QSwHX+s4aDaq8KcPJdenZcBCa8NejttQNH/yJUG+8Mbw3tFDGrADNv9NN8O5NI5Fl6nZ76QdL9E1gktFn5svPjnSkryGf4BK2scxENDdEwd5oBJZkcfmhc9MfTiJDJ0MfTcrLyxPHX3/gWOy3ioqK2Pdr/PzaRDYnI9e2bNky++53vxvjRV2embeE1jDXJDoive7vKP0f+1w3Nti6NfP7Ez8/nsj0dg5eIm7bJ59YfyKL3jF4QZmMfz/0PPx/8Of7danXRJZ+OGGgOesf5uf6/+iiRbb5ttuSP29rs88Tj4fz8w7ce68dvegi26X2TLRj95Ytw9J+4efdqhAcP57+8+5uO1Ff/433v/rUU3ZycHJeod+vdTDzH839NVL63nrkETs2OCHORX2j/by5udm5/Ym+4Xmu4260P79kMvRDhw55Jq5JcWeddZbdf//99oMf/GDkMvR8sie/VKuyuq5tPtzRoMqtuiXhKNzZKqM+XeBG5XENHWiddPDa3sOFhiz0XfO8HOeQo+moq/IJzaXQhVjGaRaCPtoOfWToQybfMfQwip6WZVk7XPAYej5oIorGZJOikhO+hhutRVaZM98lYiOBZsCrPK5x/ZG605bGqzXkMdpo+CR84xwFLlkmXwIAlLShtyWyzUyz3MvKytLer3L73r17veVrzz//vE2aNMl2ZLmm+ahk6MrsNHlOY78KMHR505GIBnXDDq3hHutoVRPJtCxPm0OTb4YlmtacCV1UPojG9bNdO58siSwOfezbUjb04Dp0bY2NjWnr0MOGriVqEydOtAkTJiQSqXm2Ods6ZitwHXohaImXghHN1A7dTSxXimq9qC5eoQDDVX2FovW7waVyCtK0DnyIE8BYCzx+9dF27FsMfYx2yIhk6EKlcJVrh3D1rKKKpDXpL5fbmhZbNB2+mI2W64Xu4U6WhD7ajn2LoTtg6CMyhi78i6zkcSEUcBBdvCdYxVHl5ZlnaBcAwNBLJkMXuprXL39JJF3s+lR58O8Gp3X3w3ABFfYtWRz62LcY+jAb+oiNoY+AVvSNkT5d4lUXzZGpa/kcbYc+2o59i6GXWIZOJD0+9OmOdg8/nLzsbNyV42g79NF27FsMfWwNfcTG0GH88OqrybX2usue7msPAIChk6ETSRehvt27k3fL033Sdbc52g59tB37FkN3z9AZQ0dfVrTmXJeAHcZleezb8auPtmPfYuhk6ETSLuvT3dWuu462Qx9tx77F0F01dMbQISe0BFG3rAUAwNDJ0Imk0UfbsW/Rx77F0EfI0BlDRx/a0Efboc9VbRg6GTr6iPTRhzb0kaGXlqEzhg4AAK6CoZOho49IH31oQx8ZemkZOmPo6EMb+mg79LmqDUMnQ0cfkT760IY+MvTSMnTG0AEAwFUwdDJ09BHpow9t6CNDHzsGBgasoaHBqqqqrLq62pqamrzX4ujp6bErr7zSe782PdZr+Rg6Y+joQxv6aDv0uaqtaA29vb3damtrPVPWpscdHR2x76+rq7M1a9bY4cOHve3OO+/0XiNDRx+RPvrQhj4y9DFEZtzZ2Zl6rsf1um1lDBMmTLAjR46knuuxXsvH0BlDBwAAVylaQ6+srLS+vr7U897eXq+UHsfixYtt7dq19sUXX3gZ+l133eW9RoaOPiJ99KENfWToY0h5ebn19/ennutxRUVF7Pv37dtnkydPtrKyMm/T4/3790e+t6uryzPzlpaWtNdramq81/0dpf9deR7+H33jR19ra6tz7YW+4Xne3Nzs5PmAvqE/13E32p9fMhn63LlzvXHz4Bi6XiNDRx+RPvrQhj4y9DGEMXQAAIBxYOhtbW0ZZ7mrrB4OADRuHszQMwUAZOjoQxv6aDv0kaGPAsF16NoaGxvT1qGHDX3nzp02f/58O/30073tiiuusN27d+dl6KxDRx/a0Efboc9VbVwpjgwdfUT66EMb+sjQS8vQGUMHAABXwdDJ0NFHpI8+tKGPDL20DJ0xdPShDX20Hfpc1Yahk6Gjj0gffWhDHxl6aRk6Y+gAAOAqGDoZOvqI9NGHNvSRoZeWoTOGjj60oY+2Q5+r2jB0MnT0EemjD23oI0MvLUNnDB0AAFwFQydDRx+RPvrQhj4y9NIydMbQ0Yc29NF26HNVG4ZOho4+In30oQ19ZOilZeiMoQMAgKtg6GTo6CPSRx/a0EeGXlqGzhg6+tCGPtoOfa5qw9DJ0NFHpI8+tKGPDL20DJ0xdAAAcBUMnQwdfUT66EMb+sjQx46BgQFraGiwqqoqq66utqamJu+1OMrKyr6xVVZW5mXojKGjD23oo+3Q56q2ojX09vZ2q62ttZ6eHm/T446Ojpx//6WXXrLVq1eToaOPSB99aEMfGfpYUldXZ52dnannelxfX5/z78+YMcP27duXl6Ezhg4AAK5StIaucnlfX1/qeW9vr1d+z4VXXnnFrr/++qzvI0NHH9rQR9uhjwx9hCkvL7f+/v7Ucz2uqKjIOTvv7u6O/XlXV5dn5i0tLWmv19TUeK/7O0r/u/I8/D/6xo++1tZW59oLfcPzvLm52cnzAX1Df67jbrQ/v+QydJXmFy5cmNNnkKGjD23oo+3QR4Y+whQ6hq7fe//99wsydMbQAQDAVYrW0Nva2jLOcteytDBvvfWWZ+i5QoaOPrShj7ZDHxn6CBNch66tsbExbR16lKHPmjXLNm7cWLChsw4dfWhDH22HPle1caU4MnT0EemjD23oI0MvLUNnDB0AAFwFQydDRx+RPvrQhj4y9NIydMbQ0Yc29NF26HNVG4ZOho4+In30oQ19ZOilZeiMoQMAgKtg6GTo6CPSRx/a0EeGXlqGzhg6+tCGPtoOfa5qw9DJ0NFHpI8+tKGPDL20DJ0xdAAAcBUMnQwdfUT66EMb+sjQS8vQGUNHH9rQR9uhz1VtGDoZOvqI9NGHNvSRoZeWoTOGDgAAroKhk6Gjj0gffWhDHxl6aRk6Y+joQxv6aDv0uaoNQydDRx+RPvrQhj4y9NIydMbQAQDAVTB0MnT0EemjD23oI0MfOwYGBqyhocGqqqqsurrampqavNcysWXLFps3b56ddtppNnHiRHvqqafyMnTG0NGHNvTRduhzVVvRGnp7e7vV1tZaT0+Pt+lxR0dH7Pt37txpkyZNsueee84OHTpke/bssWXLlpGho49IH31oQx8Z+lhSV1dnnZ2dqed6XF9fH/t+mffjjz8+pAiLMXQAAHCVojX0yspK6+vrSz3v7e31yu9xnHXWWbZ27Vqv1K4S/fLly+3w4cNk6Ogj0kcf2tBHhj6WlJeXW39/f+q5HldUVMS+Xz+77rrrPOPXtnTpUlu5cmXke7u6ujwzb2lpSXu9pqbGe93fUfrflefh/9E3fvS1trY6117oG57nzc3NTp4P6Bv6cx13o/35JZOh6/16T/D9Z5xxBhk6+oj00Yc29JGhjyX5jqHPnDkzzdAPHjyYt6Ezhg4AAK5StIbe1taWcZZ7WVlZ2vu1RO3aa69NK7lff/31ZOjoI9JHH9rQR4Y+lgTXoWtrbGxMW4ceNnShSXHKygudFMc6dPShDX20Hfpc1caV4sjQ0Uekjz60oY8MvbQMnTF0AABwFQydDB19RProQxv6yNBLy9AZQ0cf2tBH26HPVW0YOhk6+oj00Yc29JGhl5ahM4YOAACugqGToaOPSB99aEMfGXppGTpj6OhDG/poO/S5qg1DJ0NHH5E++tCGPjL00jJ0xtABAMBVMHQydPQR6aMPbegjQy8tQ2cMHX1oQx9thz5XtY2qoesOZ4cOHSJDJ5JGH22HPtqOfVvMhq47oP3whz+0N998sygNnTF0AABwlVE19IULF3qmXl5ebrfccot9+eWXZOhE0uij7di36GPfFpuhi3fffddmzJjhGfu0adPso48+KhpDZwwdfWhDH22HPle1jcmkuIGBAXv++eftnHPO8Yw9vJGhE0mjj7Zj36KPfVskhv7CCy8UnaEzhg4AAK4ypiX3qVOnFlXJnQwdfWhDH22HPjJ0S58Ud/PNNw9pUpyy/IaGBquqqrLq6mpramryXoujkEoAY+joQxv6aDv0FYu2ol221t7ebrW1tdbT0+NtetzR0ZHxs8nQ0Uekjz60oY8MfRgMfTgvLFNXV2ednZ2p53pcX18/oobOGDoAALhK0V76tbKy0vr6+lLPe3t7vfJ7JkM/44wzbMKECXbhhRfao48+aidPniRDRx+RPvrQhj4y9LFE4/D9/f2p53pcUVGR9fdOnDhhmzZt8rL522+/PfI9XV1dnpm3tLSkvV5TU+O97u8o/e/K8/D/6Bs/+lpbW51rL/QNz/Pm5mYnzwf0Df25jrvR/vySydDD7NmzJ+v7ydDRhzb00XboI0MfYfIdQw+zd+9eO+uss/IydMbQAQDAVYrW0Nva2jLOcg9PgtOEvK1bt3ql+e7ubps7d67deuutZOjoI9JHH9rQR4Y+lgTXoWtrbGxMW4ceNvT169fb9OnT7ZRTTrEpU6bYmjVr7Pjx43kZOuvQ0Yc29NF26HNVW9Ea+ljsEDJ09KENfbQd+sjQx4GhM4YOAACugqGToaOPSB99aEMfGXppGTpj6OhDG/poO/S5qg1DJ0NHH5E++tCGPjL00jJ0xtABAMBVMHQydPQR6aMPbegjQy8tQ2cMHX1oQx9thz5XtWHoZOjoI9JHH9rQR4ZeWobOGDoAALgKhk6Gjj4iffShDX1k6KVl6Iyhow9t6KPt0OeqNgydDB19RProQxv6yNBLy9AZQwcAAFfB0MnQ0Uekjz60oY8MvbQMnTF09KENfbQd+lzVhqGToaOPSB99aEMfGXppGTpj6AAA4CoYOhk6+oj00Yc29JGhjx0DAwPW0NBgVVVVVl1dbU1NTd5ruTBr1iwrKyvL29AZQ0cf2tBH26HPVW1Fa+jt7e1WW1trPT093qbHHR0dWX/v6aeftrq6uoIMnQwdfWhDH22HPjL0YUam3NnZmXqux/X19Rl/59ChQzZp0iTbsWNHQYbOGDoAALhK0Rp6ZWWl9fX1pZ739vZ65fdMrFq1ylpaWrzHZOjoI9JHH9rQR4buAOXl5dbf3596rscVFRWx7//www+9rN4fZ89k6F1dXZ6Z++bvU1NT473u7yj978rz8P/oGz/6WltbnWsv9A3P8+bmZifPB/QN/bmOu9H+/JLJ0GXm27dvTz0nQ0cfkT760IY+MnQHyHcMXQYeteVj6IyhAwCAqxStobe1tWWc5Z7NrMnQ0Uekjz60oY8M3QGC69C1NTY2pq1DHwlDZx06+tCGPtoOfa5q40pxZOjoI9JHH9rQR4ZeWobOGDoAALgKhk6Gjj4iffShDX1k6KVl6Iyhow9t6KPt0OeqNgydDB19RProQxv6yNBLy9AZQwcAAFfB0MnQ0Uekjz60oY8MvbQMnTF09KENfbQd+lzVhqGToaOPSB99aEMfGXppGTpj6AAA4CoYOhk6+oj00Yc29JGhl5ahM4aOPrShj7ZDn6vaMHQydPQR6aMPbegjQy8tQ2cMHQAAXAVDJ0NHH5E++tCGPjL00jJ0xtDRhzb00Xboc1Ubhk6Gjj4iffShDX1k6KVl6IyhAwCAqxStoQ8MDFhDQ4NVVVVZdXW1NTU1ea/F0dnZabNmzbJTTjnFJk6caCtWrLCDBw+SoaOPSB99aEMfGfpY0t7ebrW1tdbT0+NtetzR0RH7/tmzZ9uGDRvs8OHDduTIEbvnnnu81/IxdMbQ0Yc29NF26HNVW9Eael1dnZd1BzPw+vr6nH//6NGjNmHCBDJ09BHpow9t6CNDH0sqKyutr68v9by3t9crv+fCsWPH7IEHHrAFCxbkZeiMoQMAgKsUraGXl5dbf39/6rkeV1RUZP29srIybzvzzDNt165dZOjoI9JHH9rQR4ZerBm6xtDvvvtub5JcFF1dXZ6Zt7S0pL1eU1Pjve7vKP3vyvPw/+gbP/paW1uday/0Dc/z5uZmJ88H9A39uY670f78kh1Dl6mfdtppZOjoI9JHH9rQR4Y+lrS1tWWc5a6yepDly5dbd3e3V5rfs2eP3XLLLYyhAwDAuGFcrEPX1tjYmLYOPWzo69evt+nTp9v3vvc9mzRpkq1atcoOHTpEho4+In30oQ19ZOjjHdahow9t6KPt0Fcs2jB0MnT0EemjD23oI0MvLUNnDB0AAFwFQydDRx+RPvrQhj4y9NIydMbQ0Yc29NF26HNVG4ZOho4+In30oQ19ZOilZeiMoQMAgKtg6GTo6CPSRx/a0EeGXlqGzhg6+tCGPtoOfa5qw9DJ0NFHpI8+tKGPDL20DJ0xdAAAcBUMnQwdfUT66EMb+sjQS8vQGUNHH9rQR9uhz1VtGDoZOvqI9NGHNvSRoZeWoTOGDgAAroKhk6Gjj0gffWhDHxl6aRk6Y+joQxv6aDv0uaoNQydDRx+RPvrQhj4y9NIydMbQAQDAVYrW0AcGBqyhocGqqqqsurrampqavNfieP3112327Nl26qmn2sSJE+2GG26wzz//nAwdfUT66EMb+sjQx5L29narra21np4eb9Pjjo6O2PfPmzfPOjs77ejRo9bb22urVq2yBQsW5GXojKGjD23oo+3Q56q2ojX0uro6z6B99Li+vj7n3z9y5IhVVlaSoaOPSB99aEMfGfpYIjPu6+tLPVfWrfJ7rmzcuNFmzZqVl6Ezhg4AAK5StIZeXl5u/f39qed6XFFRkdPvbt682c4++2z7+OOPydDRR6SPPrShjwy9GDP0rq4uz8zfe++9jO+Rmbe0tKS9XlNT473u7yj978rz8P/oGz/6WltbnWsv9A3P8+bmZifPB/QN/bmOu9H+/JIaQ3/hhRe8Ge4fffRRTp9Bho4+tKGPtkMfGfoI09bWlnGWe1lZWdr7161bZ5MmTbLu7u6cP4MxdAAAKBbGxTp0bY2NjWnr0MOGrudRm5axkaGjj0gffWhDHxn6OIZ16OhDG/poO/QVizYMPY8dQoaOPrShj7ZDHxn6ODB0xtABAMBVMHQydPQR6aMPbegjQy8tQ2cMHX1oQx9thz5XtWHoZOjoI9JHH9rQR4ZeWobOGDoAALgKhk6Gjj4iffShDX1k6KVl6Iyhow9t6KPt0OeqNgydDB19RProQxv6yNBLy9AZQwcAAFfB0MnQ0Uekjz60oY8MvbQMnTF09KENfbQd+lzVhqGToaOPSB99aEMfGXppGTpj6AAA4CoYOhk6+oj00Yc29JGhl5ahM4aOPrShj7ZDn6vaMHQydPQR6aMPbegjQy8tQ2cMHQAAXKVoDX1gYMAaGhqsqqrKqqurrampyXstjrKystRGho4+In30oQ19ZOiO0N7ebrW1tdbT0+NtetzR0ZH194Zi6Iyhow9t6KPt0OeqtqI19Lq6Ouvs7Ew91+P6+voRNXQydPShDX20HfrI0IeZyspK6+vrSz3v7e31yu8jaeiMoQMAgKsUraGXl5dbf39/6rkeV1RUkKGjj0gffexb9JGhk6En6erq8sy8paUl7fWamhrvdX9H6X9Xnof/R9/40dfa2upce6FveJ43Nzc7eT6gb+jPddyN9uczhk6Gjj4iffShDX1k6GNHW1tbxlnuccbNGDoAAIxHxsU6dG2NjY1p69DDxh1ch57renQydPShDX20HfrI0McBrENHH9rQR9uhr1i0Yehk6Ogj0kcf2tBHhl5ahs4YOgAAuAqGToaOPiJ99KENfWTopWXojKGjD23oo+3Q56o2DJ0MHX1E+uhDG/rI0EvL0BlDBwAAV8HQydDRR6SPPrShjwy9tAydMXT0oQ19tB36XNWGoZOho49IH31oQx8ZemkZOmPoAADgKhg6GTr6iPTRhzb0kaGXlqEzho4+tKGPtkOfq9owdDJ09BHpow9t6CNDLy1DZwwdAABcBUMnQ0cfkT760IY+MvTSMnTG0NGHNvTRduhzVRuGToaOPiJ99KENfWTopWXojKEDAICrFK2hDwwMWENDg1VVVVl1dbU1NTV5rw3X+8nQ0Yc29NF26CNDHwXa29uttrbWenp6vE2POzo6hu39UYbOGDr60IY+2g59rmorWkOvq6uzzs7O1HM9rq+vH7b3k6GjD23oo+3QR4Y+ClRWVlpfX1/qeW9vr1dOH673Rxk6Y+gAAOAqRWvo5eXl1t/fn3quxxUVFcP2fjJ09KENfbQd+sjQizxD7+rq8sz8iSeeSHv92muv9RqMjY2NjY3NtU0eVZSGPhpj6AAAAOMVZwy9ra0t46z1srKyvN4PAACAoY8BwXXl2hobG9PWlYcNPdv7AQAAMPQSQVm+xtZd3FpaWpzVhj7aDn20Hft25Ld3330XQ88VLmKAPrShj7ZD33hou5I39HyjH7Shj7ZDH23HvsXQAQAAAEMHAAAADB0AAABDH08UctvVkUTL8fzNNb2vv/66zZ4920499VSbOHGi3XDDDfb5558705a6mNCsWbPslFNO8fStWLHCDh486OS+ls5MSy9HW1/wuIs6/lxouy1btti8efPstNNO8/bvU0895Yy+qPbT1Std0Kfrclx55ZWpJb16rNdcabvDhw/b8uXLvc8+44wz7O677x7TY2+ofbBL/UzJGXoht10drQ7CNb3qTGWaR48e9S6tu2rVKluwYIEzbalgY8OGDV4HceTIEbvnnnu811zb108//bR3ZcPwPh5LfXHHmyttt3PnTps0aZI999xzdujQIduzZ48tW7bM2fP4pZdestWrVzuhT8famjVrvPNC25133um95krbrVy50pYuXeoF39p0idNgsDZW+grtg106FkvO0F29ZGzcweSSXplmMAtxrS0VeEyYMMEpfTIjGdOOHTu+sY/HUl82Qx/rtpN5P/7440VzHs+YMcP27dvnhD6dAzpXg+etS+fF97//fS9B8JGpz5w5c8z1FdoHu3QslpyhF3Lb1bHsYF3Su3HjRq907KK2Y8eO2QMPPJBWQXBBn6oauiBF1D4eS33SonKnOvoLL7zQHn30UTt58qQzbXfWWWfZ2rVrvVK7ypgq0SrbdPHYe+WVV+z66693Zt8uXrzYa7svvvjCa7O77rrLe82Vtgsbevjzx0pfoX2wS8diyRl6IbddHUtDd0Xv5s2b7eyzz7aPP/7YOW3++NeZZ55pu3btckbfhx9+6EXv/nhaeB+70H4nTpywTZs2eRnF7bff7ow2fdZ1113ndY7aVKJVqdbF81jZeXd3tzP7VpWCyZMnp84LPd6/f78zbafgTHcR8/etqjHf/e53x1xfoX2wS8ciGToZelZ0+1mZ+XvvvedsW6qsqMk1LlUQZObbt2+P3ccutZ/GqF3KOvT54SxOFQXX2k7l1YULFzp13s6dO9cbNw+Ooes1V9pOw1AycVVeVIm5//777Qc/+AEZOoZeWCfLGHruvPDCC17Z86OPPnK+LWXqmhHtir6omdDB/exS++3du9frXF3RpjHV8Dhr0NBdaTvpeP/99506N1wfQw/T2tqaNuGRMXQMPWdcve1q3ME0lnrXrVvnTegKlxNdaUuV7qRNJS5lmLfcckvaGLpr+9qlWwCrhL1161av7dSGyuBuvfVWZ9pOs56DZVnpDY5Tu7Bv33rrrbTZ467sW2nSuHkwQw8azFi3nfarAkhpe/7551OTRsdaX6F9sEv9TEmvQ3fhtqv5rAcebb1xGaZmk7vQluvXr7fp06fb9773Pa9T0AQ0lfNc3teu7Fu/7bSGf8qUKd4yp+PHjzvVdprYpaw8alKcC/o0vKOJoq71M1ryN3/+fDv99NO97YorrrDdu3c703YK1lT1U9VAS2M1P2cs226ofbBL/QxXigMAABgHYOgAAAAYOgAAAGDoAAAAgKEDAAAAhg4AAIChAwAAAIYOAAAAGDoAAABg6AAwZHQ5Vl1VS1f7CqOrk+lnwWt0AwCGDgAOosvs/vCHP/SMW9c193nnnXe813SHvuDlWgEAQwcAR5GR637QuiGFrl+tTY/12ttvv00DAWDoAFAs3HbbbV5G/uyzz3qbHt9+++00DACGDgDFhO7Sdt5559nkyZO9TY+Dd24DAAwdAIoA3a/8zDPPtBkzZnibHus1AMDQAaCIWLx4sVdm15i5xtT1eMmSJTQMAIYOAMXC+vXrPQOfO3du6rU5c+Z4r+lnAIChA4Dj+KV2zWjftGlT6nU9lqFTegfA0AGgCPBL7fo/zNVXX03pHQBDBwAAAAwdAAAAQwcAAAAMHQAAADB0AAAAwNABAAAwdAAAAMDQAQAAAEMHAAAADB0AAABDBwAAAAwdAAAAMHSAUT/ov/UtthLYADB0gBIwdGAfA2DoAHT2wD4GwNAB6OyBfQyAoQPQ2QP7GABDBxjbzr6srKyk2nqsvi+GDhg6AIbujMHl8t6BgQFraGiwqqoqq66utqamJu+1YjT0XN6r9/gbhg6AoQOGPm4Mrr293Wpra62np8fb9Lijo2PcGnqu78XQAUMHwNCHbGAPPvignXnmmV7GfPPNN1t/f3+kEZ04ccJuu+02O+uss7xNj/VaOBPNZF51dXXW2dmZeq7H9fX1o2rYo/l9MXQADB1g1Ax97ty5tm/fPm/T4+bm5kgjWrt2rffzvXv3etvs2bO91/LJWCsrK62vry/1vLe31yu/j6ahj+b3xdABMHSA6M5+2zazF18sbNPvRhhNd3d34M9vsylTpkQa0TnnnJP23q1bt8a+N47y8vK0jFiPKyoqYt8/zF931L8vhg6AoQNEd/ZvvGF2xx2FbfrdCKM5fvx46rken3rqqZFGpNdzfe9wZejD/HVH/fti6AAYOsCodPbhjFWPC81YlX1nw4Ux9NH8vhg6AIYOMGqGPm/evNSYsh7HjROvWbPmG2PKd911V+rnmmgWNMAo2traxnSW+2h/XwwdAEMHGDVDD876vummm1IzucNGpJLzrbfempr1rcfBkvS6deu88nkm8wquQ9fW2Ng4quvQR/v7hmfDx70XQwcMHQBDH7LBlRKufl8MHTB0AAwdQ8fQATB0AAwdQ8fQATB0ADp7YB8DYOgAdPbAPgYMHYDOHtjHABg6QHF19mzjfwPA0AEAAKDo+P8DsKOJpt9HHgAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36maxaxis\u001b[39m: \u001b[32mFMat\u001b[39m = 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val axaxis = row(0 until 103)\n",
    "plot(axaxis, acc, axaxis, lacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO 3: With the full training set (700k training documents), Logistic Regression is noticeably more accurate than Naive Bayes in every category. What do you observe in the plot above? Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll compute the ROC plot and ROC area (AUC) for Logistic regression  for category itest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlscores\u001b[39m: \u001b[32mFMat\u001b[39m = 1.8177e-13,1,1,1,0.99800,3.0332e-12,0,1,0.88480,1,0.99999,1.0970e-16,7.0726e-19,1,0.45068,3.7902e-08,1,2.3382e-20,7.5716e-07,1,1,1.7385e-10,4.2914e-15,1,1.6561e-05,1,1.9739e-22,1,4.6652e-09,1,0.99975,1,1,6.0667e-15,0.61837,1,5.4842e-08,1,1.4422e-12,3.7628e-10,0.99968,1,1,1.0000,0.99999,1,1,0.017378,1.0841e-17,1.0841e-17,2.4883e-20,1,2.4883e-20,8.3366e-13,8.3366e-13,0.0053147,1.0000,3.0660e-16,1,8.6814e-20,5.4920e-21,9.6985e-09,1,1.2030e-06,1,3.3140e-20,5.4059e-16,0.99783,0.57497,1.0000,1.1233e-06,1,1,1.0000,1,4.0598e-10,1,1,2.4461e-15,1.0000,0.99995,1,1.2981e-16,0.98611,1,0.99947,5.0567e-12,6.4540e-14,8.5891e-11,1.0000,7.0400e-08,1.0203e-14,1,1.0000,0.99993,1.0000,2.2480e-19,1.0775e-07,1.4156e-12,1.0000,0.78571,1,1,0.99977,1,0.0017367,0,1,3.0140e-15,1.0000,1,2.1137e-14,5.2942e-09,0.99996,7.0595e-21,1,1,1,1,3.5363e-17,0.037261,1,1,8.8509e-07,8.0993e-08,0.99997,1.0000,1.7241e-10,1,3.5471e-23,3.7142e-06,1,1,1.0000,5.1677e-16,2.9611e-10,9.6717e-15,1,\u001b[33m...\u001b[39m\n",
       "\u001b[36mlrr\u001b[39m: \u001b[32mDMat\u001b[39m =         0\n",
       "  0.81698\n",
       "  0.88133\n",
       "  0.91470\n",
       "  0.93009\n",
       "  0.94001\n",
       "  0.94623\n",
       "  0.95281\n",
       "  0.95661\n",
       "  0.95930\n",
       "  0.96097\n",
       "  0.96245\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mauc\u001b[39m: \u001b[32mDMat\u001b[39m = 0.97303"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lscores = predcats(itest,?)\n",
    "val lrr =roc(lscores,good,bad,100)\n",
    "val auc = mean(lrr)                           // Fill in using the formula you used before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the ROC curve for Naive Bayes earlier, so now we can plot them on the same axes. Naive Bayes is once again in red, Logistic regression in blue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAGQCAYAAABYs5LGAAA+oklEQVR42u2deVRUd5r+e/bpOTPnzJw5s/wz88dsZ2aS3qaneyan+3QDncT8CESNERA1Rg1GBYn7lri0GqN2jGsi4EYSTYhGBSTGLRq3iEtEE6PGlbigqBHEHZT3x3MrxRQElCpKuNf6fM65UreowofnFvd53+/3Lt8zAAAA8DzfwwIAAAACHQAAAAh0AAAAINABAACAQAcI6Y/me99r0nKv90UqR48etdmzZ1vbtm3tn/7pn+z73/++/dEf/ZH9/d//vcXGxtr777/PhwyAQAcg0B8E/xT2t27d4sMGQKADtFwg3e/3PYj+/e3f/q1NmTLFjh8/blevXrU1a9bYP/zDP9TxZ8KECXzYAAh0APcFOvjo3LmzXb58+TvPf/TRR3V8/bd/+zfMAiDQAbzVoVdVVdnkyZPtX/7lX+xP/uRP7F//9V9t2rRpVl1dfdf3het7N2/etBdffNH+5m/+xv7gD/6gzmuPHDli6enp9tBDD9mf//mf2x//8R/bP/7jP1pycrIVFhaGzVd16oGa9P8AAIEO4KlAT0pKanAuuW/fvi0S6PX/fz/vvPOO/emf/mmjc92///u/b6+88kpYfC0uLq7zs//sz/6MDxsAgQ7QcoHe3IPili5dWuf5//zP/7TDhw87y7//+783OZh/7/d+L+RA1/z15s2bnZECP7t27XK6df9rfvWrXzlHqF+6dMm6du1a5/25ubnN9nX48OF1fqaOgAcAAh3AM4Hepk2bRsNx2bJlTQ7m+kPlwQT6kiVLvqO3Y8eOdV7z+eef136vtLS0zvd+/etfN8vTDz/8sE7xoEWnsAEAgQ7QYoHe3Pf99V//dZ3nFZZ+zp071yKBHvh/+vm7v/u7Jhcvf/EXfxGyn3l5ec5xA/V/Zji6fgACHQBaLNDrd6aVlZW139O52KEEerAH0+n19fnDP/zDJgd6qEf7v/feew3+P0OGDOGDBkCgA3i7Q79w4UJIHXrgHPo333wT8gFzfnSueOBrSkpKwurj/PnznYPq6v8OOj8dAAh0AM8F+hNPPFHnec0n+7nXHPpf/uVf1vleeXm58/z69eubHejt2rWr85p58+aFzcMZM2Y44V3/iPlw/h8ABDoAtGig1w/tH//4x3bs2DHn/G8d8X63/+/nP/95ne9NnTrVzp49a7/85S+bHehbtmypE7oaSVi+fLlduXLFWfbs2WOvv/66/fSnPw3KP53mVv//17B7Tk4OHy4AAh3Au4EuGjsPvU+fPnd9n+agG3pfv379mh3o4o033mjSXHpz/Av3vDwAgQ4ArRboOv970qRJ9s///M/OFdJ0xTh1v2fOnKnzHg2x10fD13q97lim90+fPr1ZV5irj05X69Wrl3MpVl3sRQGvI+B1qtqoUaNs3759BDoAgQ4Ad2PhwoV1Au6xxx7DFAAg0AHciua83377bTt58qRz2tqpU6ds7ty59ld/9Vd1Al13JQMAINAB3PqHeI+hZ114Zc6cORgFAAQ6gJvRXct0ANx//Md/2Pe//31nnlpHlT/yyCM2cuRI577hAAAEOgAAAIEOAAAABDoAAAAQ6AAAAECgAwAAEOgAAABAoAMAAACBDgAAAAQ6AAAAgQ4AAAAEukspKiqqs65Lao4dO9a1S//+/dGHh2jEQzyMUA9fe+01Ar0xPvnkkzrrzz33nKf0og8P0YiHeBg5+hTqBHoTDVdF5WZOnDiBPjxEIx7iYYR6SKAHEejBmgUAANBSEOh06OjDQzxEIx7SoUdWoDOH/mDrw0M8RCMeelkfgU6Hjj48xEM04iEdemQFOnPoAADgVgh0OnT04SEeohEP6dBbj6ioqNqlKVRXV1tGRobFxcVZfHy8ZWVlOc8FE+jMoT/Y+vAQD9GIh17W5/kOvamBnp+fbykpKVZSUuIselxQUECHjj48xEM04iEdupcCPTU11QoLC2vX9TgtLS2oQGcOHQAA3ErEBHpsbKyVl5fXrpeVlTnD73To6MNDPEQjHtKheyjQo6OjraqqqnZdj2NiYhp8rW7KojDPycmp83xSUpLzvH9D6Kub1nNzc9HXzPXs7Gz0NXNd2xl9zVuv/9WN+o4fP2EbN/q+6nAk3/omO3as2G7cMDt4sNjWrt1qX3550kpKzHbuPG0rVxba7t2n7PBhs02bztqKFTttx47TzvrGjWdt+fJdVlh4puY9VvPec7Zs2W779NMzNT+rZn1Nzes/2GmFW762o/uu2oZlhy1/8VbbvuqgHax574bMnbYyY71tf3+PHVhxyPKG5tiq1z+0T+dutf3Zu2z78BxbO/4D2zn1QzswbbXt7zPNNo18x3ZNWGb7p3xoX/R63TYMW2Tbxy63okmrbV+PqbZ+yGLbNnqF7XnVt/7x4MX26ahltnfih7a/+2Tb1H++7Rqx2L4cu8SOdRtjO9Nm2d4h8+3Qy+/YiW6j7LM+023f4Ll2YMTbzvd395pmRQPn2ZfD37ZtvWfa+kVrwrp96NDp0NGHh3gYwO3bZrdumd28aXb9uvYVZhcumF28aHbunNlXX5l9/rkCzOzoUbM9e6wmdMwJoS++MNu2zWzNGt/zn32m4DLLy9M0n+91a9eaLV7se167mFWrzBYuNFu3zvc+1RuvvnrVdIjPypVWE2pmv/ud7/nly82WLjWbMMHsgw98i9bHjTN7/32zd981e/tts6FDzebNM8vIMHvjDbN+/cymTNHP9b22e3ez4cPNXhpZbWOGXrffdjtmr6adsslpJ21Kn+P2ZqfNNu25vfZ6989t+nNFtjgxz7I6b7Q3krfanMSNtqrjAluasMQWdcy1JQlLbVfHyba540z7KGGBrU2Ya18mjLW9CRNse6cZtiv5dTuRMNROJA6zg8nj7Gjn0XYhKc2+SexjZ5IH29nkgVaemGJXE7rb5aRedi2xu1UlJFt1xwS70zHR+WodOzrL7Y5JzvcqEzo7j68m9rCKTr3sStLzdqNjV7vQpb+Vdh1k5zv3t4rEnnaq+yg72XNszdfRdimpjx3t85p9lTbTDqbOspOdh9mXCtea5eCATDvTZYgdGjLPvho6zw4Pm2vnugyyI8Pn1S7+9cMjFtjhkQvtdLeRdnDEW3Zg9Hu2f8wSO9xzku0btcT2jcu1vePy7EBNeO8btdQ+fyXf9r+ab4f6zrD9o9+3LyflO8uu0Tn2zVcX6NBDCXTm0AFaBw2MVVb6wvHKFbOTJ33heP68OZ3b7t2+cDx0yBeUCikF39atvsBTKCncPvxQB7f6gmnRIjMNoOmr/iwVWllZvtcOG2Y2caKZ7iSpAKv503cCbvRos5dfNnvhBd9z+vN//nmNvJklJpolfJsb+qrnunQxe/ZZs86dfY979/a9p1cv36KfqVB88UWzvn3Nxowx++1v/+85adD/P2qU2YABPj2vv+57fsgQs1mzzGbPNps61fezMjPN5s41e/NNn87sbLO33qr5HedctoWD99vKN0/aR28etzUzD9mHL662T2bus83TdtvWqdutsPdC2zVlgxVNXmP7J620E8+Pt+IxC+zc8GlW1n+sVSV2thsp/exmSppVpvS16qROdqdzV+cXv9PlWbuTlGxVvfpaZb+BVjlgqN3u/rxVDhpmVaPHWdVvX7HbqenO4zuvT7fq2W/4zJwxw7cBVEnoF9FjVSeqSvRYFciWLb6Nqec3bPBt4AMHfJXO3r1mxcW+D8SRI1bT2ptduuT7kKjF1wfnzh2ze5yNBBEQ6PWfz6spkTnKHX0Pmofa3129aqbBJwWkhia1z1TnqGHMnTt9HaOeKyoy+/hjXzhu3+4LTD1+7z2z9et9+2HtmxUoClU9P2eOL6gUlnpeneLAgb5wmjzZF6YKSIWWglRB1qlTtRN43br5glEhmZzsC0d1hgpMhaNCMD3d9z0FnEJM3aPeq589fbovJ/Q96VAXq+5z/HjfV2lUZigY1cVKv36Pd97xdcGq31Us6LF8UI6oaFi5stTpptVtq/uWf8qOsOeGfqDafIWUwkobRIJUlegXU7u9ZImvlZaRMljG1hhxR+bJJL9xqipkvL+K6NHDZ8SkSb6NIjP1flUEqgQUuGrvtZH37/cF6OnTvl9aHxRVUPrFQ/yl+Vt2p74H4jz0hs5Hr78eeB66lsyacpjz0NHXUho1hKvQVaBoX6pF+3c1LQrXHTvMNm/2hZY6Tw2jKrQUpv79th5363bLCbyaetTpGhWO2uer09Q+Xd9TDmifP3KkLzA13KqgfOUV33MKSHWFCkwN3eo5dbbKAjVdep00KCQV6vqeQlFaFZoaLlZY7trl063OWYWEigjto959d6+TYdeu+YLSs9tYQwoKP1VC+oXVUeqXVhWkIPZ/VdutAJVxClxVLf6W39/md63phkeM8G1IhbY2iMbH9X59nTnTZ7D+nz177KA2hsb5NbTB3zL7w0jp0FvScDr0B79DP3r0hBNECqQzZ3zdrTo7/z5d4bZ6ta8zVDerfbQaI4WjhlfVOA0a5OtU1bmqQ9WiBkuhq/26Alb7fQWpwvell3xNlvbp6nT1VT9bjZyGXJUbauzUaK1efc5p9tRZqvlz42hkq25nTYCfOuWrLFRlKIBVGSk41RHXhOd1v+Fq7RXG2mCDB/s2isbUFcIKZG2sPn18iyojVT8aOlB4q7pSJ6yfq+FlVTmaNFelpiJAxQB/y2ikQ3dvoDOH3nqoUfnmG99+WvtrTbn5u0N1uOpuFbIKXO231VlqXlWBq7BVY6T9uD9w/fOn2m9r/92p0//NoWq0U52uglffU8iq+VJjpf26miftw9VF67mPPvKNbGpUU0O+OmhKxYDmiaXZjV2qq1G14p9D0MbWPKy6Y23wjRt9FY9CWhtbG7ZnT19lpE5Y1ZOGLDRJrg2nAFblpKEHdcIadtAG1Hi9/r41v6sKTV9VKZ096+uMNaQC4DEIdDr0+466SDUsOv1E3a7/mBgFrxob7VvV7OiAIg0HqwFS6GrkUkGr0NU+Wg2T9tk6wEhDypqzVcBq+Fj7eDVbapz0M7Xf1s/Vvlthqw5XXbaC/+uvfVOJCluFrjpd/xwqnVGYNapjltk6+s0/hzx/vm9+V1WR5pIVyNqY/jljVVZ6TnMI2tiqsBTO6qr1ek22672qntSBK4x1YJWGVugu0UeHTqA3JdAjfQ5dB2BdvuxrmjT8q3lWhfKKFb4Q1WdJ870amVTgyi6FsJomBXGXLlXOPlv7Zg1PK7h1xK9+joaV1WGr41bg+0NXzZr+3wfFQ8/r08bQhtHOSEPM2nA67HzBAl9VVfMhqNKwhoZA9AFQNaZFlZc6ZW1wdc+q4LTB1XHrQ6QhlxbqjJn/xcMHVR+BHsEduv8Iae2fdUCT5mx18JM6Wx3VrP2upha1L9ZQtRonBbNs0OdGU47qjtUsaZ+sA7q0f9foqP8AKXXB/kCmqne5PnW4GnbWMIYWbVQNe+iAAHXQOihAQyaq0PTBUDgrxFXBqRLTez77zM7rffpQNeMoarpLOnQ8JNDva6B7bQ5dU5AaiVTAqhHSflcHcOkAWzVQ/oBWcPv315oT1vyzgl2jojrdSaOlFRW+0VPwIJrv0ClL+iDoaDsdDKaKTZ21qjV9CPynR+lDoGEUzTlr2EVdtIZgVKFpfoIPAYBrIdA92qH75qR9xwnpmg0awezVq8oZzlZY+6ciJVkBrqlHbWsdwKX9ukK6pc+IoaoPsz4NfWheWh8CfVY1tKI5D1VnGt72fxDUUavL9p//pq7bf3K2Lm2msA7jUDfdJR6ikQ7d9YHeWnPoaor27fPth3XEtkJap0FpflpNlo4x0qUlx48/XXvBDDcepMu8WwhVm6ovHcb/7VxzmQ4S859grrDWZ1IfCHXdOopbHbiO2lbQ+4e92c58DvEwIvQR6C7t0HX2jK6OpYZKB/lqylL7cf9R2g2NfFLVe0SjhkYUtjr6Twcg+M9l1jCKzpVTZ62NropNBy/oYAV9ryawLyu41V1rCN2lFx3hc4iHaKRDd32gt8QcuobCNb3pD3E1Z5q/Bo+gjlgbUZ21glfn0WloRcPdunSnhr91YJkOXNBh/jpPT2HtP+Jb3bWGWVqhswYAb0Ogu6RD1xXJFOC62IkaNp0eRkXqYo0aItFpVgptHcSgq9jo5HkduKDzpxXguvCJTgNQSCvgNbRSWtqs8/DojPgcog8PCfQwBHq459A1z61rYyjIdcySRlObM/fNvFuYNWpoRHcz0XM6WV4HMGgYXJeRU5eto8E1lKJTB7QhddnP+3xZOOYu8RB9eEigu6xD1xlBOqZJV6bUqWFUpK2ILtyuYe6PPrIbGgLXdV79lxLVonOtNWyiAxj0mQg8uR4P+RziIRrp0L0X6OGYQ1cW+K+kFq4gh3ugg8c03K1uW5cP1Y2nFdoaFtFVzDTPofP9NGyui6Xo8qQ6iZ/7MAOAhyDQW7BD16isskOnC9+PBi+iq3qFtq7rrUuQ6so4OtBMd2PRELmGQnS6l643qwvGa95bly1VyOtiKXjI5xCNeEiHHlmB3pw59GnTfNOt9/MzFlFzRgpiXcrOP9yh64froDSd26eKSfeW1h1gdAJ/EFc3Y+6SzyEa8dCr+gj0FujQdWlrnbGkG41QkYaAAlkHnOnAAw2N6yhyDXXoSHLNbx86FLZzsumM8BCNeEiHHgGBHsocus5Y0rVC7neYP1DoQIPCQt+whq6IpmFzVUS60LyG1HWzcQAAINBbqkPX2/v08R1fRUXaiD5d3lT3YtWFVUaM8M1LqPvWJfLeestszRrfa6jq6YzwEH14+GAGenV1tWVkZFhcXJzFx8dbVlaW81xjXLlyxSZOnOi8tm3btrZQ9/oMMtCDmUNXPumMp5ZsJl07Z6Ttcu6cHVeHrQvP65q2Ojite3ff+dwvv+y7u4zC+6uvXFXEub3IRCMeog8PPR/o+fn5lpKSYiUlJc6ixwW6GXcjTKrp+MaNG2eXLl1yFv3iq3SFr/vUoesOZwr1iKxIFeAKZp0CpgPVVNn07Ws3NWyu23LqcH+dsye9LruLDJ0RHqIRD+nQW5jU1FQr1Dzrt+hxmm5q0QhPPfWUlQVMZCvU+2lyO4hAb6pZp075LiZ2ny8a5i6uXTNbtsx33XINmSvIdQW1TZs0PGIAAHB/8Wygx8bGWnl5ee26wlrD700N9Hu9vjkdum6usnTpA16RqgvXhVo0z63zvdWFqwPX0HkjBw1Q1dMZoQ8P0UiH/h2io6NrOuD/a4H1OCYmptHXa/58woQJTpBrGT9+vP3mN79p8LVFRUVOmOfo+t0BJCUlOc/7N4S+1l9fvXprTbbdMdUaDX3/fq7n5ube15//9aFD9kVNYFfoams1XfjtHj3s3KhRdnbdOue0sdbWF4717JrfD33NW8/9dq4JfaGv1/+KPvftD92oL2I69IqKCifEdVBc+/btbdGiRfb000+HvUPXvkIXKXsgKj5dzu7oUd8vpQu46NafupOMjlXQXcOo6tGHh3iIRjr05hLsHPp3gzfXCfhgAv1eZun6J7qnh66B4klu3DA7eNAX4LpMqgJc9+3Wud87dzIXDgDgYjwb6Hl5eXc9yj0qKqrO6zXcfv78eef0tY8//tgSEhLs5MmTYe3QP/3UbPRoD1V8OtJcdxBTYOuSqbqXt38eXMWS7vdNVY8+PEQjHtKh308Cz0PXkpmZWec89PqBrlPUOnToYG3atLHBgwfb4cOH7/l/BHseuk6nDhg0aHGadF6jLpGqI89VeegccN2/VddEV2d+ny/gwrmreIg+PETj/dPHleLC1KFv2+Y7W6uVbpN994pPIV5UZDZ0qFmPHr7zwzWEHsRNS6jq0YeHaMRDOvQHJtDvZpZupa2Dv11DRYXv6DxdQlWnlGn4QFdqO33aAADgwYNAD1OHriuZqglu9YqvuNgsM1PzA74bm+h3uHqVipmqHo14iId06AS6n8bm0DXMria41XJTArZssUrdlUyH2et+4AGn9LnVTy9sc/ThIRrx0Cv6CPQwdOgqtAYMaAWBOohN16PXqWUvv2xlc+e2+Lw4VT368BAP0UiH7rlAb8ws3fM8I6MFhZ09a6bwTkz0XTu9CUfsAwDAgw2BHoYOfeZMsw0b7rMYnZK3dq3vCHUdTr948XeuYENVT1WPRjxEHx06gd6EQG9sDl0j3vf14HF15DpvXBP1Gzf6TkNrgl63+4lGPEQfHuIhge6aDl3HnnXv7mugw47mw3VLUp07rqvg3eMkd6p6qno04iH66NAJ9CYEekNm7djhu+x52Nm+3Vcp6DzyMF+CFQAAHjwI9GZ26G+/7Wuiw4bOfdMRdi+8YPbee1SkaMRDPEQfHhLo4Q70hubQdQG2/fvD9B/qcPlevczmzw/puurMuz34GvEQD9GHhwT6fejQq6rMunQxu3mzmf+R7jmu66x362Z25AgVKRrxEA/Rh4cE+v0M9Ppm6fRv5XDIlJaaTZ/uG17XeW+teWcXAADwNAR6Mzp03XV03rwQf7gm3pOTzZYuDUOLT1VPVY9GPEQfHTqB3uRArz+HPnWqcwn14Nm713dxmLBNvjes1+1+ohEP0YeHeEigu6JD1/Fr588H+UO/+sqsZ0/fVypSNOIh+vAQDwn0lg/0QLMU5CkpQf7Akyd9nbk6dAAAAAK99Tt03aFUV2NtMgcP+i4Us20bFSka8RB9eIiHBLqf6upqy8jIsLi4OIuPj7esrCznucYoKSmxESNGOK/Xosd6LphAD5xD183OXnutiWJ17XXdX3XWrBYtQNxeIKERD9GHh3hIoFt+fr6lpKQ4oaxFjwt0vfNGSE1NtXnz5tmVK1ecZW5NIuu5UDv05cvN3n23iWLffNNsxgwqUqp6PEQfHqKRDr2hgC4sLKxd1+O0tLRGX9+mTRu7du1a7boe67lgAj3QrCVLfMs90S1PBw4M26lpAAAAD1Sgx8bGWrludfYtZWVlzlB6Y4wZM8YWLFhgV69edTr0+fPnO8+F2qHn5Pjm0e+Krvqmg+DuMbRPRYpGPEQfHuJhxAZ6dHS0Venaq9+ixzExMY2+/sKFC5aYmGhRUVHOoscXL15s8LVFRUVOmOcotQNISkpynteGWLTIbOHCS7Xr/g1Uu37ypN3u0cO+WLiw4e/fh/Xc3Nz7+vMfdH36mp2djb5mrms7o6956/W/oo/9YVPWI6ZDHzRokDNvHjiHrudC7dB1l7X8/Lu8eeJEDQtQkVLV4yH68BCNdOh3o7Xn0BcsMFu1qtEt5TtJPYQ7pgEAAERUoOfl5d31KHcNq9cvADRvHtih360AuFeHrmu4626njbhqtm4dFSlVPR6iDw/RSId+LwLPQ9eSmZlZ5zz0+oF+6tQpGzp0qD355JPOMmzYMDtz5kxQgR54HnrNf23r1zfwpp07Nb7fKndO49xVPEQjHqIvcj3kSnEhdug6tVx3PK3D7dtm6elm+/ZRkVLV4yH68BCNdOhuDfRAs2bONNu8ud4bNOSvg+EAAABaGAI9xA59+nSzrVsDvnnunFmPHmanT1ORUtXjIfrwEI106G4O9MA5dF3HPeAge1/LPmSIq/S63U804iH68BAPCfRW79AnTzbbtSvgmzrnfM8eKlKqejzEQzxEIx262wM90CxNldfmt843f/ZZrtcOAACtBoEeYoc+fnzAwew6VU1PUJFS1eMhHuIhGunQ3R/ogXPo8m3//m9XsrLMVq50nV63+4lGPEQfHuIhgd7qHfqoUWYHD3670revrlxDRUpVj4d4iIdopEP3QqAHmjVypNnhw+a7NWrv3gYAANCaEOghdujDhpkdO2a+O7ToOrBUpFT16MNDPEQjHbo3Aj1wDn3wYLPiYvMd7l7nhHT36HW7n2jEQ/ThIR4S6K3eoQ8YYHb6RKXvdLWA27JSkVLV4yEe4iEa6dBdHuiBZukeLN9s2Os7Og4AAKCVIdBD7NBTU2sa8zlvmX3wARUpVT368BAP0UiH7qVAD5xD14Htt9MHmB096lq9bvcTjXiIPjzEQwK91Tv0Yc9ftOoePc2qq6lIqerRh4d4iEY6dC8FeqBZn3TOstvDRhoAAIAbINBD7NBXJr9rVbMzXKWXqh4P0YiH6KND91ygV1dXW0ZGhsXFxVl8fLxlZWU5zzVGVFTUd5bY2NigAj1wDn1p0gd2e3GOqwsQtxdIaMRD9OEhHhLolp+fbykpKVZSUuIselxQUNDk92/atMnmzJkTcoe+LPF9u/P+UipSqnr04SEeopEOvTmkpqZaYcAV2vQ4LS2tye/v3bu3XbhwIahADzRrRcfFVr1suQEAALgBzwa6hsvLy8tr18vKypzh96awbds2mzx58j1f11iHrpH9lQlva5iAipSqHn14iIdopENvDtHR0VZVVVW7rscxMTFN7s6LnQuxN0xRUZET5jk5defIk5KSnOePHCm21YkL7JtFi5x1/4bR19Zcz83NdZUer+nT1+zsbPQ1c13bGX3NW6//FX3sD5uyHnEduobmR45s2ulmjXXoN2+arU+aa7ZmDRUpVT368BAP0UiH3hxCnUPX+7744ouQAt1v1tWrZpuSM2pSfb0BAAC4Ac8Gel5e3l2PctdpafXZvXu3E+hNpbEO/fJls23Js/UCKlKqevThIR6ikQ69OQSeh64lMzOzznnoDQV6enq6bd26NeRA95+HfumS2Y7OM8y2bHHVB4RzV/EQjXiIvsj1kCvFhdCh62y3PV2mmm3fTkVKVY8+PMRDNNKhey3Q/WadO2e2r8sUs507DQAAwA0Q6CF06GfOmH3ZZWJNm76HipSqHn14iIdopEP3WqD759BPnjT7quv4mjZ9n6v1ut1PNOIh+vAQDwn0Vu3QVVgd7Vpj3P79VKRU9ejDQzxEIx261wLdb9bRo2bFXV82O3TIAAAA3ACBHkKH/tVXZqe6jjA7coSKlKoefXiIh2ikQ/daoPvn0A8cMDvbdYhv7N3Fet3uJxrxEH14iIcEeqt26Lpy7PmuA31Hx1GRUtWjDw/xEI106N4KdL9Ze/eafdMl3aykxAAAANwAgR5Ch/7ZZ2ZlnVPNSkupSKnq0YeHeIhGOnSvBbp/Dl0XiKvo3Nvs4kVX63W7n2jEQ/ThIR4S6K3aoesS7teSnzcLuB87FSlVPfrwEA/RSIfukUD3m6Ubtt3sVNOtX7liAAAAboBAD6FD37TJrDKpq9mNG1SkVPXow0M8RCMdutcC3T+HvmGD2e3E5JpUr3S1Xrf7iUY8RB8e4iGB3qod+rp1ZtUdE2r+qaYipapHHx7iIRrp0L0W6H6z1qyu9gU6AACASyDQQ+jQP8qv9A25U5FS1aMPD/EQjXTozaO6utoyMjIsLi7O4uPjLSsry3nubhw9etQGDx5sTzzxhHXo0MFWrVoVVKD759BXLb9hVZ26ur4AQR8eohEP8TBy9Hk20PPz8y0lJcVKSkqcRY8LCgoaff2pU6csISHB1q1bZxUVFVZaWmrjx48PqUMvyLlitzp3pyKlqkcfHuIhGunQm0tqaqoVFhbWrutxWlpao69XeK9YsaJZFZTfrJWLyu1Gl+cNAADALXg20GNjY6084EptZWVlzvB7Y7Rv394WLFjgDLVriH7ixIl25R4XhmmsQ89feNGud+tNRUpVjz48xEM00qE3l+joaKuqqqpd1+OYmJhGX6/vvfLKK07waxk3bpxNmjSpwdcWFRU5YZ6Tk1Pn+aSkJOf5Ra8ftWvdU50NonX/hmnt9dzcXFfp8Zo+fc3OzkZfM9e1ndHXvPX6X9HH/rAp6xHToev1ek3g69u2bRtSh547p8Su9kynIqWqRx8e4iEa6dCbS7Bz6P369asT6JcuXQo60P1m5c46aRUpAw0AAMAteDbQ8/Ly7nqUe1RUVJ3X6xS1CRMm1Blynzx5ckgd+oppJ6yi9xAqUqp69OEhHqKRDr25BJ6HriUzM7POeej1A13ooDh15aEeFOc/D33F745Yed8RrvuAcO4qHqIRD9EXuR5ypbgQOvTlrx6y8n4vU5FS1aMPD/EQjXToXgx0v1krJuy3sv5jDQAAwC0Q6KF06GP3Wdmg8VSkVPXow0M8RCMduhcD3T+HvnzUHisbOtH1etGHh2jEQzyMHH0Eeigd+oidVjZyChUpVT368BAP0UiH7sVAr51DH/qplY2aagAAAG6BQA+hQ18xaItdGjuDipSqHn14iIdopEP3YqD759BzB3xiZRNmu14v+vAQjXiIh5Gjj0APoUPPS19vZZMyqEip6tGHh3iIRjp0Lwa636y81DVW9ru5BgAA4BYI9BA69Pw+q6x82gIqUqp69OEhHqKRDt2Lge6fQ1/ZK98uz37b9XrRh4doxEM8jBx9LRrousNZRUWF5zv0D59fbpfnLKYipapHHx7iIRojs0PXHdCeeeYZ27VrlycD3W/Wqh5LrWLe+wYAAOAWWjTQR44c6YR6dHS0zZgxw27evOnJDn119xy7kv0BFSlVPfrwEA/RGJkduti7d6/17t3bCfauXbvawYMHPRPo/jn0Nc8usquLc12vF314iEY8xMPI0dcqB8VVV1fbxx9/bJ06dXKCvf7i9g59Xde37PqSlVSkVPXow0M8RGPkduj+QN+wYYPnAt1v1vrOC+zG8lUGAADgFlp1yL1Lly6eGnL3d+gbOmXZzZVrqUip6tGHh3iIxsjs0AMPips+fXqzDopTl5+RkWFxcXEWHx9vWVlZznONEcpIQGNz6JuS3rTKNRtcX4CgDw/RiId4GDn6PHvaWn5+vqWkpFhJSYmz6HFBQcFd/+9wdehbEmfZ7Q2bqEip6tGHh3iIxsjs0MN5YZnU1FQrLCysXdfjtLS0+xrofrO2JUy36i1bDQAAwC149tKvsbGxVl5eXrteVlbmDL/fLdDbtm1rbdq0se7du9uyZcvszp07QXfoGtUv7PiaKggqUqp69OEhHqIxMjv0cKJ5+Kqqqtp1PY6Jibnn+yorK+3QoUNONz97dsP3NC8qKnLCPCcnp87zSUlJtmHDJtudMNls1y5ng+h1/g3T2uu5ubmu0uM1ffqanZ2Nvmauazujr3nr9b+ij/1hU9YjpkOvT2lp6T1f31CHruP49iZONNuzh4qUqh59eIiHaKRDby7BzqHX5/z589a+ffugAl1mXbtmtj9xnNnnnxsAAIBb8Gyg5+Xl3fUo9/oHwemAvOPHjztD88XFxTZo0CCbOXNm0B26jun7Kmm02YEDVKRU9ejDQzxEIx16cwk8D11LZmZmnfPQ6wf6xo0brUePHvbYY49ZcnKyzZs3z27duhVUoOs89LIys2OdXqpJ9a9c9wHh3FU8RCMeoi9yPfRsoLeG4erQL140K+403OzoUSpSqnr04SEeopEO3YuBLrNKS81Odxpck+rFBgAA4BYI9CA79JISs7OdBpidOkVFSlWPPjzEQzTSoXsx0DWHrhw/3yndnGR3uV704SEa8RAPI0cfgR5kh66R9kud+uq8NypSqnr04SEeopEO3YuBLrOOHTO7nNSrJtUvGQAAgFsg0IPs0A8fNrua1LMm1S9TkVLVow8P8RCNdOheDHTNoR88aHYj6bmaVL/qer3ow0M04iEeRo4+Aj3IDn3/frPKxC7mXNSdipSqHn14iIdopEP3XqDLrH37zG4ndNLt3QwAAMAtEOhBdujOTdYSEswCLjNLRUpVjz48xEM00qF7KNA1h757x227k5DkCb3ow0M04iEeRo4+Aj3IDn3n1ltWldiZipSqHn14iIdopEP3aqDLrMKN1+1W0rMGAADgJgj0IDv07Wsr7EZyDypSqnr04SEeopEO3auBrjn0bR+W2bXOKZ7Qiz48RCMe4mHk6CPQg+zQt+ZdtCtdelORUtWjDw/xEI106F4NdJm1eek5q+iWZgAAAG6CQA+yQ9/07mkr796fipSqHn14iIdopEMPB9XV1ZaRkWFxcXEWHx9vWVlZznNNIT093aKiooIOdM2hf/L211bWc5AnChD04SEa8RAPI0efZwM9Pz/fUlJSrKSkxFn0uKCg4J7vW716taWmpoYU6OrQNy44bt88P5SKlKoefXiIh2ikQw8HCuXCwsLadT1OS7v73HZFRYUlJCTYyZMnQwp0mbUh87BdfGGkAQAAuAnPBnpsbKyVl5fXrpeVlTnD73dj6tSplpOT4zwOtUPf8OZBu9BnFBUpVT368BAP0UiHHg6io6OtKuCOZ3ocExPT6OsPHDjgdPX+efa7BXpRUZET5v7w95OUlGTvvrTBSl54uXaD6HX+DdPa67m5ua7S4zV9+pqdnY2+Zq5rO6Oveev1v6KP/WFT1iOmQ1eYf/3117XroXboH7++10rTJ1CRUtWjDw/xEI106OEg2Dl0BXhDSzCBLrPWT95tpQMnGQAAgJvwbKDn5eXd9Sj3e4V1yB36qzvs3ODfUZFS1aMPD/EQjXTo4SDwPHQtmZmZdc5Dvx+BrvPQ14//1M4Ne92VHxDOXcVDNOIh+iLXQ64UF2yHPnaznR05k4qUqh59eIiHaKRD92qgO3PoL2+0s6PeMAAAADdBoAfboY9cb2fHZlCRUtWjDw/xEI106F4NdM2hfzx0tZ2dMM8TetGHh2jEQzyMHH0EepAd+oZBBXZ2UjYVKVU9+vAQD9FIh+7VQJdZGwfk2bnX3jEAAAA3QaAH2aFvTF9u56a9S0VKVY8+PMRDNNKhezXQnfuhpy6x0tlLPKEXfXiIRjzEw8jRR6AH2aFv6vOelc5ZRkVKVY8+PMRDNNKhezXQZdbmFxbZ+bm5BgAA4CYI9CA79K0p2XYhu4CKlKoefXiIh2ikQ/dqoGsO/dOe8+zi4tWe0Is+PEQjHuJh5Ogj0IPs0Ld3z7Rv3l9HRUpVjz48xEM00qF7NdBl1o7n3rRLyzYYAACAmyDQg+zQd3adaeUrN1ORUtWjDw/xEI106F4NdM2h7+4yzS5/tM0TetGHh2jEQzyMHH0EepAdelHn39mV9YVUpFT16MNDPEQjHbpXA11m7UueZFc37TYAAAA34dlAr66utoyMDIuLi7P4+HjLyspynmuMwsJCS09Pt8cee8w6dOhgr776ql26dCnoDv2LpAl2ffteKlKqevThIR6ikQ49HOTn51tKSoqVlJQ4ix4XFDR+wZcBAwbY5s2b7cqVK3bt2jV76623nOeCCXTNoX+Z+Fu7ufsLT4wooA8P0YiHeBg5+jwb6KmpqU7XHdiBp6WlNfn9169ftzZt2gTdoR9KHG2V+w5QkVLVow8P8RCNdOjhIDY21srLy2vXy8rKnOH3pnDjxg1bvHixDR8+PKhAl1mHO460O4cOGwAAgJvwbKBHR0dbVVVV7boex8TE3PN9UVFRztKuXTs7ffp00B36sY7DzI4doyKlqkcfHuIhGunQW7tD1xz6woULnYPkGqKoqMgJ85ycnDrPJyZ2sq87DrIz27fXbhC9zr9hWns9NzfXVXq8pk9fs7Oz0dfMdW1n9DVvvf5X9LE/bMp6xM6hK9SfeOKJoDr0fv3625mE/mb36OypSKnq8RB9eIhGOvQmkpeXd9ej3DWsHsjEiROtuLjYGZovLS21GTNmBD2H/tJLY600oaZoOHfOAAAA3MQDcR66lszMzDrnodcP9I0bN1qPHj3s0UcftYSEBJs6dapVVFQEFeipqQPsYkIfswsXqEip6tGHh3iIRjp0r1A/0Dt37mnlib3M7nFBGrfoRR8eohEP8TBy9BHoQRjeu/cAu5LQw+wenT0VKVU9HqIPD9FIh+7iQB8yZKxdT+imI+oMAADATRDoQQR6r14DrTKhs9mtW1SkVPXow0M8RCMdulcDPSkpxe4kJJndvu0JvejDQzTiIR5Gjj4CPQjDn39+kFV3TKAipapHHx7iIR7SoXs50Punj7bbHZMMAADAbRDoQQR6j279rTKxCxUpVT368BAP8ZAO3cuBnvj083YjsZtn9KIPD9GIh3gYOfoI9CAM79453a4l9aAipapHHx7iIR7SoXs50NN6DrOKTr0MAADAbRDowXToCalW3rkvFSlVPfrwEA/xkA7dy4Ge+GR3u9Sln2f0og8P0YiHeBg5+gj0IAx/7uk+drFrfypSqnr04SEe4iEdupcDvXen/nbhucEGAADgNgj0IAK921O9rLT7MCpSqnr04SEe4iEdupcDPemxrnau50jP6EUfHqIRD/EwcvQR6MF06E8+byUpo6lIqerRh4d4iId06F4O9F7t+tjpF8YZAACA2/BsoFdXV1tGRobFxcVZfHy8ZWVlOc81xo4dO2zAgAH2+OOPW4cOHWzKlCl2+fLl4Dr0Nt3tVJ9XqEip6tGHh3iIh3To4SI/P99SUlKspKTEWfS4oKCg0dcPHjzYCgsL7fr161ZWVmZTp0614cOHBxXonaKS7WTqJM+MKKAPD9GIh3gYOfo8G+ipqalOQPvR47S0tCa//9q1axYbGxtch/7os3byxdeoSKnq0YeHeIiHdOjhQmFcXl5eu66uW8PvTWXr1q2Wnp4eVKCnPNHTvh4wzQAAANyGZwM9Ojraqqqqatf1OCYmpknvPXz4sHXs2NGOHDkSVKA/F93FigfPoiKlqkcfHuIhHtKht3aHXlRU5IT5vn377voahXlOTk6d5zs98ox90XdK7YbQV73OLeu5ubmu0uM1ffqanZ2Nvmauazujr3nr9b+ij/1hU9Yjag59w4YNzhHuBw8ebNL/8Z0O/Ved7MTILCpSqnr04SEe4iEderjIy8u761HuUVFRdV6/ZMkSS0hIsOLi4ib/H9+ZQ4/uYsdfnm8AAABu44E4D11LZmZmnfPQ6we61htadBpbUwO9+y8S7MTYbCpSqnr04SEe4iEdupeoH+jP/k97Oz5+kWf0og8P0YiHeBg5+gj0IAzv8UgHO/Hqe1SkVPXow0M8xEM6dC8Heq9fdLTjU5YaAACA2yDQgwj0nv/Tzk68vpyKlKoefXiIh3hIh+7lQO/+0zg7MTPfM3rRh4doxEM8jBx9BHoQhqf87CkrfvNDKlKqevThIR7iIR26lwP9hZ8/ZV9nrTYAAAC3QaAHEei9fhprXy9YT0VKVY8+PMRDPKRD93Kgp/y4jZ18e6Nn9KIPD9GIh3gYOfoI9CAM7/2TNnbqvS1UpFT16MNDPMRDOnQvB3rf/2pjp5d+agAAAG6DQA8m0H/0qJXk7aQipapHHx7iIR7SoXs60H8YY2c//MwzetGHh2jEQzyMHH0EehCGp/0w2krX7qUipapHHx7iIR7SoXs50NN/GGXnN+43AAAAt0GgBxPoP/iVXdx2iIqUqh59eIiHeEiH7uVAf/HhX9qlnUc8oxd9eIhGPMTDyNFHoAdh+ICHf2HlRcepSKnq0YeHeIiHdOheDvSBDz9iFV+eNAAAALfh2UCvrq62jIwMi4uLs/j4eMvKynKea4yoqKjaJdRAH/zw/9rVw2eoSKnq0YeHeIiHdOjhIj8/31JSUqykpMRZ9LigoOCe72tOoA956Od2/cQ5z4wooA8P0YiHeBg5+jwb6KmpqVZYWFi7rsdpaWn3NdCHPvTfdqvkIhUpVT368BAP8ZAOPVzExsZaeXl57XpZWZkz/H4/A334Q/9lVRfLDQAAwG14NtCjo6Otqqqqdl2PY2Ji7mugj3zoJ1ZdcYWKlKoefXiIh3hIh+6FDr2oqMgJ85ycnDrPv/TQj2zL2rW1G0Jf9Tq3rOfm5rpKj9f06Wt2djb6mrmu7Yy+5q3X/4o+9odNWWcOPYgOfdRDPzCrrKQipapHHx7iIR7SoYeLvLy8ux7l3lhwNyfQxzz0sNmdOwYAAOA2Hojz0LVkZmbWOQ+9fnAHnofe1PPRvxvoD1GRUtWjDw/xEA/p0L1G/UAfrSF3D+lFHx6iEQ/xMHL0EehBGP7yQz+iIqWqRx8e4iEe0qF7PdBfeujHBgAA4EYI9CACfcTD/0VFSlWPPjzEQzykQ/d6oA9/+Kee0os+PEQjHuJh5Ogj0IMwfNjDP6MipapHHx7iIR7SoXs90If+4H8MAADAjRDoQQT64B88QkVKVY8+PMRDPKRD93qgD3R5oDPvhodoxEP0Ra6HBHowgf7DX1CRUtWjDw/xEA/p0L0e6AN+/CsDAABwIwR6EIH+4o9+TUVKVY8+PMRDPKRD93qg93N5oDPvhodoxEP0Ra6HBHoQhqf/JIaKlKoefXiIh3hIh+75QP/vxwwAAMCNEOhBBHraT90d6FT1eIhGPEQfHTqB3oRA7/OTRz2lF314iEY8xMPI0UegB2F43589QUVKVY8+PMRDPKRD93qgp/1vnAEAALgRzwZ6dXW1ZWRkWFxcnMXHx1tWVpbzXLhe31Cg9/n5k1SkVPXow0M8xEM69HCSn59vKSkpVlJS4ix6XFBQELbXNxToKT/7f54aUUAfHqIRD/EwcvR5NtBTU1OtsLCwdl2P09LSwvb6hgx/4ZGnqEip6tGHh3iIh3To4SQ2NtbKy8tr18vKypzh9HC9vqFAT/1VBwMAAHAjng306Ohoq6qqql3X45iYmLC9vsEO/RftqEip6tGHh3iIh3ToXunQi4qKnDBfuXJlnecnTJjgGMbCwsLCwuK2RRnlyUBviTl0AACABxXXBHpeXt5dj1qPiooK6vUAAAAEeisQeF65lszMzDrnldcP9Hu9HgAAgECPENTla27drUtOTg768BCNeIiHEerh3r17CfSmwsUeHmx9eIiHaMTDSNIX0YEebPWDPm/pw0M8RCMeRpK+iA50AACABwUCHQAAgEAHAAAAAr0VCOW2q/cTnY7nX9yqd8eOHTZgwAB7/PHHrUOHDjZlyhS7fPmyazTqokLp6en22GOPOfpeffVVu3Tpkmu3ubTe7TTM1tAY+Dls6PPoFg+PHj1qgwcPtieeeMLZ1qtWrXK1h7qipZs81DU7RowYUXu6rx7rObdovHLlik2cONH5v9u2bWsLFy5s9c9hc/fRLak54gI9lNuuttTOwK16tQNVaF6/ft25xO7UqVNt+PDhrtGoYmPz5s3OzuDatWv21ltvOc+5cZuvXr3aucph/e3d2hob+/y5ycNTp05ZQkKCrVu3zioqKqy0tNTGjx/v2r/tTZs22Zw5c1ylT5+9efPmOX8rWubOnes85xaNkyZNsnHjxjkFuRZd/jSwaGtNfaHuo1tSc8QFulsvGdvYh8WNehWagZ2H2zSq8GjTpo3r9CmEFEgnT578zvZubY33CnQ3eKjwXrFihWf+tnv37m0XLlxwlT79XejvN/Bv2U1/K0899ZTTNPhRqPfr188V+kLdR7ek5ogL9FBuu9qaHxY36t26daszbOxGjTdu3LDFixfXGUFwiz6NbOjiEw1t79bWKD0a4tTOvXv37rZs2TK7c+eOqzxs3769LViwwBlq19ClhmbVZbrxc7ht2zabPHmy6/6Wx4wZ43h49epVx7v58+c7z7lFY/1Ar///t6a+UPfRLak54gI9lNuutuaHxW16Dx8+bB07drQjR464TqN/nqtdu3Z2+vRpV+k7cOCAU6n7587qb2+3eFhZWWmHDh1yOojZs2e7Sp/+v1deecXZIWrR0KyGaN34t6LuvLi42HXbWCMGiYmJtX8renzx4kXXaFSRpjuM+bexRmV+85vfuEJfqPvoltRMh06H3mR0G1qF+b59+1yrUUOIOpDGbSMICvOvv/660e3tts+l5qfd0hkFaqjfvWlUwW0eakh15MiRrvxbHjRokDNvHjiHrufcolHTUgpxjcBoRGbRokX29NNP06ET6I3vWJlDD54NGzY4Q50HDx50vacKdR0F7SZ9DR0BHbjN3ebh+fPnnR2qm/RpLrX+/GpgoLvFQ+n44osvXPl34vY59Prk5ubWOfCROXQCvQ5uve1qYx8WN+hdsmSJczBX/SFEt2jUMJ20aShLneWMGTPqzKG7cZu77XbAGr4+fvy446G8VNc2c+ZMV3moo50Dh2OlOXCe2g0ad+/eXeeocbf9LUub5s0DO/TAcGltjdq+Kial7eOPP649iNQN+kLdR7ek5og+D90Nt10N5vzf1tLbWHepo8ndoHHjxo3Wo0cPe/TRR50dgA4+09CdW7d5QzsHt3ioc/mTk5OdU5tu3brlOg91QJe68oYOinODRk316KBRt+57dOrf0KFD7cknn3SWYcOG2ZkzZ1yjUUWbRgI1aqDTZXXMTmt72Nx9dEtq5kpxAAAADwAEOgAAAIEOAAAABDoAAAAQ6AAAAECgAwAAEOgAAABAoAMAAACBDgAAAAQ6ADQbXXpVV83SFb3qoyuQ6XuB1+EGAAIdAFyILq/7zDPPOMGta5j72bNnj/Oc7swXeGlWACDQAcClKMh1v2fdcELXp9aix3rus88+wyAAAh0AvMKsWbOcjnzt2rXOosezZ8/GGAACHQC8hO7K9uyzz1piYqKz6HHgndoAgEAHAA+ge5O3a9fOevfu7Sx6rOcAgEAHAA8xZswYZ5hdc+aaU9fjsWPHYgwAgQ4AXmHjxo1OgA8aNKj2uYEDBzrP6XsAQKADgMvxD7XriPZDhw7VPq/HCnSG3gEIdADwAP6hdn2tz+jRoxl6ByDQAQAAgEAHAAAg0AEAAIBABwAAAAIdAAAACHQAAAACHQAAAAh0AAAAINABAACAQAcAACDQAQAAgEAHAAAAAh2gxT/03/seSwQsAAQ6QAQEOrCNAQh0AHb2wDYGINAB2NkD2xiAQAdgZw9sYwACHaB1d/ZRUVER5XVr/b4EOhDoAAS6awKuKa+trq62jIwMi4uLs/j4eMvKynKe82KgN+W1eo1/IdABCHQg0B+YgMvPz7eUlBQrKSlxFj0uKCh4YAO9qa8l0IFAByDQmx1g7733nrVr187pmKdPn25VVVUNBlFlZaXNmjXL2rdv7yx6rOfqd6J3C6/U1FQrLCysXdfjtLS0Fg3slvx9CXQAAh2gxQJ90KBBduHCBWfR4+zs7AaDaMGCBc73z58/7ywDBgxwngumY42NjbXy8vLa9bKyMmf4vSUDvSV/XwIdgEAHaHhnf+KE2SefhLbovQ0ETXFxccCPP2HJyckNBlGnTp3qvPb48eONvrYxoqOj63TEehwTE9Po68P867b470ugAxDoAA3v7HfuNHvjjdAWvbeBoLl161btuh4//vjjDQaRnm/qa8PVoYf5123x35dAByDQAVpkZ1+/Y9XjUDtWdd/3wg1z6C35+xLoAAQ6QIsF+uDBg2vnlPW4sXniefPmfWdOef78+bXf14FmgQHYEHl5ea16lHtL/74EOgCBDtBigR541Pe0adNqj+SuH0Qacp45c2btUd96HDgkvWTJEmf4/G7hFXgeupbMzMwWPQ+9pX/f+kfDN/ZaAh0IdAACvdkBF0m49fcl0IFAByDQCXQCHYBAByDQCXQCHYBAB2BnD2xjAAIdgJ09sI2BQAdgZw9sYwACHcBbO3uWB38BINABAADAc/x/hE0+wx/BylwAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mrocxaxis\u001b[39m: \u001b[32mFMat\u001b[39m = 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rocxaxis = row(0 until 101)\n",
    "plot(rocxaxis, rr, rocxaxis, lrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">TODO 4: In the cell below, compute and plot lift curves from the ROC curves for Naive Bayes and Logistic regression. The lift curves should show the ratio of ROC y-values over a unit slope diagonal line (Y=X). The X-values should be the same as for the ROC plots, except that X=0 will be omitted since the lift will be undefined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO 5: Experiment with different values for learning rate and batchSize to get the best performance for absolute accuracy and ROC area on category 6. Write your optimal values below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIDMach",
   "language": "bidmach",
   "name": "bidmach"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
