
val dir = "../data/MNIST/"

val Xtrain = loadFMat(dir + "train.fmat.lz4")
val ytrain = loadIMat(dir + "ctrain.imat.lz4")

val Xtest = loadFMat(dir + "test.fmat.lz4")
val ytest = loadIMat(dir + "ctest.imat.lz4")

val (nn,opts) = Net.learnerX(Xtrain, ytrain);


/* options */

// TF settings 
//training iterations = 200000
//display step = 10

//n_input = 784 # MNIST data input (img shape: 28*28)
//n_classes = 10 # MNIST total classes (0-9 digits)
//dropout = 0.75 # Dropout, probability to keep units

opts.batchSize = 128 //same with TF
opts.npasses = 10
opts.lrate = 0.001f //same with TF
opts.hasBias = true
opts.links = 2*iones(10,1)
//opts.targets = mkdiag(ones(10,1)) \ zeros(10, 784)
//opts.rmask = zeros(1,10) \ ones(1, 784)
//opts.lookahead = 2
opts.featType = 1
//opts.order = 0

import BIDMach.networks.layers._
import BIDMach.networks.layers.Node
import BIDMach.networks.layers.Node._
import java.util.Arrays



/* neural network design */

val in = input;

//convolution layer
val conv1 = new ConvolutionNode{
  inputs(0) = in;
  kernel = 5\5;
  noutputs = 32;
  hasBias = false; //opts.hasBias;
  stride = 1;
  pad = 1;
};

//convolution layer
val conv2 = new ConvolutionNode{
  inputs(0) = conv1;
  kernel = 5\5; // define an Imat
  noutputs = 64;
  hasBias = false; //opts.hasBias;
  stride = 1;
  pad = 1;
};

//fully connected layer
//reshape conv2 output to fit fully connected layer input
var fc1 = linear(conv2)(outdim = 1024, hasBias = opts.hasBias, aopts = opts.aopts);

//Output, class prediction
val out = glm(fc1)(opts.links);
val layers = Array(in, conv1, conv2, fc1, out)

opts.nodeset = new NodeSet(layers);
opts.what;


/* train */

val model = nn.model.asInstanceOf[Net]
nn.train


/* test */

val (mm, mopts) = Net.predictor(model, Xtest);
mm.predict


/* benchmark */

val preds = FMat(mm.preds(0))

val ll = DMat(ln(preds *@ ytest + (1-preds) *@ (1-ytest)))
val rc = roc(preds, ytest, 1-ytest, 1000);

:silent

(mean(ll), mean(rc))
