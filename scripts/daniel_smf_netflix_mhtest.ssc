:silent
import BIDMach.models.SMF

/**
 * Test SMF code on netflix data. This will use OUR MHTest updater, which I put
 * in as a new updater (SMF.learner2) to make this script more concise.
 */

// Get random seed set up.
// TODO random seed code

// Now get back to the real netflix data. First, load data and set things up:
val dir = "/data/netflix/"
val a = loadSMat(dir+"newtrain.smat.lz4")
val ta = loadSMat(dir+"newtest.smat.lz4")
val d = 256
val (nn,opts) = SMF.learner2(a, d)
println("size(a)="+size(a)+", with a.nnz="+a.nnz)

// Daniel Seita: stuff for the MH Test updater. OH ... and our N is going to be
// super-large. Ahhhh... we may need temperature then.
opts.smf = true // IMPORTANT, this affects some of the code.
opts.N = a.nnz
opts.temp = a.nnz / 1000
opts.Nknown = true
opts.n2lsigma = 1.0f
opts.nn2l = 4000
opts.sigmaProposer = 0.01f
opts.continueDespiteFull = false
opts.verboseMH = false
opts.collectData = false
opts.collectDataDir = "tmp/"
opts.exitTheta = false
opts.initThetaHere = false
opts.burnIn = -1

// For the SMF
opts.matrixOfScores = true

// Daniel Seita: actually, a batch size of 2000 means we may get 100k "elements"
// due to the sparsity. So I'm thinking we stick to batch sizes of 1000 or less.
opts.batchSize = 1000
opts.uiter = 5
opts.urate = 0.05f
opts.lrate = 0.05f  
opts.npasses = 3
val lambda = 4f
opts.lambdau = lambda
opts.regumean = lambda
opts.lambdam = lambda / 500000 * 20
opts.regmmean = opts.lambdam
opts.evalStep = 31
opts.doUsers = false
opts.lsgd = 0.010f
opts.what
nn.train

val model = nn.model.asInstanceOf[SMF]
val xa = (ta != 0)
val (mm, mopts) = SMF.predictor1(model, a, xa)
mopts.batchSize = 10000
mopts.uiter = 5
mopts.urate = opts.urate
mopts.lsgd = 0.0f
mm.predict

val pa = SMat(mm.preds(1));
min(pa.contents,5,pa.contents)
max(pa.contents,1,pa.contents)
val diff = ta.contents - pa.contents
val rmse = sqrt((diff ^* diff) / diff.length)
println("rmse = %f" format rmse.v)
