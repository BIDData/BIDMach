import org.apache.spark.SparkContext
import org.apache.spark.mllib.classification.LogisticRegressionWithSGD
import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics
import org.apache.spark.mllib.optimization.L1Updater
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.util.MLUtils
import scala.compat.Platform._ 

val nnodes = 2

val t0=currentTime
// Load training data in LIBSVM format.
/*val both = MLUtils.loadLibSVMFile(sc, "s3n://bidmach/CriteoTrain.libsvm", false, 595072, nnodes*4)
val splits = both.randomSplit(Array(0.6, 0.4))
val train = splits(0)
val test = splits(1) */

val train = MLUtils.loadLibSVMFile(sc, "s3n://bidmach/RCV1train6.libsvm", false, 276544, nnodes*4)
val test = MLUtils.loadLibSVMFile(sc, "s3n://bidmach/RCV1test6.libsvm", false, 276544, nnodes*4)

val t1=currentTime

val lrAlg = new LogisticRegressionWithSGD()
lrAlg.optimizer.
  setNumIterations(10).
  setRegParam(1e-10).
  setUpdater(new L1Updater)

// Run training algorithm to build the model
val numIterations = 100
val model = lrAlg.run(train)

val t2=currentTime

// Clear the default threshold.
model.clearThreshold()

// Compute raw scores on the test set. 
val scoreAndLabels = test.map { point =>
  val score = model.predict(point.features)
  (score, point.label)
}

val t3=currentTime

// Get evaluation metrics.
val metrics = new BinaryClassificationMetrics(scoreAndLabels)
val auROC = metrics.areaUnderROC()
println("Area under ROC = " + auROC)

println("load time %f, train %f, predict %f" format ((t1-t0)/1000f,(t2-t1)/1000f, (t3-t2)/1000f))

val ts = model.weights.toString;
scala.tools.nsc.io.File("/home/ec2-user/weights.txt").writeAll(ts.substring(1,ts.length-1))



