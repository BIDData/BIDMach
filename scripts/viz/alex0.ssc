import BIDMach.networks.layers._

val traindir = "/data/data/ImageNet/train/";
val testdir = "/code/BIDMach/data/ImageNet/val/";
val traindata = traindir+"partNCHW%04d.bmat.lz4";
val trainlabels = traindir+"label%04d.imat.lz4";
val testdata = testdir+"partNCHW%04d.bmat.lz4";
val testlabels = testdir+"label%04d.imat.lz4";
val testpreds = testdir+"pred%04d.fmat.lz4";

class MyOpts extends Learner.Options with Net.Opts with FileSource.Opts with Grad.Opts;
val opts = new MyOpts;
val ds = FileSource(traindata, trainlabels, opts);
val net = new Net(opts);
val grad = new Grad(opts);
val nn = new Learner(ds, net, null, grad, null, opts);


def lr_update(ipass:Float, istep:Float, frac:Float):Float = {
  val lr = if (ipass < 20) {
      0f//1e-2f
  } else if (ipass < 40) {
      1e-3f
  } else 1e-4f;
  lr
}

opts.logfile = "logAlexnet.txt";
opts.batchSize= 4;
opts.npasses = 80;
//opts.nend = 10;
opts.lrate = 0//1e-4f;
opts.texp = 0f;
opts.pstep = 0.05f
opts.hasBias = true;
opts.l2reg = 0f//0.0005f;
opts.vel_decay = 0f//0.9f;
opts.lr_policy = lr_update _;
opts.tensorFormat = Net.TensorNCHW;
opts.useCache = true;
opts.convType = Net.CrossCorrelation;
//opts.inplace = Net.BackwardCaching;
opts.inplace = Net.InPlace;

:silent

val means = ones(3\256\256\opts.batchSize) *@ loadFMat(traindir+"means.fmat.lz4");

{
    import BIDMach.networks.layers.Node._;

    Net.initDefaultNodeSet;

    val in =        input;
    val meanv =     const(means);
    val din =       in - meanv;
    val scalef =    const(row(0.01f));
    //val sdin =      din *@ scalef;
    //val fin =       format(in)();
    val cin =       cropMirror(din)(sizes=irow(3,227,227,0), randoffsets=irow(0,28,28,-1));
    //val min =       randmirror(cin)();

    val conv1 =     conv(cin)(w=11,h=11,nch=96,stride=4,initfn=Net.gaussian,initv=0.01f,initbiasv=0f);
    val relu1 =     relu(conv1)();
    val pool1 =     pool(relu1)(w=3,h=3,stride=2);
    val norm1 =     LRNacross(pool1)(dim=5,alpha=0.0001f,beta=0.75f);

    val conv2 =     conv(norm1)(w=5,h=5,nch=256,stride=1,pad=2,initfn=Net.gaussian,initv=0.01f,initbiasv=1f);   
    val relu2 =     relu(conv2)();
    val pool2 =     pool(relu2)(w=3,h=3,stride=2);
    val norm2 =     LRNacross(pool2)(dim=5,alpha=0.0001f,beta=0.75f);

    val conv3 =     conv(norm2)(w=3,h=3,nch=384,pad=1,initfn=Net.gaussian,initv=0.01f,initbiasv=0f); 
    val relu3 =     relu(conv3)();

    val conv4 =     conv(relu3)(w=3,h=3,nch=384,pad=1,initfn=Net.gaussian,initv=0.01f,initbiasv=1f);   
    val relu4 =     relu(conv4)();

    val conv5 =     conv(relu4)(w=3,h=3,nch=256,pad=1,initfn=Net.gaussian,initv=0.01f,initbiasv=1f);
    val relu5 =     relu(conv5)();
    val pool5 =     pool(relu5)(w=3,h=3,stride=2);

    val fc6 =       linear(pool5)(outdim=4096,initfn=Net.gaussian,initv=0.01f,initbiasv=1f);
    val relu6 =     relu(fc6)();
    val drop6 =     dropout(relu6)(0.5f);

    val fc7 =       linear(drop6)(outdim=4096,initfn=Net.gaussian,initv=0.01f,initbiasv=1f);
    val relu7  =    relu(fc7)();
    val drop7 =     dropout(relu7)(0.5f);

    val fc8  =      linear(drop7)(outdim=1000,initfn=Net.gaussian,initv=0.01f,initbiasv=1f);
    val out =       softmaxout(fc8)(scoreType=1,lossType=1);

    opts.nodeset=Net.getDefaultNodeSet
}

def loss = {net.layers(net.layers.length-1).asInstanceOf[SoftmaxOutputLayer]};

val sgd = nn.updater.asInstanceOf[Grad];
import BIDMach.viz._

nn.launchTrain;

def load(net:Net,fname:String) {
    for (i <- 0 until net.modelmats.length) {
        val data = loadMat(fname+"modelmat%02d.lz4" format i);
        net.modelmats(i)<--data
    }
}


def run(){
    java.lang.Thread.sleep(4000)
    nn.pause
    java.lang.Thread.sleep(500)
    load(net,"models/alex32p/")
}
run()


val model = net
val s = new Synthesis("imagenet")
val o = s.opts

o.realImagesPath = "/data/data/ImageNet/train/"
{
    import javax.swing._
    val classNames = scala.io.Source.fromFile("data/imagenet_classname.txt").getLines.map(_.split(": ")(1)).toArray;
    val display = classNames.zipWithIndex.map(x=>"fc8 "+x._2+": "+x._1.slice(1,x._1.length-2));
    var box2: JComboBox[String] = null;         
    val m = net.modelmats(net.modelmats.length-2); //1000*4096 matrix
    val (_,tmp) = sortdown2(m.t);
    val topFeatures = IMat(cpu(tmp));            
    val (_,tmp2) = sortdown2(m);
    val topClasses = IMat(cpu(tmp2))
    s.plot.add_combobox(display,
                        (i:Int,v:String)=>{
                            box2.removeAllItems;   
                            topFeatures(0->20,i).data.foreach(x=>box2.addItem("fc7 "+x.toString+": "+topClasses(0->3,x).data.map(classNames(_)).reduce(_+";"+_)))
                            s.opts.endLayer = net.layers.length - 2;
                            s.opts.derivFunc = (a:Layer)=>{val m = a.deriv;m.set(0f);m(i,?)=1f}
                            s.resetFlag = true
                        });
    box2 =s.plot.add_combobox(Array(),
                        (i:Int,v:String)=>{
                            s.opts.endLayer = 23;
                            val id = v.split(": ")(0).split(" ")(1).toInt
                            s.opts.derivFunc = (a:Layer)=>{val m = a.deriv;m.set(0f);m(id,?)=1f}
                            s.resetFlag = true
                        });
}
s.init(model,null);


o.endLayer = 23
o.derivFunc = (a:Layer)=>{val m = a.deriv;m.set(0f);m(1,?)=1f}
o.printInfo = false
o.clipping = true
//opts.endLayer = 17
//opts.derivFunc = (a:Layer)=>{val m = a.deriv;m.set(0f);m.reshapeView(13,13,256,2)(6,6,0,?)=1f}


val f5 = model.layers(5).asInstanceOf[BIDMach.networks.layers.ConvLayer].filter.asInstanceOf[BIDMat.GFilter]
f5.setBwdDataAlgo=0
val df5 = s.D.layers(5).asInstanceOf[BIDMach.networks.layers.ConvLayer].filter.asInstanceOf[BIDMat.GFilter]
df5.setBwdDataAlgo=0
net.predicting=false


:silent




//---------Useless scripts---------
//println("Examine the 'nn' variable to track learning state.\n");
//val v = nn.add_plot(new FilterViz(5,bw=3)).asInstanceOf[FilterViz]
//v.interval = 100
//val s = nn.add_plot(new Synthesis).asInstanceOf[Synthesis]
//s.lrate = 1000f
//val s = start("imagenet")
/**plotscore(s.dscores)
plotscore(s.gscores)
plotscore(s.gsteps)
plothist(s.gdata)*/

//nn.train;

//val (mm, mopts) =  Net.predLabels(net, testdata, testlabels);
//mopts.batchSize= opts.batchSize;
//mopts.autoReset = false;
//mm.predict;

//println("Accuracy = %f" format mean(mm.results(0,?),2).v);



