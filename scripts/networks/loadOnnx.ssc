import onnx.Onnx
import onnx.Onnx.{NodeProto,ValueInfoProto,TensorProto}
import com.google.protobuf.{CodedInputStream,TextFormat}
import java.io._
import java.nio.ByteBuffer
import scala.collection.JavaConversions._
import scala.collection.mutable.{HashMap,ArrayBuffer}
import BIDMach.networks.layers._
import jcuda.jcudnn._
import jcuda.jcudnn.JCudnn._

val modelFile = "/code/onnx/models/squeezenet/squeezenet/model.onnx";

class ModelMap { 
  var nmodels = 0;
  val mmap = new HashMap[String,Int];
  val tmap = new HashMap[String,Boolean];
  def addModel2(name:String, name2:String, transposed:Boolean = false) = { 
    if (!mmap.contains(name)) { 
      mmap(name) = nmodels;
      tmap(name) = transposed;
      if (name2 != null) {mmap(name2) = nmodels+1; tmap(name2) = false}
      nmodels += 2;
    }
  }
  def addModel4(name:String, name2:String, name3:String, name4:String) = { 
    if (!mmap.contains(name)) { 
      mmap(name) = nmodels;
      tmap(name) = false;
      if (name2 != null) {mmap(name2) = nmodels+1; tmap(name2) = false}
      if (name3 != null) {mmap(name3) = nmodels+2; tmap(name3) = false}
      if (name4 != null) {mmap(name4) = nmodels+3; tmap(name4) = false}
      nmodels += 4;
    }
  }
}

val modelMap = new ModelMap

def createConvNode(node:NodeProto, outputMap:HashMap[String,Node], inputMap:HashMap[String,ValueInfoProto], modelMap:ModelMap) = { 
  val pads = izeros(1, 4)
  val kernel_shape = iones(1, 2)
  val strides = iones(1, 2)
  for (attrib <- node.getAttributeList) { 
    attrib.getName match { 
      case "pads" => { 
	pads(0) = attrib.getInts(0).toInt
	pads(1) = attrib.getInts(1).toInt
	pads(2) = attrib.getInts(2).toInt
	pads(3) = attrib.getInts(3).toInt
      }
      case "kernel_shape" => { 
	kernel_shape(0) = attrib.getInts(0).toInt
	kernel_shape(1) = attrib.getInts(1).toInt
      }
      case "strides" => { 
	strides(0) = attrib.getInts(0).toInt
	strides(1) = attrib.getInts(1).toInt
      }
    }
  }
  val mname = node.getInput(1);
  val hb = (node.getInputCount > 2);
  val initf:(Mat,Float)=>Mat = Net.xavier
  val initv0:Float = 1f
  val initbiasf:(Mat,Float)=>Mat = Net.constant
  val initbiasv0:Float = 0f
  val lrs:Float=1f
  val bs:Float=1f
  val ct:Int=cudnnConvolutionMode.CUDNN_CROSS_CORRELATION

  val weightSpec=inputMap(node.getInput(1));
  val wdims = weightSpec.getType.getTensorType.getShape
  val odim = wdims.getDim(0).getDimValue.toInt

  val newnode = new ConvNode{inputs(0)=null; modelName=mname; kernel=kernel_shape; noutputs=odim; stride=strides; pad=pads; hasBias=hb; 
    initfn = initf; initv = initv0; initbiasfn = initbiasf; initbiasv = initbiasv0; convType=ct; lr_scale=lrs; bias_scale=bs;}
  outputMap(node.getOutput(0)) = newnode
  modelMap.addModel2(node.getInput(1), if (node.getInputCount > 2) node.getInput(2) else null);
  newnode
}

def createGemmNode(node:NodeProto, outputMap:HashMap[String,Node], inputMap:HashMap[String,ValueInfoProto], modelMap:ModelMap) = { 
  val hBias = (node.getInputCount > 2);
  val mname = node.getInput(1);
  val initf = Net.xavier;
  val initv0 = 1f;
  val initbiasf = Net.constant;
  val initbiasv0 = 0f;
  val lrs = 1f;
  val bs = 1f;

  val weightSpec=inputMap(node.getInput(1));
  val wdims = weightSpec.getType.getTensorType.getShape
  val odim = wdims.getDim(0).getDimValue.toInt

  val newnode = new LinNode{inputs(0)=null; modelName = mname; outdim=odim; hasBias=hBias; initfn = initf; initv = initv0; 
			    initbiasfn = initbiasf; initbiasv = initbiasv0; lr_scale=lrs; bias_scale=bs;};
  outputMap(node.getOutput(0)) = newnode
  modelMap.addModel2(node.getInput(1), if (node.getInputCount > 2) node.getInput(2) else null, true);
  newnode
}

def createMaxPoolNode(node:NodeProto, outputMap:HashMap[String,Node]) = { 
  val pads = izeros(1, 4)
  val kernel_shape = iones(1, 2)
  val strides = iones(1, 2)
  for (attrib <- node.getAttributeList) { 
    attrib.getName match { 
      case "pads" => { 
	pads(0) = attrib.getInts(0).toInt
	pads(1) = attrib.getInts(1).toInt
	pads(2) = attrib.getInts(2).toInt
	pads(3) = attrib.getInts(3).toInt
      }
      case "kernel_shape" => { 
	kernel_shape(0) = attrib.getInts(0).toInt
	kernel_shape(1) = attrib.getInts(1).toInt
      }
      case "strides" => { 
	strides(0) = attrib.getInts(0).toInt
	strides(1) = attrib.getInts(1).toInt
      }
    }
  }
  val newnode = new PoolingNode{inputs(0)=null; h=kernel_shape(0); w=kernel_shape(1); stride=strides(0); pad=pads(0);}
  outputMap(node.getOutput(0)) = newnode
  newnode
}


def createAveragePoolNode(node:NodeProto, outputMap:HashMap[String,Node]) = { 
  val pads = izeros(1, 4)
  val kernel_shape = iones(1, 2)
  val strides = iones(1, 2)
  for (attrib <- node.getAttributeList) { 
    attrib.getName match { 
      case "pads" => { 
	pads(0) = attrib.getInts(0).toInt
	pads(1) = attrib.getInts(1).toInt
	pads(2) = attrib.getInts(2).toInt
	pads(3) = attrib.getInts(3).toInt
      }
      case "kernel_shape" => { 
	kernel_shape(0) = attrib.getInts(0).toInt
	kernel_shape(1) = attrib.getInts(1).toInt
      }
      case "strides" => { 
	strides(0) = attrib.getInts(0).toInt
	strides(1) = attrib.getInts(1).toInt
      }
    }
  }
  val newnode = new PoolingNode{inputs(0)=null; h=kernel_shape(0); w=kernel_shape(1); stride=strides(0); pad=pads(0);
				poolingMode=cudnnPoolingMode.CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING}
  outputMap(node.getOutput(0)) = newnode
  newnode
}

def createGlobalAveragePoolNode(node:NodeProto, outputMap:HashMap[String,Node]) = { 
  val newnode = new PoolingNode{inputs(0)=null; h= -1; w= -1; stride=1; pad=0;
				                poolingMode=cudnnPoolingMode.CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING}
  outputMap(node.getOutput(0)) = newnode
  newnode
}

def createGlobalMaxPoolNode(node:NodeProto, outputMap:HashMap[String,Node]) = { 
  val newnode = new PoolingNode{inputs(0)=null; h= -1; w= -1; stride=1; pad=0;}
  outputMap(node.getOutput(0)) = newnode
  newnode
}

def createBatchNormScaleNode(node:NodeProto, outputMap:HashMap[String,Node], modelMap:ModelMap) = { 
  var epsilon = 1e-5f
  var momentum = 0.9f;
  var doSpatial = 1;
  for (attrib <- node.getAttributeList) { 
    attrib.getName match { 
      case "epsilon" => epsilon = attrib.getF
      case "momentum" => momentum = attrib.getF
      case "spatial" => doSpatial = attrib.getI.toInt
    }
  }
  val avgFactor = 1f - momentum;

  val mname = node.getInput(1);
  val normMode = if (doSpatial == 1) BatchNormLayer.SPATIAL else BatchNormLayer.PER_ACTIVATION
  val hb = true;
  val lrs = 1f
  val bs = 1f
  val inp = Net.UseNetPlacing
  val newnode = new BatchNormScaleNode{inputs(0)=null; modelName=mname; expAvgFactor=avgFactor; batchNormMode=normMode; 
				       hasBias=hb; lr_scale=lrs; bias_scale=bs; inplace=inp}    
  outputMap(node.getOutput(0)) = newnode
  modelMap.addModel4(node.getInput(1),
		     if (node.getInputCount > 2) node.getInput(2) else null,
		     if (node.getInputCount > 3) node.getInput(3) else null, 
		     if (node.getInputCount > 4) node.getInput(4) else null)
  newnode
}


def createReshapeNode(node:NodeProto, outputMap:HashMap[String,Node], weightsMap:HashMap[String,Mat]) = { 
  val shapeSpec=reverse(IMat(weightsMap(node.getInput(1))).t)
//  val dims = shapeSpec.getType.getTensorType.getShape
  val newnode = new ReshapeNode{inputs(0)=null; dims=shapeSpec}
  outputMap(node.getOutput(0)) = newnode
  newnode
}

def createReluNode(node:NodeProto, outputMap:HashMap[String,Node]) = { 
  val inplac = Net.UseNetPlacing
  val newnode = new RectNode{inputs(0) = null; inplace = inplac};
  outputMap(node.getOutput(0)) = newnode
  newnode
}

def createSumNode(node:NodeProto, outputMap:HashMap[String,Node]) = { 
  val newnode = new AddNode{inputs(0) = null;};
  outputMap(node.getOutput(0)) = newnode
  newnode
}

def createConcatNode(node:NodeProto, outputMap:HashMap[String,Node]) = { 
  var axis = 1
  for (attrib <- node.getAttributeList) { 
    attrib.getName match { 
      case "axis" => axis = attrib.getI.toInt
    }
  }
  val newnode = new StackNode{inputs(0) = null;};
  outputMap(node.getOutput(0)) = newnode
  newnode
}

def createDropoutNode(node:NodeProto, outputMap:HashMap[String,Node]) = { 
  var ratio = 0.5f
  for (attrib <- node.getAttributeList) { 
    attrib.getName match { 
      case "ratio" => ratio = attrib.getF
    }
  }
  val newnode = new DropoutNode{inputs(0) = null; frac=ratio};
  outputMap(node.getOutput(0)) = newnode
  newnode
}

def createSoftmaxNode(node:NodeProto, outputMap:HashMap[String,Node], outputName:String) = { 
  val newnode = if (outputName.matches(node.getOutput(0))) { 
    val scoreTyp = 1
    val lossTyp = 1
    new SoftmaxOutputNode{inputs(0) = null; scoreType=scoreTyp; lossType = lossTyp}
  } else { 
    new SoftmaxNode{inputs(0) = null;};
  }
  outputMap(node.getOutput(0)) = newnode
  newnode
}

val builder = Onnx.ModelProto.newBuilder()
builder.mergeFrom(new FileInputStream(modelFile));

println("Building Graph")
val graph = builder.getGraph
println("Getting Nodes and Inputs")
val nodeProtos = graph.getNodeList
val inputs = graph.getInputList

val outputMap = new HashMap[String,Node];
val inputMap = new HashMap[String,ValueInfoProto];

// Create input map
for (b <- inputs) { 
  inputMap(b.getName) = b;
}

println("Getting Initializer Data")
val weights = graph.getInitializerList
val weightsMap = new HashMap[String,Mat];

for (w <- weights) { 
  val dims0 = w.getDimsList.map(_.toInt).toArray
  val dims = dims0.size match { 
    case 4 => Array(dims0(1), dims0(3), dims0(2), dims0(0))
    case 2 => Array(dims0(1), dims0(0))
    case 1 => Array(dims0(0), 1)
  }
  val ttype = w.getDataType;
  val bb = w.getRawData.toByteArray;
  val bbw = ByteBuffer.wrap(bb);
  bbw.order(java.nio.ByteOrder.LITTLE_ENDIAN);
  val mat = ttype match { 
    case 1 => { 
      val m = FMat.make(dims);
      val fb = bbw.asFloatBuffer
      for (i <- 0 until m.length) m(i) = fb.get(i);
      m
    }
    case 2 => { 
      val m = BMat.make(dims);
      for (i <- 0 until m.length) m(i) = bb(i);
      m
    }
    case 3 => { 
      val m = BMat.make(dims);
      for (i <- 0 until m.length) m(i) = bb(i);
      m
    }
    case 6 => { 
      val m = IMat.make(dims);
      val fb = bbw.asIntBuffer
      for (i <- 0 until m.length) m(i) = fb.get(i);
      m
    }
    case 7 => { 
      val m = LMat.make(dims);
      val fb = bbw.asLongBuffer
      for (i <- 0 until m.length) m(i) = fb.get(i);
      m
    }
    case 11 => { 
      val m = DMat.make(dims);
      val fb = bbw.asDoubleBuffer
      for (i <- 0 until m.length) m(i) = fb.get(i);
      m
    }
  }
  weightsMap(w.getName) = mat;
}

val matBuffer = ArrayBuffer.empty[Mat]

println("Constructing outputMap")

// A NodeSet to contain the translated graph
val nodes = new NodeSet(nodeProtos.size+2);

// The input layer for the network
nodes(0) = new InputNode;
nodes(1) = new CropNode{inputs(0)=nodes(0);}

// How to find the data input tensor:
val dataname = (inputs.map(_.getName).toSet -- weights.map(_.getName).toSet).head
outputMap(dataname) = nodes(1);

// Create all the nodes in the graph
var i = 2;
for (node <- nodeProtos) { 
  val newnode = node.getOpType match { 
    case "Conv" => createConvNode(node, outputMap, inputMap, modelMap);
    case "BatchNormalization" => createBatchNormScaleNode(node, outputMap, modelMap);
    case "Relu" => createReluNode(node, outputMap);
    case "MaxPool" => createMaxPoolNode(node, outputMap);
    case "AveragePool" => createAveragePoolNode(node, outputMap);
    case "GlobalAveragePool" => createGlobalAveragePoolNode(node, outputMap);
    case "Sum" => createSumNode(node, outputMap);
    case "Concat" => createConcatNode(node, outputMap);
    case "Dropout" => createDropoutNode(node, outputMap);
    case "Reshape" => createReshapeNode(node, outputMap, weightsMap);
    case "Gemm" => createGemmNode(node, outputMap, inputMap, modelMap);
    case "Softmax" => createSoftmaxNode(node, outputMap, graph.getOutput(0).getName);
  }
  nodes(i) = newnode
  i += 1;
}

println("Linking Nodes")

def linkToInputs(nodep:NodeProto, outputMap:HashMap[String,Node], ninputs:Int) { 
  val node = outputMap(nodep.getOutput(0));
  for (i <- 0 until ninputs) { 
    val inname = nodep.getInput(i)
    val innode = outputMap(inname);
    node.inputs(i) = innode;
  }
}

for (node <- nodeProtos) { 
  node.getOpType match { 
    case "Conv" => linkToInputs(node, outputMap, 1);
    case "BatchNormalization" => linkToInputs(node, outputMap, 1);
    case "Relu" => linkToInputs(node, outputMap, 1);
    case "MaxPool" => linkToInputs(node, outputMap, 1);
    case "AveragePool" => linkToInputs(node, outputMap, 1);
    case "GlobalAveragePool" => linkToInputs(node, outputMap, 1);
    case "Sum" => linkToInputs(node, outputMap, node.getInputCount);
    case "Concat" => linkToInputs(node, outputMap, node.getInputCount);
    case "Dropout" => linkToInputs(node, outputMap, 1);
    case "Reshape" => linkToInputs(node, outputMap, 1);
    case "Gemm" => linkToInputs(node, outputMap, 1);
    case "Softmax" => linkToInputs(node, outputMap, 1);
  }
}

println("Populating modelmats")

val nmodels = modelMap.nmodels
val modelmats = new Array[Mat](nmodels)

for (w <- weights) { 
  val wname = w.getName
  if (weightsMap.contains(wname) && modelMap.mmap.contains(wname)) { 
    val data = weightsMap(wname)
    modelmats(modelMap.mmap(wname)) = if (modelMap.tmap(wname)) data.t else data
  }
}

println("Starting Predictor")

val traindir = "../../data/ImageNet/train/";
val testdir = "../../data/ImageNet/val/";
val traindata = traindir+"partNCHW%04d.bmat.lz4";
val trainlabels = traindir+"label%04d.imat.lz4";
val testdata = testdir+"partNCHW%04d.bmat.lz4";
val testlabels = testdir+"label%04d.imat.lz4";
val testpreds = testdir+"pred%04d.fmat.lz4";

val opts = new Net.FilePredOptions
val net0 = new Net(opts)
net0.setmodelmats(modelmats)
opts.nodeset=nodes

val (mm, mopts) =  Net.predLabels(net0, testdata, testlabels);
mopts.tensorFormat = Net.TensorNCHW;
mopts.inplace = Net.BackwardCaching;
mopts.convType = Net.CrossCorrelation;
mopts.batchSize= 64
mopts.autoReset = false

val net = mm.model.asInstanceOf[Net];
mm.predict; 


println("Done")


