:silent
val datadir = "../../data/CIFAR10/parts/"
val trainfname = datadir + "trainNCHW%d.fmat.lz4";
val labelsfname = datadir + "labels%d.imat.lz4";
val testfname = datadir + "testNCHW%d.fmat.lz4";
val testlabelsfname = datadir + "testlabels%d.imat.lz4";
val predsfname = datadir + "preds%d.fmat.lz4";

val (nn,opts) = Net.learner(trainfname,labelsfname);

val convtype = jcuda.jcudnn.cudnnConvolutionMode.CUDNN_CROSS_CORRELATION;
val avgpool = jcuda.jcudnn.cudnnPoolingMode.CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING;


opts.batchSize= 64
opts.npasses = 50
opts.lrate = 1e-3f 
//opts.lrate = 3e-4f

opts.gsq_decay = 0.99f
opts.vel_decay = 0.9f
opts.texp = 0.0f
opts.vexp = 0.0f
opts.pstep = 0.1f
opts.hasBias = true;
opts.tensorFormat = Net.TensorNCHW;

{
import BIDMach.networks.layers.Node._;

Net.initDefaultNodeSet;

val in =     input;
val lin1 =   linear(in)(outdim=20);
val sig1 =   sigmoid(lin1);

val lin2 =   linear(sig1)(outdim=30);
val sig2 =   sigmoid(lin2);


val lin3 =   linear(sig2)(outdim=3);
val out =    glm(lin3)(); 


opts.nodemat = nodes;
val model = nn.model.asInstanceOf[Net];
nn.train;

val (mm, mopts) =  Net.predictor(model, testfname, testlabelsfname, predsfname);
mopts.batchSize = opts.batchSize;
val mmodel = mm.model.asInstanceOf[Net];
mm.predict;

println("Accuracy = %f" format mean(mm.results(0,?),2).v);

:silent

