import BIDMach.extern._
import BIDMach.networks.layers._
import java.io.FileReader

val traindir = "../../data/ImageNet/train/";
//val traindir = "/home/jfc/data/ImageNet/2012/BIDMach/train/";
val testdir = "../../data/ImageNet/val/";
val traindata = traindir+"partNCHW%04d.bmat.lz4";
val trainlabels = traindir+"label%04d.imat.lz4";
val testdata = testdir+"partNCHW%04d.bmat.lz4";
val testlabels = testdir+"label%04d.imat.lz4";
val testpreds = testdir+"pred%04d.fmat.lz4";

class MyOpts extends Learner.Options with Net.Opts with FileSource.Opts with Grad.Opts;
val opts = new MyOpts;
val ds = FileSource(traindata, trainlabels, opts);
val net = new Net(opts);
val grad = new Grad(opts);
val nn = new Learner(ds, net, null, grad, null, opts);


def lr_update(ipass:Float, istep:Float, frac:Float):Float = {
  val lr = if (ipass < 20) {
      1e-2f
  } else if (ipass < 40) {
      1e-3f
  } else 1e-4f;
  lr
}

opts.logfile = "logAlexnet_CaffeIO.txt";
opts.batchSize= 128;
opts.npasses = 80;
//opts.nend = 10;
opts.lrate = 1e-4f;
opts.texp = 0f;
opts.pstep = 0.05f
opts.hasBias = true;
opts.l2reg = 0.0005f;
opts.vel_decay = 0.9f;
opts.lr_policy = lr_update _;
opts.tensorFormat = Net.TensorNCHW;
opts.useCache = false;
opts.convType = Net.CrossCorrelation;
opts.inplace = Net.BackwardCaching;
opts.inplace = Net.InPlace;

//:silent

val means = ones(3\256\256\256) *@ loadFMat(traindir+"means.fmat.lz4");

var f:FileReader = null
var caffeModel:CaffeModel = null
try {
  f = new FileReader("bvlc_alexnet.prototxt")
  caffeModel = CaffeModel.loadModel(f, net, means)
} finally {
  if (f ne null) {
    f.close()
  }
}

def loss = {net.layers(net.layers.length-1).asInstanceOf[SoftmaxOutputLayer]};

val sgd = nn.updater.asInstanceOf[Grad];


//nn.launchTrain;
//
//println("Examine the 'nn' variable to track learning state.\n");

nn.train;

val (mm, mopts) = caffeModel.predLabels(testdata, testlabels);
mopts.batchSize= opts.batchSize;
mopts.autoReset = false;
mm.predict;

println("Accuracy = %f" format mean(mm.results(0,?),2).v);
//:silent


