import BIDMach.extern._
import BIDMach.networks.layers._
import java.io.FileReader

val traindir = "../../data/ImageNet/train/";
//val traindir = "/home/jfc/data/ImageNet/2012/BIDMach/train/";
val testdir = "../../data/ImageNet/val/";
val traindata = traindir+"partNCHW%04d.bmat.lz4";
val trainlabels = traindir+"label%04d.imat.lz4";
val testdata = testdir+"partNCHW%04d.bmat.lz4";
val testlabels = testdir+"label%04d.imat.lz4";
val testpreds = testdir+"pred%04d.fmat.lz4";

val (nn, opts) = Net.learner(traindata, trainlabels)
val net = nn.model.asInstanceOf[Net]

//:silent

val means = ones(3\256\256\256) *@ loadFMat(traindir+"means.fmat.lz4");

var f:FileReader = null
var caffeModel:CaffeModel = null
try {
  f = new FileReader("bvlc_alexnet_solver.prototxt")
  caffeModel = CaffeModel.loadFromSolver(f, opts, net, means)
} finally {
  if (f ne null) {
    f.close()
  }
}

opts.logfile = "logAlexnet4y_CaffeIO.txt";
opts.npasses = 80;
opts.useCache = false;
opts.inplace = Net.InPlace;

def loss = {net.layers(net.layers.length-1).asInstanceOf[SoftmaxOutputLayer]};


//nn.launchTrain;
//
//println("Examine the 'nn' variable to track learning state.\n");

nn.train;

val (mm, mopts) = caffeModel.predLabels(testdata, testlabels);
mopts.batchSize= opts.batchSize;
mopts.autoReset = false;
mm.predict;

println("Accuracy = %f" format mean(mm.results(0,?),2).v);
//:silent


